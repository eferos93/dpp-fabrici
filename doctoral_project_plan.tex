\documentclass[12pt]{article}

\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm, a4paper]{geometry}
\usepackage[latin1]{inputenc}
\usepackage{eurosym}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{color}
\usepackage{biblatex}
%\bibliography{References.bib}
\addbibresource{References.bib}
%\usepackage{natbib}
%\bibliographystyle{apaeng}
\definecolor{shadecolor}{gray}{0.95}
\setlength{\FrameSep}{\fboxsep}
\usepackage{url}
\setlist{noitemsep, topsep=3pt}

\ifpdf
  \DeclareGraphicsExtensions{.pdf,.png,.jpg}
\else
  \DeclareGraphicsExtensions{.eps}
\fi  

\newcommand{\dottedrule}[1]{%
   \parbox[t]{#1}{\rule{0pt}{5mm}\dotfill}}
\newcommand{\dottedline}{%
   {\rule{0pt}{5mm}\dotfill\newline}}
\newcommand{\dottedlineitem}{%
   {\rule{0pt}{5mm}\dotfill\mbox{}}}

\usepackage{fancyhdr}
\fancyhead{}
\cfoot{\thepage}
\lhead{\includegraphics[height=15mm]{ec_logo}}
\rhead{\includegraphics[height=15mm]{DEDS_logo}}
%\setlength{\headheight}{47pt}

%\thispagestyle{fancy}

\setlength{\headheight}{47pt}
\pagestyle{fancy}

\begin{document}

\noindent\framebox[\textwidth][c]{
\bf\large
\begin{tabular}{c}
European Joint Doctorate in  \\
Data Engineering for Data Science (DEDS) \\*[2mm]
Doctoral Project Plan\footnotemark \\
Synopses-Driven Data Integration and Federated Learning \\ Eros Fabrici \\
\end{tabular}
}\\[5mm]

%\footnotetext{Choose the appropriate heading. Based on the PhD Study Plan of Aalborg University, available at \url{http://www.phd.teknat.aau.dk/intranet/phd-study-plan}.}

%The Doctorate Project Plan (DPP), Thesis Proposal Report (TPR), and Research Progress Report (RPR) constitute a tool for directing the development of a  doctorate process. It helps to formulate and concretise different elements involved in the process. It is also meant as a communication tool among the doctoral candidate, his/her co-supervisors, and the Candidate Progress Committee (CPC).  From an administrative viewpoint, it is a tool for evaluating the extent to which the proposed research can be realised within the framework of a doctorate study. Therefore, this tool will be used for the candidate's evaluation in the four milestones M1--M4.

%The DPP has to be submitted to the chair of the CPC no later than two months after the start of the studies (M1). The DPP should include the initial plan of the doctorate project, as well as the preliminary overview of the literature in the studied field, which should further lead to concretise the specific project topic. It is expected that the co-supervisors lead the production of the plan.
%In the TPR, the DPP is updated by the candidate according to the experiences gained during the beginning phase of the project. It is expected that the TPR is much more concrete and elaborated than the DPP. The TPR should propose a specific path for the rest of the doctorate project, including concrete topics to be studied, tentative list of expected publications, doctorate training, external co-operation, and other activities to be completed during the project. The TPR should be sent to the chair of the CPC no later than one month before the end of the first academic year (M2). In the RPR, the TPR is updated by the candidate, reporting the results, and the completed activities (e.g., publications, doctorate training, external co-operations) during the doctorate project. The RPR should be sent to the chair of the CPC no later than one month before the end of the second academic year (M3). Finally, the Doctoral Thesis will be submitted at the end of the third year (M4).

%The following sections contain the elements that are to be present in the DPP, TPR, and RPR. The DPP should be specific and as short as possible while still containing the necessary information. Sections 1--6 and 8 should in total not exceed 10 pages (12 point Times New Roman, 20 mm margins on all sides).
%The template form at the end of this document must be filled out and handed in along with the doctorate plan/report, to be added to the portfolio of the candidate.
%\begin{shaded}
%\noindent
%\emph{The particular areas that you must pay attention to with regard to the TPR and RPR are written in italic and highlighted.}
%\end{shaded}

%Please make sure that a proper scientific conduct is demonstrated throughout the DPP, TPR, and RPR. For guidelines see, for example, the European Code of Conduct for Research Integrity\footnote{\url{http://www.esf.org/fileadmin/Public_documents/Publications/Code_Conduct_ResearchIntegrity.pdf}}, the Singapore Statement\footnote{\url{http://www.singaporestatement.org/}}, and similar sources.

\section{Project Summary}
The term Big Data refers to data sets that are too large or complex to be dealt with by traditional data processing software. 
In particular, Big Data captures to 4 dimensions: Velocity, Variety, Veracity, and Volume. This large quantity of data available nowadays has 
a lot of statistical and business value, therefore their analysis is of core importance for business decision-making. Nevertheless, the data 
involved in those processes contains a lot of sensitive information regarding individuals (e.g. health sector). There is therefore also the need to 
guarantee the privacy of the individuals while being able to extract insights and patterns from the data. 

Data Integration is the set of processes to gather and bridge data from heterogeneous sources together in order to 
have a unified view. The premise of data integration is to make data more freely available and easier 
to consume and process by systems and users.
Research on Data Integration started more than 50 years ago \cite*{recordLinkTheory,dataModelIntegration1980} but as we entered the Big Data era, new challenges arose,
 which include scaling \cite*{Dong2013} data integration while guaranteeing the privacy \cite*{yu2016big, Gkoulalas-Divanis2021} of the individuals involved in the datasets.
Over the last decade new techniques have been applied for improving computational performance, consisting of the use of parallelizing the computation by using big data processing platforms \cite*{Dong2013},
 or algorithmically, namely using summarization techniques \cite*{Cormode2011}, used for 
approximate fast and approximate querying, improving the performance of Machine Learning processes \cite*{Gribonval2020, Antonanzas2021, Jiang2018} as well as in some data integration scenarios.
Despite the progress made, it is difficult to combine efficiency (the integration is completed with no, or very few, errors), computational performance and privacy altogether \cite*{He2017}. 

%Analyzing Big Data may involve accessing sensitive information, especially in the health sector. For these reasons, in Data Integration, 
%techniques like Secure Multi-Party Computation and Differential Privacy \cite*{Dwork2013} have been used. One big concern in private Data Integration is that it is 
%difficult to guarantee privacy, accuracy, and good performance at the same time.

Machine Learning and Data Integration have really close relationship \cite*{Dong2019}. In particular, it is possible to leverage the first to improve the performance of the second
and vice-versa. An evolving branch of Machine Learning (ML) is Federated Learning (FL), which consists in building a model in a federated setting (when the data is distributed across different data owners) and model in a collaborative way, without moving the data to a central server. This new technique is a good match with the need of privacy in ML nowadays. Despite its advantages, 
 there are a lot of open problems in FL \cite*{Kairouz2021}. In particular, data in FL needs to be pre-processed (e.g. align the schemas, record linkage) in order to start the training process. This would 
 require the data to move out of the edge-devices, therefore threatening privacy.

 This Ph.D. aims to explore algorithms, data structures and ML for scaling Data Integration tasks while guaranteeing privacy and achieving good performance, tailored to the Federated Learning pre-processing workflow.


%A short (maximum 400 words) summary in layman's terms describing in a preliminary manner key motivation, significance, methodology, and expected outcome of the doctorate study. A reader of the local newspaper should be able to understand the summary.

%\begin{shaded}
%\noindent
%\emph{TPR: An updated version of the summary, concretising key motivation, significance, methodology, and expected outcome of the doctorate study.}

%\noindent
%\emph{RPR: An updated version of the summary, refining key motivation, significance, methodology, and reporting the hitherto outcome of the doctorate study.}
%\end{shaded}

\section{Scientific Content of the Doctorate Project}
\subsection{Background}
\subsubsection{Data Integration}
Data Integration (DI) is the practice of consolidating data from disparate sources into a unified view. It has been studied since the birth relational databases. 
It is characterized by three main steps: 
\begin{enumerate}
   \item \textbf{Schema alignment}, a process that takes as input a set of different schemas on the same domain an outputs a \textit{mediated schema}, an \textit{attribute matching} and a \textit{schema mapping}.
   \item \textbf{Record linkage}, also referred as entity resolution, computes a partitioning of the set of records from different datasets, such that each partition identifies the records that refer to a distinct entity.
   \item \textbf{Data fusion} aim is to identify which are the best records to represent a specific entity, when a source provide conflicting values.
\end{enumerate}

%\begin{enumerate}
%\item The background for the project problem should be described (maximum 300 words).
%\item An introduction stating the state of the art for the doctorate project. The introduction should include key references listed under Section 7. Typically, at least 10-15 references to peer-reviewed scientific material are expected. In case it is necessary to refer to non-peer-reviewed material then use a footnote (or parenthesis) to provide information to the source. Explain the relevance of the present doctorate project so the scientific contribution will be evident -- i.e., explain how the project advances current state-of-the-art. Scientific challenges should be clearly defined -- do not mistake this for technological challenges.
\subsubsection{Federated Learning}
FL is a ML approach where a model is trained across multiple decentralized data owners. Each data owner trains a local model and then, 
either in a centralized, decentralized or heterogeneous approach, build a global model. It differs from a distributed machine learning 
as the data is not expected to be identically distributed. Besides the advantage of having a distributed computation, 
guaranteeing more efficiency, it gained a lot of popularity due to the fact that data is not exchanged between the parts involved, thus guaranteeing privacy.

It has gained a lot of popularity both in research and industry, in particular in transportation \cite*{Elbir2020}, Industry 4.0 \cite*{Shubyn2022} and digital health \cite*{Prayitno2021}.
\subsubsection{Differential Privacy \& Synopses for Big Data}
Differential Privacy (DP) is a technique for sharing datasets' information without compromising the privacy of the individuals. 
The idea is to add noise to the data such that the new distribution is close to the real one, but not equal. 

More specifically, it guarantees that any sequence of outputs (response to a query) is equally likely 
to occur, independent of the presence or absence of any individual in the dataset. The main advantage of DP is that it is robust 
against membership and information inference attacks, i.e. when an attacker is able to de-anonymize an anonymized dataset via 
linkage attacks. A good example of de-anonymization attack is the one proposed by Narayanan et.al. \cite*{Nara2008} where from an 
anonymized dataset of Netflix subscribers' viewing history, they de-anonymized it through a linkage attack with the Internet Movies Database, 
revealing the users' apparent political preferences and other sensitive information.


Synopses or summaries are a set of technique and probabilistic data structures to compute compact description of big datasets. 
These methods compute lossy, compact summaries of data, from which it is possible to carry out interactive analyses and queries. 
They have been used extensively for streaming data, now gaining popularity also in ML and FL.
%They gained a lot of popularity over the last decade due to the rise of Big Data.

\subsection{State of the Art}
\subsubsection{Privacy-aware Data Integration in the Big Data Era}
Privacy in the context of data management has gained a lot of popularity over the last decade, as public awareness about issues in management sensitive data increased. Due two this,
privacy became of central importance in the field of Big Data Management, analytics and processing.

In the particular case of Data Integration, privacy-preserving techniques
has been used extensively in literature, especially for record linkage. In particular, differentially-private record linkage and cryptography has
been used extensively \cite*{Khurram2020,Vatsalan2017, Clifton, Kuzu2013, Gkoulalas-Divanis2021, Nobrega2021, Bonomi2012, Kuzu2013}. 
As regards schema matching and data fusion, there are fewer works on guaranteeing privacy, most of the work is based on guaranteeing efficiency, by using 
both rule-based and learning-based approaches \cite*{Rodrigues2021,Riedel2013,Saleem2009}.


\paragraph{Schema matching.}
Schema matching aligns attributes and data types. It is one of the oldest problems studied for data integration and the 
traditional approaches consist in extracting knowledge according to a predefined schema. They can be categorized as it follows:
\begin{itemize}
   \item \textbf{Schema-level matchers}, where only the metadata is considered (e.g. column labels, data-types). Linguistic matching is mostly used here (stemming, tokenization, etc.) \cite*{Bernstein2011}.
   \item \textbf{Instance-level matchers}, where the content of the columns is used for matching by using probabilistic approaches \cite*{Szymczak2016, Dasu2002} or rule-based approaches.
   \item \textbf{Hybrid matchers} that combine the two matchers just described.
\end{itemize}

In schema matching the problem of \textit{volume} have to be taken into account only in few specific cases, for example when we consider millions sources from the web \cite*{Pimplikar2012}, but not in typical DI scenarios, 
where the number of sources is limited.
Universal Schema \cite*{Riedel2013} has revolutionized schema alignment. It consists in extracting (subject, predicate, object) triples, where the predicate can be any word or phrase from texts and instead of outputting 
mappings between predicates, it adds inferred triples. This is done through matrix factorization \cite*{Riedel2013}, while recently it is improved by using 
Recurrent Neural Networks \cite*{Das2016,Nee2015}.

For what we know so far, there is no work in literature regarding privacy-aware schema matching. This because most of the techniques are based on the schemas' metadata. 
Nevertheless, if Instance-level approaches are used, it may be useful to use techniques for guaranteeing the privacy of the individuals, e.g. differential privacy.

%namely there is no need to increase computational performance, rather 
%exploring new techniques for having more precise matchers could be necessary. Nevertheless, the availability of big data, brought recent 
%research towards \textbf{learning-based} matchers, where pre-existing mappings are used to train machine learning algorithms that 



\paragraph{Record linkage.}
Record Linkage, also called Entity Resolution, consists in finding records, among different data sources, that refers to the same real world entity. 
It is the most important problem in integrating data from different sources. 

Generally, it proceeds in three steps: 
\begin{enumerate}
   \item \textbf{blocking records} that are likely to be a match;
   \item \textbf{compare pairs of records} to decide if it's a match;
   \item \textbf{clustering records} according to the previous step's results.
\end{enumerate}

Approaches consisted mostly in rule-based techniques \cite*{recordLinkTheory, Gal2011} for the first two steps, while for clustering either 
rule-based or optimizing a particular objective function \cite*{Hass2009}. 

Recently, supervised learning approaches (e.g. Support Vector Machines, Decision Trees, Random Forest) showed to obtain high precision and recall \cite*{Das2017}, 
at the cost of generating training labels, i.e. to obtain a precision and recall of 99\% on linking a pair of datasets, 1.5M training labels are required \cite*{Dong2018}.

Performance and efficiency is not only the main concern of Record Linkage. In a real-world scenario, the data involved in the linkage may be sensitive, and methods to guarantee 
the privacy of the individuals is a major concern. Privacy-Preserving Record Linkage (PPRL) identifies the set of techniques that aim to link different datasets in 
a privacy-preserving manner.
Initially, Secure Multiparty Computation (SMC) techniques were used, in particular, the Paillier crypto-system \cite*{paillier1999public}. 
These protocols are reliable and very effective, with the downside of a very prohibitive computational cost. 
In other to improve performance, by applying secure transformations to the data \cite*{Bonomi2013}, such as embedding records to different spaces and then mining them with differential privacy.
This comes with the cost of having less accurate results. 

Generally, the PPRL protocols proposed for secure two-party private record linkage are not able to meet the following three requirements altogether, without making strict assumptions: 
(1) \textbf{full end-to-end privacy}, 
(2) \textbf{perfect precision and recall} for the matching records and (3) \textbf{sub-quadratic computational complexity} \cite*{He2017, Groce2019}. 
%After \cite*{He2017} pointed out this problem, new approaches were proposed and resulted in meeting all the three requirements described above \cite*{Groce2019}, 
%but still limited to certain adversarial models, that do not match well with real world scenarios (e.g. \textit{honest-but-curious}), 
Moreover, multi-party PPRL is a more realistic scenario and only in the last years it has been tackled, with still limited results \cite*{Vatsalan2016, Vatsalan2017, Vatsalan2020}.
%Although there have been many prior works that looked into different security and privacy aspects of PPRL \cite*{Gkoulalas-Divanis2021}, there still remain major challenges that need to be addressed. 
%For example, inference
%For example, a malicious party may create many random records with the intent of matching with the other parties' actual records \cite*{Gkoulalas-Divanis2021}. 
%To tackle this problem, blockchain technologies are recently being proposed in literature \cite*{Nobrega2021}.

\paragraph{Data Fusion.} Data fusion resolves conflicts between different data sources, by selecting the best record per entity. 
Access to highly accurate data is critical for industry applications, such as knowledge graph search, so data fusion is often 
an important step in data integration.

The main methods for data fusion are rule-based \cite*{dong2009data} and also data-mining based \cite*{Pas2010}. 
Graphical models are also used in this context \cite*{Gao2016} as well as semi-unsupervised approaches \cite*{Reka2017}.

Privacy-preserving data fusion has not been studied deeply in literature. There are a few context specific works, for example \cite*{DING2019129} 
identifies privacy issues and future research directions for data fusion in Internet-Of-Things and \cite*{Gati2021} which focuses on Differential Privacy in the 
context of Cyber-Physical Systems.

\subsubsection{Federated Learning}
Federated Learning (FL) has been proposed by Google \cite*{Kon2016}. The idea is to build a global ML model from datasets that are 
distributed across edge devices, without moving the data. 
An unbalanced and non-IID (identically and independently distributed) data partitioning across a massive number of unreliable 
devices with limited communication bandwidth was introduced as the defining set of challenges \cite*{Kairouz2021}.
%TODO add references in this paragraph
Privacy is one of the essential properties of FL. Many techniques exist in literature (e.g. Secure Multiparty Computation, homomorphic encryption), but 
\textbf{Differential Privacy} represents \textit{de facto} standard for Privacy in many areas (querying, synthetic data generation, etc.) as it guarantees a 
better computational performance rather than cryptographic approaches.

FL can be categorized as it follows: 
\begin{itemize}
   \item \textbf{Horizontal Federated Learning}. Horizontal FL refers when the federated datasets share the same feature space (the column names) but not the sample space (rows). This system
   assumes that all the participants are honest and security against an honest-but-curious server \cite*{Yang2019}. Usually, the learning steps in this system are: (1) 
   each data owner \textit{train a local model} then the (2) \textit{gradients are sent} to the central server, which applies a (3) \textit{secure aggregation} on them and  
   received by the federation. Finally, the (4) \textit{model updates} computed by the central server are sent back to the data owners and their local models get updated.
   \item \textbf{Vertical Federated Learning}. Vertical FL is applicable when the datasets share the sample ID space, but the features are different. In this scenario, data pre-processing is required, in particular 
   \textit{schema alignment} and \textit{entity resolution}. These phases require exchanging data with a third party to do the pre-computation, therefore security is more difficult to guarantee in this case.
\end{itemize}
%in many areas such as queries, synthetic data generation and in ML training

\subsubsection{Future Directions}
FL is getting more and more used in many areas, in particular in the health care \cite*{Che2022,Bou2019,app112311191}. Despite the fact 
that FL brought us new hope for the of data privacy in Artificial Intelligence, various challenges needs to be addressed \cite*{Kairouz2021}. 
In particular, FL applications usually require engineers to align and link the datasets manually. Therefore, it would be critical to work 
on new methods to automate scale the data preparation steps while guaranteeing the privacy.

\subsection{Project Objectives}
The goal of this PhD can be divided in two main objectives. The first is to improve the state of the art of Privacy Preserving DI (PPDI) by 
bringing it in a more practical scenario, namely, the FL data preparation step. Secondly, after having identified strength and weaknesses of 
the actual PPDI techniques, design and develop a framework to integrate with the FL process. We aim to use techniques like synopses, 
probabilistic data structures and differential privacy.
\begin{enumerate}
   \item \textbf{O1.} Improve the state of the art of Privacy Preserving DI techniques by tackling the limitations that make them unfeasible to apply to 
   real world scenarios.
   \item \textbf{O2.} Propose a framework to integrate to real world scenarios, namely the FL preprocessing steps.
\end{enumerate}

\subsection{Key Methods}
We will try to apply the following methods to achieve the
project's objectives and ensure the production of high quality results:
\begin{itemize}
   \item Study the literature review of the current Privacy-Preserving Data Integration techniques and analyze their strengths 
   and weaknesses. %This step can be considered as a continuous loop as more and more scientific papers are
   %published in the top tier conferences and journals.
   \item After understanding and analyzing the offerings of current solutions, we will propose algorithms that will use Differential Privacy 
   and Synopses that will satisfy all the three requirements mentioned in the state of the art. 
   The goal here is to design and implement the solution in a simulated federated environment.
   \item Regarding the evaluation of the proposed solutions, appropriate benchmarks will be considered
   ensuring the correctness of our results.
\end{itemize}

\subsection{Significance and Outcome}

Federated Learning is getting more and more used in the real world as satisfies privacy requirements. 
Unfortunately, it is still challenging to apply it in real world scenario, and it requires a lot of effort by 
engineers to prepare the data for FL tasks. 

The expected outcome of this project includes (1) presentation of our work in top tier conferences
and journals, (2) collaboration with other research teams and/or industrial partners (e.g. secondment), to
exchange ideas and boost the results of our work, and (3) open-sourcing critical components of our work.

\section{Co-supervisors/Candidate Co-operation Agreements}
The project will be carried out in three years during which the PhD student will stay in one research institution and one university. During the first and the third year, the candidate will work in Athena Research Center (ARC) under the supervision of Prof. Minos Garofalakis (ARC). During the second year, the program
will take place in Universitat Politecnica de Catalunya (UPC) under the supervision of Prof. Oscar Romero (UPC). The project will be a joint work of all parties, hence close co-operation is expected in the following way.

The progress of the project will be validated through frequent meetings between the candidate and his supervisors. The candidate will meet on a weekly basis with his home supervisor and one or two times per month with his host supervisor (the opposite when he will be hosted at UPC). Following typical business practice, the expectations and tasks planned for each meeting will be clearly communicated in advance, with a reasonable notice, both from the supervisors to the candidate and vice-versa. Standard tools of the trade will be used to boost collaboration, such
as a shared repository for documents and code artifacts (e.g., Mendeley Library, GitHub, etc.), communication platforms (e.g. Skype, Teams).


\section{Work Plan}
\subsection{Timetable}
The PhD is a 3-year-long study, spanning from May 1st, 2022 to February 28th, 2025.
\begin{table}[h]
   \centering
   \begin{tabular}{lp{.8\textwidth}}
       \textbf{Time}        & \textbf{Plan}                                                               \\
       \toprule
       %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
       \textbf{Spring 2022}   &
       Winter School at ARC \newline
       Preparation of the two months study plan                         \newline
       Literature review of Privacy Preserving Data Integration    \newline
       Summer School at ULB \\
       \textbf{Milestones}  &
       \textbf{Submission of two months study plan}                                                       \\
       \midrule
       %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
       \textbf{Fall 2022} &
       Participation in 1 PhD courses as shown in the courses' table \newline
       Preparation of the 11 months study plan \newline
       Survey the current state of the art in Privacy Preserving DI \newline
       Summer School at ULB \\
       \textbf{Milestones}  &
       \textbf{Submission of 11 months study plan}                                                        \\
       \midrule
       %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
       \textbf{Spring 2023}   &
       Create an efficient algorithm based of synopses and differential privacy for schema alignment \newline
       Summer School at UPC                                                                               \\
       \midrule
       %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
       \textbf{Fall 2023} &
       Participation in 2 PhD courses as shown in the courses' table \newline
       Design and develop an algorithm for PPRL using synopses and differential privacy \\                                                                              \\
       \midrule
       %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
       \textbf{Spring 2024}   &
       Prototype a framework for PPDI for Federated Learning systems                                         \\
       \midrule
       %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
       \textbf{Fall 2024} &
       Write the thesis                               \\
       \textbf{Milestones}  &
       \textbf{Submission of the PhD thesis}                                                              \\
       \bottomrule
   \end{tabular}
   % \caption{The plan for the PhD study}\label{table:timeplan}
\end{table}

\subsection{Thesis Outline}
The thesis will be constituted by the research papers that will be written during the whole duration of
the project. The thesis report will include (1) an introduction chapter providing background knowledge,
motivation, research challenges, objectives and contributions, (2) a chapter about the state of the art
(survey paper), (3) one chapter for each published research paper that will include technical details of the
implementation, evaluation etc., and (4) a last chapter concluding the work, discussing lessons learned
and providing future directions.

\subsubsection{Tentative Publication List}
The publications that can be considered at the moment of writing the Doctorate Project Plan are the
following:
\begin{enumerate}
   \item A survey paper targeting to illustrate the state of the art of Privacy Preserving Data Integration. Our
   main contributions will be to initiate a new reader to the field of PPDI,
   by illustrating the current applied techniques through examples. Comparison of the methods,
   limitations, research challenges, and future work will also be included.
   \item A research and a demo paper about learning for each of the following: (a) Differentially Private and Synopses-driven schema alignment for FL and (b) PPRL for FL and show how it can be used 
   for tracking the patient history.
   \item A research paper about the framework for Privacy Preserving DI for FL systems.
\end{enumerate}

%\item Statement of the project's objectives. This could be formulated as a hypothesis and/or research questions if applicable.

%\item Key methods. Coverage of the methodological needs, identification of means of meeting these needs, and the methodological design. The coverage should include techniques for evaluating or assessing the outcome of the project (e.g. empirical studies and/or theoretical studies).


%\item Potential significance and application(s) of the project's expected outcome, possibly including methodological contributions.

%\item Work and time plans including measurable milestones (project milestones and deadlines for expected publications for each 6-month period, or finer).
%A practice is recommended where results are documented and submitted for publication in peer-reviewed outlets throughout the project.

%The planned timing for the stays at the host institution should be given. In addition to this, the plans for mobility to a partner organisation (secondment) should be stated.


%\item Outline of the content of the thesis.

%\item
%Outline the publication strategy for the project.
%Tentative titles (or expected subjects) on papers, including preliminary authors list (indicate who has the primary responsibility for the publication). Three international peer-reviewed publications should be planned, at least.


%\emph{RPR: The list of publications, published and/or accepted as part of the doctorate project should be reported, together with the ongoing and planned ones.}
%\end{shaded}

%\end{enumerate}

%The DEDS programme expects that the co-supervisor and candidate should meet (face to face if possible) at least once every other week.
%Each of these working meetings should produce minutes drafted by the candidate stating:
%(1) what was done since last meeting,
%(2) what will be done before next meeting,
%(3) what is slowing down or blocking the project, and
%(4) what was discovered that would be of interest, or needs to be discussed.

%In addition, periodic monitoring meetings are planned just before moving from one university of the co-tutelle to the other.
%These teleconference (e.g., skype) meetings involving the candidate and both co-supervisors allow doctoral candidates to present their results, ask questions, prepare the next stay, etc.
%Minutes of these meetings are drafted by the candidate in a Periodic Evaluation Form, reviewed by the local supervisor, and added to the candidate's portfolio.%allowing the CPC an efficient quality control and monitoring.

%Please detail the agreement on the relationship between the co-supervisors and the candidate (meeting frequency, communication forms, mutual expectations, etc.).

%\begin{shaded}
%\noindent
%\emph{TPR: Status and updated agreement on the relationship between co-supervisors and candidate.}

%\noindent
%\emph{RPR: Report on the achieved relationship between co-supervisors and candidate throughout the doctorate project.}
%\end{shaded}

\section{Proposed Education and Training Programme}
During the PhD studies, it is necessary to have research activities adding up to at least 30 ECTS credits. 
The ECTS points should be divided between general and research-related courses. Courses can either
be taken in National and Kapodistrian University of Athens or in Universitat Politecnica de Catalunya,
with conference attendance and other activities contributing as well.
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}\hline
\makebox[5cm]{Activity} & At & ECTS & Type & Time & Status \\\hline\hline
Distributed Systems & NKUA & 6 & General & Autumn'22 & Planned \\
Big Data Management & UPC & 6 & Project & Autumn'23 & Planned \\
Research Methods & UPC & 6 & General & Autumn'23 & Planned \\\hline
Winter School (ARC) & ARC & 3 & Project & Spring'22 & Completed \\
Summer School (ULB) & ULB & 3 & Project & Spring'22 & Mandatory \\
Winter School (AAU) & AAU & 3 & General & Fall'22 & Mandatory \\
Summer School (UPC) & UPC & 3 & General & Spring'23 & Mandatory\\\hline
Conference Attendance & TBD & 6 & Project & Multiple & Planned\\\hline
Secondment & SPR & 4 & Project & Summer'24 & Planned\\\hline
Greek Language course & NKUA & - & Project & Multiple & Planned\\\hline
\end{tabular}
\end{center}

\section{Knowledge Dissemination and Participation to Scientific Events}

We plan to disseminate the product knowledge by publishing papers in top tier conferences, such as ACM
SIGMOD, VLDB, IEEE ICDE, EDBT etc. and journals, such as VLDB J., ACM TODS, IEEE TKDE,
Information Systems, etc. Moreover, we will pursue opportunities to expose our work to additional
outlets (e.g., AI Summit, ACM/IEEE local chapters, meet-ups) through presenting talks and tutorials or
giving demonstrations, in order to open a communication channel with the big data engineering,
and big data management communities. In this way, we will (a) advertise our work and explore collaboration
and exploitation opportunities, and (b) collect valuable feedback that will ameliorate and/or redirect our
research.


%, e.g., newspaper articles, seminars, conference presentations, teaching, etc.
%As seen, dissemination is not only teaching but can also be other activities.

\section{External Co-operation}
The doctorate candidate will spend time studying both in Greece 
and Spain. Furthermore, a secondment of three months will take place, where the candidate will join
Spring Techno, where he will work on of a complex Federated Learning scenario with real data.
During the following three years, all ESRs will meet in four different winter/summer schools to present their work, receive feedback, exchange ideas, and get exposed to new challenges. During these schools, candidates will have the opportunity to get in touch with academic and non-academic partners, presenting them their findings, reflecting on new opportunities, and opening the way for further collaboration. Finally, the candidate may co-operate with external researchers or research teams, in case that his work can be combined or merged with similar works of others.

%The doctorate candidate must participate actively in another research environment outside his/her home and host universities.
%Outline a plan for external co-operation (e.g., secondment at a partner organization).
%One or two tentative institutions (others than that of the co-supervisors) must be described. \\
%This should include:
%\begin{itemize}
%\item Co-operation with researchers at external/international research environments (typically partner organizations).
%\item Active engagement in external research environments via, e.g., an external stay of 2-3 months.
%Activities of specific significance for the study must be included. Summer schools, conference attendance, etc. are not considered external cooperation. The co-operation must be a research co-operation in which also the visiting institution contributes to the research. The co-operation must be active and it must be with a research institution or a company doing innovation and research.
%\end{itemize}

%Summer schools, conference attendance, etc., are not considered external cooperation.
%The candidate can be awarded with up to 4 ECTS credits based on the Secondment Evaluation Forms of these co-operations.

%\begin{shaded}
%\noindent
%\emph{TPR: A description must be updated with hitherto completed and expected/planned co-operation activities.}

%\noindent
%\emph{RPR: Completed co-operation activities during the doctorate project must be reported.}
%\end{shaded}

\section{Agreements on Immaterial Rights to Patents}

Patents and immaterial rights will be handled according to general rules applied by Athena Research Center, National and Kapodistrian University of Athens, and Universitat Politecnica de Catalunya.

%\begin{shaded}
%\noindent
%\emph{TPR: Update this section if applicable.}

%\noindent
%\emph{RPR: Update this section if applicable.}
%\end{shaded}

\section{Financing Budget}
As regards the long-term career ambitions and objective of the candidate, pursuing a PhD offers 
This project is one of the 15 ESRs of Data Engineering for Data Science PhD programme, which is funded by the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 955895. The funding covers expenses related to the successful completion of the project, such as work equipment, research experiments, training activities and others
that are relevant to the programme.

%\begin{shaded}
%\noindent
%\emph{TPR: Update this section if applicable.}

%\noindent
%\emph{RPR: Update this section if applicable.}
%\end{shaded}

\section{Career Development Plan}
After completing the three years 
programme, the candidate will be an independent researcher, ready to join the academia or pursue a competitive professional career in the industry. 
During the PhD programme, the candidate will be initiated 
into research by acquiring competitive research skills, will gain expertise in state-of-the-art technologies, 
cultivate soft skills, such as communication, presentation and co-operation, and work within a professional environment.


%\section{References}
%\bibliographystyle{te}
\printbibliography{}
%List of essential references used in the doctorate plan (e.g., in the state of the art) including authors, title, publication outlet, pages/volume/year and for conferences also town/country/dates. Include only peer-reviewed publications (includes books from recognised publishers). The list should include the most important 10-25 references in the research field.

%\begin{shaded}
%\noindent
%\emph{TPR: List of essential references used in the thesis proposal must be updated.}

%\noindent
%\emph{RPR: List of essential references used in the progress report must be updated.}
%\end{shaded}

\pagebreak

\noindent\framebox[\textwidth][c]{
\bf\large
\begin{tabular}{c}
\bf European Joint Doctorate in  \\
\bf Data Engineering for Data Science (DEDS) \\
Doctorate Project Plan\footnotemark\\
Thesis Title \\ First Name Last Name \\
\end{tabular}
}\\[5mm]
\footnotetext{Choose the appropriate heading among the three}

\emph{This page must be completed and sent together with the project
plan/report in a pdf file to the chair of the Candidate Progress Committee.}

\vspace*{3mm}

\noindent
Project title: \dottedline
Name of doctorate candidate: \dottedline
Email: \dottedline
Supervisor: \dottedline
Home University: \dottedline
Co-supervisor: \dottedline
Host University: \dottedline
Secondment supervisor: \dottedline
Partner organisation: \dottedline
Date of enrolment: \dottedline
Expected date of completion: \dottedline

\vspace*{3mm}
\subsubsection*{Signatures}
\vspace*{3mm}

\begin{tabular}{p{0.48\textwidth}}
The Doctorate Candidate\\
\dottedline
\vspace{2cm}%
Date: \\

The Supervisor from the Host University\\
Professor \dottedline
\vspace{2cm}%
Date: \\

\end{tabular}
%
\begin{tabular}{p{0.48\textwidth}}
The Supervisor from the Home University\\
Professor \dottedline
\vspace{2cm}%
Date: \\

The Secondment Supervisor \\
\dottedline
\vspace{2cm}%
Date: \\

\end{tabular}


\begin{center}
\begin{tabular}{p{0.48\textwidth}}
The Chair of the Candidate Progress Committee\\
Professor \dottedline
\vspace{2cm}%
Date: \\

\end{tabular}
\end{center}

\end{document}