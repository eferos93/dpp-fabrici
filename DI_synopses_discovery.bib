
@article{Said2014,
	title = {Comparative recommender system evaluation: {Benchmarking} recommendation frameworks},
	doi = {10.1145/2645710.2645746},
	abstract = {Recommender systems research is often based on comparisons of predictive accuracy: the better the evaluation scores, the better the recommender. However, it is difficult to compare results from different recommender systems due to the many options in design and implementation of an evaluation strategy. Additionally, algorithmic implementations can diverge from the standard formulation due to manual tuning and modifications that work better in some situations. In this work we compare common recommendation algorithms as implemented in three popular recommendation frameworks. To provide a fair comparison, we have complete control of the evaluation dimensions being benchmarked: dataset, data splitting, evaluation strategies, and metrics. We also include results using the internal evaluation mechanisms of these frameworks. Our analysis points to large differences in recommendation accuracy across frameworks and strategies, i.e. the same baselines may perform orders of magnitude better or worse across frameworks. Our results show the necessity of clear guidelines when reporting evaluation of recommender systems to ensure reproducibility and comparison of results.},
	journal = {RecSys 2014 - Proceedings of the 8th ACM Conference on Recommender Systems},
	author = {Said, Alan and Bellogín, Alejandro},
	year = {2014},
	note = {ISBN: 9781450326681},
	pages = {129--136},
	file = {PDF:/home/erosfabrici/Zotero/storage/D9BDWDS9/recsys-benchmarking.pdf:application/pdf},
}

@inproceedings{huang2012private,
  title={Private set intersection: Are garbled circuits better than custom protocols?},
  author={Huang, Yan and Evans, David and Katz, Jonathan},
  booktitle={NDSS},
  year={2012}
}

@article{durham2013composite,
  title={Composite bloom filters for secure record linkage},
  author={Durham, Elizabeth A and Kantarcioglu, Murat and Xue, Yuan and Toth, Csaba and Kuzu, Mehmet and Malin, Bradley},
  journal={IEEE transactions on knowledge and data engineering},
  volume={26},
  number={12},
  pages={2956--2968},
  year={2013},
  publisher={IEEE}
}

@inproceedings{christen2017efficient,
  title={Efficient cryptanalysis of bloom filters for privacy-preserving record linkage},
  author={Christen, Peter and Schnell, Rainer and Vatsalan, Dinusha and Ranbaduge, Thilina},
  booktitle={Advances in Knowledge Discovery and Data Mining: 21st Pacific-Asia Conference, PAKDD 2017, Jeju, South Korea, May 23-26, 2017, Proceedings, Part I 21},
  pages={628--640},
  year={2017},
  organization={Springer}
}

@article{christen2018precise,
  title={Precise and fast cryptanalysis for Bloom filter based privacy-preserving record linkage},
  author={Christen, Peter and Ranbaduge, Thilina and Vatsalan, Dinusha and Schnell, Rainer},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={31},
  number={11},
  pages={2164--2177},
  year={2018},
  publisher={IEEE}
}

@inproceedings{christen2018pattern,
  title={Pattern-mining based cryptanalysis of Bloom filters for privacy-preserving record linkage},
  author={Christen, Peter and Vidanage, Anushka and Ranbaduge, Thilina and Schnell, Rainer},
  booktitle={Advances in Knowledge Discovery and Data Mining: 22nd Pacific-Asia Conference, PAKDD 2018, Melbourne, VIC, Australia, June 3-6, 2018, Proceedings, Part III},
  pages={530--542},
  year={2018},
  organization={Springer}
}

@article{kroll2014automated,
  title={Automated cryptanalysis of bloom filter encryptions of health records},
  author={Kroll, Martin and Steinmetzer, Simone},
  journal={arXiv preprint arXiv:1410.6739},
  year={2014}
}

@ARTICLE{sequence_BF_DP,
  author={Xue, Wanli and Vatsalan, Dinusha and Hu, Wen and Seneviratne, Aruna},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Sequence Data Matching and Beyond: New Privacy-Preserving Primitives Based on Bloom Filters}, 
  year={2020},
  volume={15},
  number={},
  pages={2973-2987},
  doi={10.1109/TIFS.2020.2980835}}
@article{kula_metadata_2015,
	title = {Metadata embeddings for user and item cold-start recommendations},
	volume = {1448},
	issn = {16130073},
	abstract = {I present a hybrid matrix factorisation model representing users and items as linear combinations of their content features' latent factors. The model outperforms both collaborative and content-based models in cold-start or sparse interaction data scenarios (using both user and item metadata), and performs at least as well as a pure collaborative matrix factorisation model where interaction data is abundant. Additionally, feature embeddings produced by the model encode semantic information in a way reminiscent of word embedding approaches, making them useful for a range of related tasks such as tag recommendations.},
	journal = {CEUR Workshop Proceedings},
	author = {Kula, Maciej},
	year = {2015},
	note = {arXiv: 1507.08439},
	keywords = {Cold-start, Matrix Factorization, Recommender Systems},
	pages = {14--21},
	file = {PDF:/home/erosfabrici/Zotero/storage/QBM924J5/1507.08439.pdf:application/pdf},
}

@article{said_rival_2014,
	title = {{RiVal} - {A} toolkit to foster reproducibility in recommender system evaluation},
	doi = {10.1145/2645710.2645712},
	abstract = {Currently, it is diffcult to put in context and compare the results from a given evaluation of a recommender system, mainly because too many alternatives exist when design- ing and implementing an evaluation strategy. Furthermore, the actual implementation of a recommendation algorithm sometimes diverges considerably from the well-known ideal formulation due to manual tuning and modifications observed to work better in some situations. RiVal - a recommender system evaluation toolkit - allows for complete control of the different evaluation dimensions that take place in any experimental evaluation of a recommender system: data split- ting, definition of evaluation strategies, and computation of evaluation metrics. In this demo we present some of the functionality of RiVal and show step-by-step how RiVal can be used to evaluate the results from any recommendation framework and make sure that the results are comparable and reproducible.},
	journal = {RecSys 2014 - Proceedings of the 8th ACM Conference on Recommender Systems},
	author = {Said, Alan and Bellogín, Alejandro},
	year = {2014},
	note = {ISBN: 9781450326681},
	keywords = {Recommender systems, Benchmarking, Evaluation, Experiments, Recommendation frameworks, Reproducibility},
	pages = {371--372},
	file = {PDF:/home/erosfabrici/Zotero/storage/ITGGKQRG/2014-recsys-rival.pdf:application/pdf},
}

@article{Bellogin2021,
	title = {Improving {Accountability} in {Recommender} {Systems} {Research} {Through} {Reproducibility}},
	url = {http://arxiv.org/abs/2102.00482},
	abstract = {Reproducibility is a key requirement for scientific progress. It allows the reproduction of the works of others, and, as a consequence, to fully trust the reported claims and results. In this work, we argue that, by facilitating reproducibility of recommender systems experimentation, we indirectly address the issues of accountability and transparency in recommender systems research from the perspectives of practitioners, designers, and engineers aiming to assess the capabilities of published research works. These issues have become increasingly prevalent in recent literature. Reasons for this include societal movements around intelligent systems and artificial intelligence striving towards fair and objective use of human behavioral data (as in Machine Learning, Information Retrieval, or Human-Computer Interaction). Society has grown to expect explanations and transparency standards regarding the underlying algorithms making automated decisions for and around us. This work surveys existing definitions of these concepts, and proposes a coherent terminology for recommender systems research, with the goal to connect reproducibility to accountability. We achieve this by introducing several guidelines and steps that lead to reproducible and, hence, accountable experimental workflows and research. We additionally analyze several instantiations of recommender system implementations available in the literature, and discuss the extent to which they fit in the introduced framework. With this work, we aim to shed light on this important problem, and facilitate progress in the field by increasing the accountability of research.},
	author = {Bellogín, Alejandro and Said, Alan},
	year = {2021},
	note = {arXiv: 2102.00482},
	file = {PDF:/home/erosfabrici/Zotero/storage/9MA4ZCES/2102.00482.pdf:application/pdf},
}

@article{shafto_human-recommender_2016,
	title = {Human-{Recommender} {Systems}},
	doi = {10.1145/2959100.2959188},
	abstract = {We bring to the fore of the recommender system research community, an inconvenient truth about the current state of understanding how recommender system algorithms and humans influence one another, both computationally and cognitively. Unlike the great variety of supervised machine learning algorithms which traditionally rely on expert input labels and are typically used for decision making by an ex-pert, recommender systems specifically rely on data input from non-expert or casual users and are meant to be used directly by these same non-expert users on an every day basis. Furthermore, the advances in online machine learn-ing, data generation, and predictive model learning have be-come increasingly interdependent, such that each one feeds on the other in an iterative cycle. Research in psychology suggests that people's choices are (1) contextually depen-dent, and (2) dependent on interaction history. Thus, while standard methods of training and assessing performance of recommender systems rely on benchmark datasets, we sug-gest that a critical step in the evolution of recommender systems is the development of benchmark models of human behavior that capture contextual and dynamic aspects of human behavior. It is important to emphasize that even extensive real life user-tests may not be sufficient to make up for this gap in benchmarking validity because user tests are typically done with either a focus on user satisfaction or engagement (clicks, sales, likes, etc) with whatever the rec-ommender algorithm suggests to the user, and thus ignore the human cognitive aspect. We conclude by highlighting the interdisciplinary implications of this endeavor.},
	author = {Shafto, Patrick and Nasraoui, Olfa},
	year = {2016},
	note = {ISBN: 9781450340359},
	pages = {127--130},
	file = {PDF:/home/erosfabrici/Zotero/storage/VQU4YE8E/2959100.2959188.pdf:application/pdf},
}

@article{ferro_evaluating_2018,
	title = {From {Evaluating} to {Forecasting} {Performance}: {How} to {Turn} {Information} {Retrieval}, {Natural} {Language} {Processing} and {Recommender} {Systems} into {Predictive} {Sciences}},
	volume = {7},
	issn = {2193-2433},
	abstract = {We describe the state-of-the-art in performance modeling and prediction for Information Retrieval (IR), Natural Language Processing (NLP) and Recommender Systems (RecSys) along with its shortcomings and strengths. We present a framework for further research, identifying five major problem areas: understanding measures, performance analysis, making underlying assumptions explicit, identifying application features determining performance, and the development of prediction models describing the relationship between assumptions, features and resulting performance.},
	number = {1},
	author = {Ferro, Nicola and Fuhr, Norbert and Grefenstette, Gregory and Konstan, Joseph and Castells, Pablo and Daly, Elizabeth and Declerck, Thierry and Ekstrand, Michael and Geyer, Werner and Gonzalo, Julio and Kuflik, Tsvi and Lindén, Krister and Magnini, Bernardo and Nie, Jian-Yun and Perego, Raffaele and Shapira, Bracha and Soboroff, Ian and Tintarev, Nava and Verspoor, Karin and Willemsen, Martijn and Zobel, Justin},
	year = {2018},
	keywords = {113 Computer and information sciences, 6121 Languages, Article},
	pages = {1--42},
	file = {PDF:/home/erosfabrici/Zotero/storage/GZ6TJUZJ/17442-dagman.pdf:application/pdf},
}

@article{canamares_offline_2020,
	title = {Offline evaluation options for recommender systems},
	volume = {23},
	issn = {15737659},
	url = {https://doi.org/10.1007/s10791-020-09371-3},
	doi = {10.1007/s10791-020-09371-3},
	abstract = {We undertake a detailed examination of the steps that make up offline experiments for recommender system evaluation, including the manner in which the available ratings are filtered and split into training and test; the selection of a subset of the available users for the evaluation; the choice of strategy to handle the background effects that arise when the system is unable to provide scores for some items or users; the use of either full or condensed output lists for the purposes of scoring; scoring methods themselves, including alternative top-weighted mechanisms for condensed rankings; and the application of statistical testing on a weighted-by-user or weighted-by-volume basis as a mechanism for providing confidence in measured outcomes. We carry out experiments that illustrate the impact that each of these choice points can have on the usefulness of an end-to-end system evaluation, and provide examples of possible pitfalls. In particular, we show that varying the split between training and test data, or changing the evaluation metric, or how target items are selected, or how empty recommendations are dealt with, can give rise to comparisons that are vulnerable to misinterpretation, and may lead to different or even opposite outcomes, depending on the exact combination of settings used.},
	number = {4},
	journal = {Information Retrieval Journal},
	author = {Cañamares, Rocío and Castells, Pablo and Moffat, Alistair},
	year = {2020},
	note = {Publisher: Springer Netherlands
ISBN: 1079102009371},
	keywords = {Recommender systems, Evaluation, Effectiveness metric, Experimental design},
	pages = {387--410},
	file = {PDF:/home/erosfabrici/Zotero/storage/7FTPAJHP/Cañamares2020_Article_OfflineEvaluationOptionsForRec.pdf:application/pdf},
}

@article{rossetti_contrasting_2016,
	title = {Contrasting offline and online results when evaluating recommendation algorithms},
	doi = {10.1145/2959100.2959176},
	abstract = {Most evaluations of novel algorithmic contributions assess their accuracy in predicting what was withheld in an of- ine evaluation scenario. However, several doubts have been raised that standard offline evaluation practices are not ap- propriate to select the best algorithm for field deployment. The goal of this work is therefore to compare the offline and the online evaluation methodology with the same study participants, i.e. a within users experimental design. This paper presents empirical evidence that the ranking of algo- rithms based on offline accuracy measurements clearly con- tradicts the results from the online study with the same set of users. Thus the external validity of the most commonly applied evaluation methodology is not guaranteed.},
	number = {September},
	journal = {RecSys 2016 - Proceedings of the 10th ACM Conference on Recommender Systems},
	author = {Rossetti, Marco and Stella, Fabio and Zanker, Markus},
	year = {2016},
	note = {ISBN: 9781450340359},
	keywords = {Evaluation methodology, Experimental within users design, User study},
	pages = {31--34},
	file = {PDF:/home/erosfabrici/Zotero/storage/ZQY5MLEF/contrasting-offline-online_camera.pdf:application/pdf},
}

@article{de_pauw_exploratory_2020,
	title = {Exploratory {Methods} for {Evaluating} {Recommender} {Systems}},
	doi = {10.1145/3383313.3411456},
	abstract = {A common and recently widely accepted problem in the field of machine learning is the black box nature of many algorithms. In practice, many machine learning algorithms can only be viewed and evaluated in terms of their inputs and outputs, without taking their internal workings into account. Perhaps the most notorious examples in this context are artificial neural networks and deep learning techniques, but they are certainly not the only techniques that suffer from this problem. Matrix factorisation models for recommendation systems, for example, suffer from the same lack of interpretability. Our research focuses on applying and adapting pattern mining techniques to gain meaningful insights in recommendation algorithms by analysing them in terms of both their input and output, also allowing us to compare different algorithms and discover the hidden biases that lead to those differences.},
	number = {September 2020},
	journal = {RecSys 2020 - 14th ACM Conference on Recommender Systems},
	author = {De Pauw, Joey},
	year = {2020},
	note = {ISBN: 9781450375832},
	keywords = {Interpretability, Model Explanation, Pattern Mining},
	pages = {782--786},
	file = {PDF:/home/erosfabrici/Zotero/storage/9FVHN2KK/DePauwExploratory.pdf:application/pdf},
}

@article{mansoury_automating_2018,
	title = {Automating recommender systems experimentation with librec-auto},
	doi = {10.1145/3240323.3241614},
	abstract = {Recommender systems research often requires the creation and execution of large numbers of algorithmic experiments to determine the sensitivity of results to the values of various hyperparameters. Existing recommender systems platforms fail to provide a basis for systematic experimentation of this type. In this paper, we describe librec-auto, a wrapper for the well-known LibRec library, which provides an environment that supports automated experimentation.},
	number = {September},
	journal = {RecSys 2018 - 12th ACM Conference on Recommender Systems},
	author = {Mansoury, Masoud and Ordonez-Gauger, Aldo and Burke, Robin and Sepulveda, Xavier},
	year = {2018},
	note = {ISBN: 9781450359016},
	keywords = {Experimentation, Librec, Recommender Systems Frameworks},
	pages = {500--501},
	file = {PDF:/home/erosfabrici/Zotero/storage/LXH5U7XR/ACM-p500-mansoury.pdf:application/pdf},
}

@article{mansoury_fairness-aware_nodate,
	title = {Fairness-aware {Recommendation} with librec-auto},
	author = {Mansoury, Masoud},
	note = {ISBN: 9781450375832},
	keywords = {experimentation, fair-, librec, recommender systems frameworks},
	pages = {594--596},
	file = {PDF:/home/erosfabrici/Zotero/storage/XKUNVXIR/3383313.3411525.pdf:application/pdf},
}

@phdthesis{vargas_novelty_2015,
	title = {Novelty and {Diversity} {Evaluation} and {Enhancement} in {Recommender} {Systems}},
	url = {http://hdl.handle.net/10486/666686},
	abstract = {Recommender Systems have become a pervasive technology in a wide spectrum of everyday applications, and can be said to be familiar to the general public. In situations where there is an information overload, such as e-commerce, streaming platforms or social networks, providing personalized recommendations has proven to be a major source of enhanced functionality, user satisfaction, and revenue improvements. The development of recommendation algorithms and technologies has typically focused on maximizing the prediction accuracy of the user’s interests. However, there is an increasing awareness in the field that there are other properties that have an impact on user satisfaction and business performance. In particular, there are many cases where applying some degree of novelty or diversity may be beneficial for both the users that receive the recommendations and the business that provides them. In this thesis we develop a principled approach to the evaluation and enhancement of novelty and diversity in Recommender Systems. We consider that the improvement of such fundamental dimensions of the usefulness of recommendations has to take into account how users explore and perceive recommendations, what are the problems that novelty and diversity solve and the causes of such problems. We propose in our first contribution a unified framework for the evaluation and enhancement of novelty and diversity in recommendations that generalizes and enhances many of the proposals previously studied in the state of the art under a common basis. Special emphasis is done in the study of the diversity within recommendations lists, for which two different contributions are presented. On the one hand, an adaptation of search result diversification metrics and techniques from Information Retrieval is explored to cope with the ambiguity of user interests and tastes. On the other hand, a domain-specific solution for assessing and optimizing the diversity of recommendations is proposed to address the need of users for varied recommendations when genre information about the recommendation domain is available. Finally, we address diversity as an overall quality from the system point of view, and we propose solutions for the problem in this perspective by turning the recommendation task around and recommending users to items. Our proposals are tested on a common experimental design that considers three different datasets for movie and music recommendation and four well-known baseline recommendation algorithms. The results of our experiments support the validity of our contributions and allow the analysis and further insights on their behavior when applied to different settings.},
	author = {Vargas, Saúl},
	year = {2015},
	note = {Issue: February
ISBN: 978-1-4899-7637-6},
	file = {PDF:/home/erosfabrici/Zotero/storage/R9YNJZI6/phd-thesis.pdf:application/pdf},
}

@book{ricci_recommender_2015,
	title = {Recommender systems handbook, {Second} edition},
	isbn = {978-1-4899-7637-6},
	abstract = {This second edition of a well-received text, with 20 new chapters, presents a coherent and unified repository of recommender systems’ major concepts, theories, methodologies, trends, and challenges. A variety of real-world applications and detailed case studies are included. In addition to wholesale revision of the existing chapters, this edition includes new topics including: decision making and recommender systems, reciprocal recommender systems, recommender systems in social networks, mobile recommender systems, explanations for recommender systems, music recommender systems, cross-domain recommendations, privacy in recommender systems, and semantic-based recommender systems. This multi-disciplinary handbook involves world-wide experts from diverse fields such as artificial intelligence, human-computer interaction, information retrieval, data mining, mathematics, statistics, adaptive user interfaces, decision support systems, psychology, marketing, and consumer behavior. Theoreticians and practitioners from these fields will find this reference to be an invaluable source of ideas, methods and techniques for developing more efficient, cost-effective and accurate recommender systems.},
	author = {Ricci, Francesco and Shapira, Bracha and Rokach, Lior},
	year = {2015},
	doi = {10.1007/978-1-4899-7637-6},
	note = {Publication Title: Recommender Systems Handbook, Second Edition},
	file = {PDF:/home/erosfabrici/Zotero/storage/LSHDUY5Z/gunawardana2015.pdf:application/pdf},
}

@article{mesas_evaluating_2017,
	title = {Evaluating decision-aware recommender systems},
	doi = {10.1145/3109859.3109888},
	abstract = {The main goal of a Recommender System is to suggest relevant items to users, although other utility dimensions - such as diversity, novelty, confidence, possibility of providing explanations - are often considered. In this work, in order to increase the amount of relevant items presented to the user, we analyse how the system could measure the confidence on its own recommendations, so it has the capability of taking decisions about whether an item should be recommended or not. A direct consequence of this design is that the number of suggested items decreases, impacting in some of the beyond-accuracy dimensions (especially, coverage). We present an evaluation of different decision-aware techniques that can be applied to some families of recommender systems, and explore evaluation metrics that allow to combine more than one evaluation dimension. Empiric results show that large precision improvements are obtained when using these approaches at the expense of user and item coverage.},
	number = {August 2017},
	journal = {RecSys 2017 - Proceedings of the 11th ACM Conference on Recommender Systems},
	author = {Mesas, Rus M. and Bellogín, Alejandro},
	year = {2017},
	note = {ISBN: 9781450346528},
	pages = {74--78},
	file = {PDF:/home/erosfabrici/Zotero/storage/J8E3EN3R/recsys.pdf:application/pdf},
}

@article{di_buccio_unfolding_2015,
	title = {Unfolding {Off}-the-shelf {IR} {Systems} for {Reproducibility}},
	doi = {10.13140/RG.2.1.3475.0161},
	abstract = {In this position paper, we discuss the issue of how to ensure reproducibility of the results when off-the-shelf open source Information Retrieval (IR) systems are used. These systems provided a great advancement to the field but they rely on many configurations parameters which are often implicit or hidden in the documentation and/or source code. If not fully understood and made explicit, these parameters may make it difficult to reproduce results or even to understand why a system is not behaving as expected. The paper provides examples of the effects of hidden pa-rameters in off-the-shelf IR systems, describes the enabling technologies needed to embody the approach, and show how these issues can be addressed in the broader context of com-ponent based IR evaluation. We propose a solution for systematically unfolding the configuration details of off-the-shelf IR systems and under-standing whether a particular instance of a system using is behaving as expected. The proposal requires to: 1) build a taxonomy of components used by off-the-shelf systems, 2) uniquely identify them and their combination in a given configuration, 3) run each configuration on standard test collections, 4) compute the expected performance measures for each run, 4) and publish on a Web portal all the gathered information in order to make accessible and comparable for everybody how an off-the-shelf system with a given config-uration is expected to behave.},
	number = {August},
	author = {Di Buccio, Emanuele and Maria, Giorgio and Nunzio, Di and Ferro, Nicola and Harman, Donna and Maistro, Maria and Silvello, Gianmaria},
	year = {2015},
	file = {PDF:/home/erosfabrici/Zotero/storage/XLJBIJ2W/2015-SIGIR-RIGOR-SIlvello.pdf:application/pdf},
}

@article{guo_librec_2015,
	title = {Librec: {A} {Java} library for recommender systems},
	volume = {1388},
	issn = {16130073},
	abstract = {The large array of recommendation algorithms proposed over the years brings a challenge in reproducing and comparing their performance. This paper introduces an open-source Java library that implements a suite of state-of-the-art algorithms as well as a series of evaluation metrics. We empirically find that LibRec performs faster than other such libraries, while achieving competitive evaluative performance.},
	journal = {CEUR Workshop Proceedings},
	author = {Guo, Guibing and Zhang, Jie and Sun, Zhu and Yorke-Smith, Neil},
	year = {2015},
	pages = {2--5},
	file = {PDF:/home/erosfabrici/Zotero/storage/ZLMNEBQV/demo_paper1.pdf:application/pdf},
}

@article{bajpai_challenges_2017,
	title = {Challenges with reproducibility},
	doi = {10.1145/3097766.3097767},
	abstract = {The Computer Science (CS) culture is gentle to accepting papers that are non-reproducible as long as they appear plausible. In this paper, we discuss some of the challenges with reproducibility and a set of recommendations that we as a community can undertake to initiate a cultural change.},
	journal = {Reproducibility 2017 - Proceedings of the Reproducibility Workshop, Part of SIGCOMM 2017},
	author = {Bajpai, Vaibhav and Ott, Jörg and Kühlewind, Mirja and Trammell, Brian and Schönwälder, Jürgen and Sperotto, Anna},
	year = {2017},
	note = {ISBN: 9781450350600},
	keywords = {Reproducibility},
	pages = {1--4},
	file = {PDF:/home/erosfabrici/Zotero/storage/N4UFQJYJ/3097766.3097767.pdf:application/pdf},
}

@article{alejandro_bellogin_pablo_castells_statistical_2017,
	title = {Statistical biases in {Information} {Retrieval} {Metrics} for {Recommender} {Systems}},
	volume = {2},
	author = {Alejandro Bellogín, Pablo Castells, Iván Cantador},
	year = {2017},
	note = {ISBN: 1136800900994},
	pages = {301--312},
	file = {PDF:/home/erosfabrici/Zotero/storage/WZW5M8K3/statical_bellogin_information_2017_ps.pdf:application/pdf},
}

@article{said_recommender_2012,
	title = {Recommender systems evaluation: {A} {3D} benchmark},
	volume = {910},
	issn = {16130073},
	abstract = {Recommender systems add value to vast content resources by matching users with items of interest. In recent years, immense progress has been made in recommendation tech- niques. The evaluation of these has however not been matched and is threatening to impede the further development of rec-ommender systems. In this paper we propose an approach that addresses this impasse by formulating a novel evalua-tion concept adopting aspects from recommender systems research and industry. Our model can express the quality of a recommender algorithm from three perspectives, the end consumer (user), the service provider and the vendor (business and technique for both). We review current bench- marking activities and point out their shortcomings, which are addressed by our model. We also explain how our 3D benchmarking framework would apply to a specific use case.},
	number = {January},
	journal = {CEUR Workshop Proceedings},
	author = {Said, Alan and Tikk, Domonkos and Shi, Yue and Larson, Martha and Stumpf, Klara and Cremonesi, Paolo},
	year = {2012},
	pages = {21--23},
	file = {PDF:/home/erosfabrici/Zotero/storage/EHHMK9DZ/Recommender_Systems_Evaluation_A_3D_Benchmark.pdf:application/pdf},
}

@article{bagher_user_2017,
	title = {User trends modeling for a content-based recommender system},
	volume = {87},
	issn = {09574174},
	doi = {10.1016/j.eswa.2017.06.020},
	abstract = {Recommender systems have been developed to overcome the information overload problem by retrieving the most relevant resources. Constructing an appropriate model to estimate the user interests is the major task of recommender systems. The profile matching and latent factors are two main approaches for user modeling. Although a notion of timestamps has already been applied to address the temporary nature of recommender systems, the evolutionary behavior of such systems is less studied. In this paper, we introduce the concept of trend to capture the interests of user in selecting items among different group of similar items. The trend based user model is constructed by incorporating user profile into a new extension of Distance Dependent Chines Restaurant Process (dd-CRP). dd-CRP which is a Bayesian Nonparametric model, provides a framework for constructing an evolutionary user model that captures the dynamics of user interests. We evaluate the proposed method using a real-world data-set that contains news tweets of three news agencies (New York Times, BBC and Associated Press). The experimental results and comparisons show the superior recommendation accuracy of the proposed approach, and its ability to effectively evolve over time.},
	number = {June},
	journal = {Expert Systems with Applications},
	author = {Bagher, Rahimpour Cami and Hassanpour, Hamid and Mashayekhi, Hoda},
	year = {2017},
	keywords = {Content-based recommender systems, User modeling, User trends},
	pages = {209--219},
	file = {PDF:/home/erosfabrici/Zotero/storage/PMY6RJWQ/UserTrendsModelingforaContent-basedRecommenderSystem---preprint.pdf:application/pdf},
}

@article{mansoury_algorithm_2019,
	title = {Algorithm selection with librec-auto},
	volume = {2360},
	issn = {16130073},
	abstract = {Due to the complexity of recommendation algorithms, experimentation on recommender systems has become a challenging task. Current recommendation algorithms, while powerful, involve large numbers of hyperparameters. Tuning hyperparameters for finding the best recommendation outcome often requires execution of large numbers of algorithmic experiments particularly when multiples evaluation metrics are considered. Existing recommender systems platforms fail to provide a basis for systematic experimentation of this type. In this paper, we describe librec-auto, a wrapper for the well-known LibRec library, which provides an environment that supports automated experimentation.},
	number = {April},
	journal = {CEUR Workshop Proceedings},
	author = {Mansoury, Masoud and Burke, Robin},
	year = {2019},
	pages = {1--7},
	file = {PDF:/home/erosfabrici/Zotero/storage/Q8NTZP2H/paper3LibRecAuto.pdf:application/pdf},
}

@article{hug_surprise_2020,
	title = {Surprise: {A} {Python} library for recommender systems},
	volume = {5},
	issn = {2475-9066},
	doi = {10.21105/joss.02174},
	abstract = {Surprise is a Python scikit building and analyzing recommender systems.},
	number = {52},
	journal = {Journal of Open Source Software},
	author = {Hug, Nicolas},
	year = {2020},
	note = {ISBN: 9783319296593},
	pages = {2174},
	file = {PDF:/home/erosfabrici/Zotero/storage/JJYP2CWA/10.21105.joss.02174.pdf:application/pdf},
}

@article{Ekstrand2020,
	title = {{LensKit} for {Python}: {Next}-{Generation} {Software} for {Recommender} {Systems} {Experiments}},
	doi = {10.1145/3340531.3412778},
	abstract = {LensKit is an open-source toolkit for building, researching, and learning about recommender systems. First released in 2010 as a Java framework, it has supported diverse published research, small-scale production deployments, and education in both MOOC and traditional classroom settings. In this paper, I present the next generation of the LensKit project, re-envisioning the original tool's objectives as flexible Python package for supporting recommender systems research and development. LensKit for Python (LKPY) enables researchers and students to build robust, flexible, and reproducible experiments that make use of the large and growing PyData and Scientific Python ecosystem, including scikit-learn, and TensorFlow. To that end, it provides classical collaborative filtering implementations, recommender system evaluation metrics, data preparation routines, and tools for efficiently batch running recommendation algorithms, all usable in any combination with each other or with other Python software. This paper describes the design goals, use cases, and capabilities of LKPY, contextualized in a reflection on the successes and failures of the original LensKit for Java software.},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	author = {Ekstrand, Michael D.},
	year = {2020},
	note = {arXiv: 1809.03125
ISBN: 9781450368599},
	keywords = {evaluation, experiments, recommender systems, support software},
	pages = {2999--3006},
	file = {PDF:/home/erosfabrici/Zotero/storage/7FW77ZXZ/1809.03125.pdf:application/pdf},
}

@article{ekstrand_exploring_2021,
	title = {Exploring author gender in book rating and recommendation},
	issn = {15731391},
	doi = {10.1007/s11257-020-09284-2},
	abstract = {Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of these patterns reflect important real-world phenomena driving interactions between the various users and items; other patterns may be irrelevant or reflect undesired discrimination, such as discrimination in publishing or purchasing against authors who are women or ethnic minorities. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to one dimension of social concern, namely content creator gender. Using publicly available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms tend to propagate at least some of each user’s tendency to rate or read male or female authors into their resulting recommendations, although they differ in both the strength of this propagation and the variance in the gender balance of the recommendation lists they produce. The data, experimental design, and statistical methods are designed to be reusable for studying potentially discriminatory social dimensions of recommendations in other domains and settings as well.},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Ekstrand, Michael D. and Kluver, Daniel},
	year = {2021},
	keywords = {Recommender systems, Discrimination, Gender bias, Research methods},
	file = {PDF:/home/erosfabrici/Zotero/storage/FU5EDF5Q/bag2-preprint.pdf:application/pdf},
}

@article{buitinck_api_2013,
	title = {{API} design for machine learning software: experiences from the scikit-learn project},
	url = {http://arxiv.org/abs/1309.0238},
	abstract = {Scikit-learn is an increasingly popular machine learning li- brary. Written in Python, it is designed to be simple and efficient, accessible to non-experts, and reusable in various contexts. In this paper, we present and discuss our design choices for the application programming interface (API) of the project. In particular, we describe the simple and elegant interface shared by all learning and processing units in the library and then discuss its advantages in terms of composition and reusability. The paper also comments on implementation details specific to the Python ecosystem and analyzes obstacles faced by users and developers of the library.},
	author = {Buitinck, Lars and Louppe, Gilles and Blondel, Mathieu and Pedregosa, Fabian and Mueller, Andreas and Grisel, Olivier and Niculae, Vlad and Prettenhofer, Peter and Gramfort, Alexandre and Grobler, Jaques and Layton, Robert and Vanderplas, Jake and Joly, Arnaud and Holt, Brian and Varoquaux, Gaël},
	year = {2013},
	note = {arXiv: 1309.0238},
	pages = {1--15},
	file = {PDF:/home/erosfabrici/Zotero/storage/Y9ZJ8F27/1309.0238.pdf:application/pdf},
}

@article{bellogin_precision-oriented_2011,
	title = {Precision-oriented evaluation of recommender systems: {An} algorithmic comparison},
	doi = {10.1145/2043932.2043996},
	abstract = {There is considerable methodological divergence in the way precision-oriented metrics are being applied in the Recommender Systems field, and as a consequence, the results reported in different studies are difficult to put in context and compare. We aim to identify the involved methodological design alternatives, and their effect on the resulting measurements, with a view to assessing their suitability, advantages, and potential shortcomings. We compare five experimental methodologies, broadly covering the variants reported in the literature. In our experiments with three state-of-the-art recommenders, four of the evaluation methodologies are consistent with each other and differ from error metrics, in terms of the comparative recommenders' performance measurements. The other procedure aligns with RMSE, but shows a heavy bias towards known relevant items, considerably overestimating performance. © 2011 ACM.},
	journal = {RecSys'11 - Proceedings of the 5th ACM Conference on Recommender Systems},
	author = {Bellogín, Alejandro and Castells, Pablo and Cantador, Iván},
	year = {2011},
	note = {ISBN: 9781450306836},
	keywords = {evaluation, error metrics, precision metrics},
	pages = {333--336},
	file = {PDF:/home/erosfabrici/Zotero/storage/PXYJD4LQ/2043932.2043996.pdf:application/pdf},
}

@book{Ricci2015,
	title = {Recommender systems handbook, {Second} edition},
	isbn = {978-1-4899-7637-6},
	abstract = {This second edition of a well-received text, with 20 new chapters, presents a coherent and unified repository of recommender systems’ major concepts, theories, methodologies, trends, and challenges. A variety of real-world applications and detailed case studies are included. In addition to wholesale revision of the existing chapters, this edition includes new topics including: decision making and recommender systems, reciprocal recommender systems, recommender systems in social networks, mobile recommender systems, explanations for recommender systems, music recommender systems, cross-domain recommendations, privacy in recommender systems, and semantic-based recommender systems. This multi-disciplinary handbook involves world-wide experts from diverse fields such as artificial intelligence, human-computer interaction, information retrieval, data mining, mathematics, statistics, adaptive user interfaces, decision support systems, psychology, marketing, and consumer behavior. Theoreticians and practitioners from these fields will find this reference to be an invaluable source of ideas, methods and techniques for developing more efficient, cost-effective and accurate recommender systems.},
	author = {Ricci, Francesco and Shapira, Bracha and Rokach, Lior},
	year = {2015},
	doi = {10.1007/978-1-4899-7637-6},
	note = {Publication Title: Recommender Systems Handbook, Second Edition},
	file = {PDF:/home/erosfabrici/Zotero/storage/C7K9W39J/Francesco Ricci, Lior Rokach, Bracha Shapira (eds.) - Recommender Systems Handbook (2015, Springer US).pdf:application/pdf},
}

@article{sun_are_2020,
	title = {Are {We} {Evaluating} {Rigorously}? {Benchmarking} {Recommendation} for {Reproducible} {Evaluation} and {Fair} {Comparison}},
	doi = {10.1145/3383313.3412489},
	abstract = {With tremendous amount of recommendation algorithms proposed every year, one critical issue has attracted a considerable amount of attention: there are no effective benchmarks for evaluation, which leads to two major concerns, i.e., unreproducible evaluation and unfair comparison. This paper aims to conduct rigorous (i.e., reproducible and fair) evaluation for implicit-feedback based top-N recommendation algorithms. We first systematically review 85 recommendation papers published at eight top-tier conferences (e.g., RecSys, SIGIR) to summarize important evaluation factors, e.g., data splitting and parameter tuning strategies, etc. Through a holistic empirical study, the impacts of different factors on recommendation performance are then analyzed in-depth. Following that, we create benchmarks with standardized procedures and provide the performance of seven well-tuned state-of-the-arts across six metrics on six widely-used datasets as a reference for later study. Additionally, we release a user-friendly Python toolkit, which differs from existing ones in addressing the broad scope of rigorous evaluation for recommendation. Overall, our work sheds light on the issues in recommendation evaluation and lays the foundation for further investigation. Our code and datasets are available at GitHub (https://github.com/AmazingDD/daisyRec).},
	journal = {RecSys 2020 - 14th ACM Conference on Recommender Systems},
	author = {Sun, Zhu and Yu, DI and Fang, Hui and Yang, Jie and Qu, Xinghua and Zhang, Jie and Geng, Cong},
	year = {2020},
	note = {ISBN: 9781450375832},
	keywords = {Recommender Systems, Benchmarks, Reproducible Evaluation},
	pages = {23--32},
	file = {PDF:/home/erosfabrici/Zotero/storage/EXMTRAH7/3383313.3412489.pdf:application/pdf},
}

@article{Sakai2014,
	title = {Statistical reform in information retrieval?},
	volume = {48},
	issn = {0163-5840},
	doi = {10.1145/2641383.2641385},
	abstract = {IR revolves around evaluation. Therefore, IR researchers should employ sound evaluation practices. Nowadays many of us know that statistical significance testing is not enough, but not all of us know exactly what to do about it. This paper provides suggestions on how to report effect sizes and confidence intervals along with p-values, in the context of comparing IR systems using test collections. Hopefully, these practices will make IR papers more informative, and help researchers form more reliable conclusions that "add up." Finally, I pose a specific question for the IR community: should IR journal editors and SIGIR PC chairs require (rather than encourage) reporting of effect sizes and confidence intervals.},
	number = {1},
	journal = {ACM SIGIR Forum},
	author = {Sakai, Tetsuya},
	year = {2014},
	pages = {3--12},
	file = {PDF:/home/erosfabrici/Zotero/storage/SA5G67GG/2641383.2641385.pdf:application/pdf},
}

@article{kosir_how_2013,
	title = {How to improve the statistical power of the 10-fold cross validation scheme in recommender systems},
	doi = {10.1145/2532508.2532510},
	abstract = {At this stage development of recommender systems (RS), an evaluation of competing approaches (methods) yielding similar performances in terms of experiment reproduction is of crucial importance in order to direct the further development toward the most promising direction. These comparisons are usually based on the 10-fold cross validation scheme. Since the compared performances are often similar to each other, the application of statistical significance testing is inevitable in order to not to get misled by randomly caused differences of achieved performances. For the same reason, to reproduce experiments on a different set of experimental data, the most powerful significance testing should be applied. In this work we provide guidelines on how to achieve the highest power in the comparison of RS and we demonstrate them on a comparison of RS performances when different variables are contextualized. © 2013 ACM.},
	journal = {ACM International Conference Proceeding Series},
	author = {Košir, Andrej and Odić, Ante and Tkalčič, Marko},
	year = {2013},
	note = {ISBN: 9781450324656},
	keywords = {evaluation, recommender systems, experimental design, folding, paired testing},
	pages = {3--6},
	file = {PDF:/home/erosfabrici/Zotero/storage/KGWY3SWJ/2532508.2532510.pdf:application/pdf},
}

@article{raj_comparing_2020,
	title = {Comparing {Fair} {Ranking} {Metrics}},
	url = {http://arxiv.org/abs/2009.01311},
	abstract = {Ranking is a fundamental aspect of recommender systems. However, ranked outputs can be susceptible to various biases; some of these may cause disadvantages to members of protected groups. Several metrics have been proposed to quantify the (un)fairness of rankings, but there has not been to date any direct comparison of these metrics. This complicates deciding what fairness metrics are applicable for specific scenarios, and assessing the extent to which metrics agree or disagree. In this paper, we describe several fair ranking metrics in a common notation, enabling direct comparison of their approaches and assumptions, and empirically compare them on the same experimental setup and data set. Our work provides a direct comparative analysis identifying similarities and differences of fair ranking metrics selected for our work.},
	author = {Raj, Amifa and Wood, Connor and Montoly, Ananda and Ekstrand, Michael D.},
	year = {2020},
	note = {arXiv: 2009.01311},
	pages = {1--9},
	file = {PDF:/home/erosfabrici/Zotero/storage/VCPSW4TP/2009.01311.pdf:application/pdf},
}

@article{Zaharia2018,
	title = {Accelerating the {Machine} {Learning} {Lifecycle} with {MLflow}},
	abstract = {Machine learning development creates multiple new challenges that are not present in a traditional software development lifecycle. These include keeping track of the myriad inputs to an ML application (e.g., data versions, code and tuning parameters), reproducing results, and production deployment. In this paper, we summarize these challenges from our experience with Databricks customers, and describe MLflow, an open source platform we recently launched to streamline the machine learning lifecycle. MLflow covers three key challenges: experimentation, reproducibility, and model deployment, using generic APIs that work with any ML library, algorithm and programming language. The project has a rapidly growing open source community, with over 50 contributors since its launch in June 2018.},
	journal = {Bulletin of the IEEE Computer Society Technical Committee on Data Engineering},
	author = {Zaharia, Matei and Chen, Andrew and Davidson, Aaron and Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Murching, Siddharth and Nykodym, Tomas and Ogilvie, Paul and Parkhe, Mani and Xie, Fen and Zumar, Corey},
	year = {2018},
	pages = {39--45},
	file = {PDF:/home/erosfabrici/Zotero/storage/X7R2NFP3/ieee_mlflow.pdf:application/pdf},
}

@article{sculley_hidden_2015,
	title = {Hidden technical debt in machine learning systems},
	volume = {2015-Janua},
	issn = {10495258},
	abstract = {Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean François and Dennison, Dan},
	year = {2015},
	pages = {2503--2511},
	file = {PDF:/home/erosfabrici/Zotero/storage/2SM7CCXA/NIPS-2015-hidden-technical-debt-in-machine-learning-systems-Paper.pdf:application/pdf},
}

@article{da_costa_case_2018,
	title = {Case recommender},
	doi = {10.1145/3240323.3241611},
	abstract = {This paper presents a polished open-source Python-based recommender framework named Case Recommender, which provides a rich set of components from which developers can construct and evaluate customized recommender systems. It implements wellknown and state-of-the-art algorithms in rating prediction and item recommendation scenarios. The main advantage of the Case Recommender is the possibility to integrate clustering and ensemble algorithms with recommendation engines, easing the development of more accurate and efficient approaches.},
	author = {da Costa, Arthur and Fressato, Eduardo and Neto, Fernando and Manzato, Marcelo and Campello, Ricardo},
	year = {2018},
	note = {ISBN: 9781450359016},
	keywords = {recommender systems, framework, python},
	pages = {494--495},
	file = {PDF:/home/erosfabrici/Zotero/storage/LZJ4LRBU/3240323.3241611.pdf:application/pdf},
}

@article{cremonesi_looking_2011,
	title = {Looking for "good" recommendations: {A} comparative evaluation of recommender systems},
	volume = {6948 LNCS},
	issn = {03029743},
	doi = {10.1007/978-3-642-23765-2_11},
	abstract = {A number of researches in the Recommender Systems (RSs) domain suggest that the recommendations that are "best" according to objective metrics are sometimes not the ones that are most satisfactory or useful to the users. The paper investigates the quality of RSs from a user-centric perspective. We discuss an empirical study that involved 210 users and considered seven RSs on the same dataset that use different baseline and state-of-the-art recommendation algorithms. We measured the user's perceived quality of each of them, focusing on accuracy and novelty of recommended items, and on overall users' satisfaction. We ranked the considered recommenders with respect to these attributes, and compared these results against measures of statistical quality of the considered algorithms as they have been assessed by past studies in the field using information retrieval and machine learning algorithms. © 2011 IFIP International Federation for Information Processing.},
	number = {PART 3},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Cremonesi, Paolo and Garzotto, Franca and Negro, Sara and Papadopoulos, Alessandro Vittorio and Turrin, Roberto},
	year = {2011},
	note = {ISBN: 9783642237645},
	keywords = {Recommender systems, quality metrics, user study},
	pages = {152--168},
	file = {PDF:/home/erosfabrici/Zotero/storage/H7LN5CV7/Cremonesi2011_Chapter_LookingForGoodRecommendationsA.pdf:application/pdf},
}

@inproceedings{cormode_marginal_2018,
	address = {Houston TX USA},
	title = {Marginal {Release} {Under} {Local} {Differential} {Privacy}},
	isbn = {978-1-4503-4703-7},
	url = {https://dl.acm.org/doi/10.1145/3183713.3196906},
	doi = {10.1145/3183713.3196906},
	abstract = {Many analysis and machine learning tasks require the availability of marginal statistics on multidimensional datasets while providing strong privacy guarantees for the data subjects. Applications for these statistics range from finding correlations in the data to fitting sophisticated prediction models. In this paper, we provide a set of algorithms for materializing marginal statistics under the strong model of local differential privacy. We prove the first tight theoretical bounds on the accuracy of marginals compiled under each approach, perform empirical evaluation to confirm these bounds, and evaluate them for tasks such as modeling and correlation testing. Our results show that releasing information based on (local) Fourier transformations of the input is preferable to alternatives based directly on (local) marginals.},
	language = {en},
	urldate = {2022-09-30},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Cormode, Graham and Kulkarni, Tejas and Srivastava, Divesh},
	month = may,
	year = {2018},
	pages = {131--146},
	file = {3183713.3196906.pdf:/home/erosfabrici/Documents/3183713.3196906.pdf:application/pdf},
}

@article{cormode_data_2017,
	title = {Data sketching},
	volume = {60},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3080008},
	doi = {10.1145/3080008},
	abstract = {The approximate approach is often faster and more efficient.},
	language = {en},
	number = {9},
	urldate = {2022-09-30},
	journal = {Commun. ACM},
	author = {Cormode, Graham},
	month = aug,
	year = {2017},
	pages = {48--55},
	file = {Cormode - 2017 - Data sketching.pdf:/home/erosfabrici/Zotero/storage/5VUXKL7U/Cormode - 2017 - Data sketching.pdf:application/pdf},
}

@article{cormode_data_2017-1,
	title = {Data sketching},
	volume = {60},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3080008},
	doi = {10.1145/3080008},
	abstract = {The approximate approach is often faster and more efficient.},
	language = {en},
	number = {9},
	urldate = {2022-09-30},
	journal = {Commun. ACM},
	author = {Cormode, Graham},
	month = aug,
	year = {2017},
	pages = {48--55},
	file = {Cormode - 2017 - Data sketching.pdf:/home/erosfabrici/Zotero/storage/52F4HFF9/Cormode - 2017 - Data sketching.pdf:application/pdf},
}

@inproceedings{cormode_marginal_2018-1,
	address = {Houston TX USA},
	title = {Marginal {Release} {Under} {Local} {Differential} {Privacy}},
	isbn = {978-1-4503-4703-7},
	url = {https://dl.acm.org/doi/10.1145/3183713.3196906},
	doi = {10.1145/3183713.3196906},
	abstract = {Many analysis and machine learning tasks require the availability of marginal statistics on multidimensional datasets while providing strong privacy guarantees for the data subjects. Applications for these statistics range from finding correlations in the data to fitting sophisticated prediction models. In this paper, we provide a set of algorithms for materializing marginal statistics under the strong model of local differential privacy. We prove the first tight theoretical bounds on the accuracy of marginals compiled under each approach, perform empirical evaluation to confirm these bounds, and evaluate them for tasks such as modeling and correlation testing. Our results show that releasing information based on (local) Fourier transformations of the input is preferable to alternatives based directly on (local) marginals.},
	language = {en},
	urldate = {2022-09-30},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Cormode, Graham and Kulkarni, Tejas and Srivastava, Divesh},
	month = may,
	year = {2018},
	pages = {131--146},
	file = {Cormode et al. - 2018 - Marginal Release Under Local Differential Privacy.pdf:/home/erosfabrici/Zotero/storage/R3JN8RDR/Cormode et al. - 2018 - Marginal Release Under Local Differential Privacy.pdf:application/pdf},
}

@article{kang_schema_nodate,
	title = {On {Schema} {Matching} with {Opaque} {Column} {Names} and {Data} {Values}},
	abstract = {Most previous solutions to the schema matching problem rely in some fashion upon identifying "similar" column names in the schemas to be matched, or by recognizing common domains in the data stored in the schemas. While each of these approaches is valuable in many cases, they are not infallible, and there exist instances of the schema matching problem for which they do not even apply. Such problem instances typically arise when the column names in the schemas and the data in the columns are "opaque" or very difficult to interpret. In this paper we propose a two-step technique that works even in the presence of opaque column names and data values. In the first step, we measure the pair-wise attribute correlations in the tables to be matched and construct a dependency graph using mutual information as a measure of the dependency between attributes. In the second stage, we find matching node pairs in the dependency graphs by running a graph matching algorithm. We validate our approach with an experimental study, the results of which suggest that such an approach can be a useful addition to a set of (semi) automatic schema matching techniques.},
	language = {en},
	author = {Kang, Jaewoo and Naughton, Jeffrey F},
	pages = {12},
	file = {Kang and Naughton - On Schema Matching with Opaque Column Names and Da.pdf:/home/erosfabrici/Zotero/storage/A6C3TPTR/Kang and Naughton - On Schema Matching with Opaque Column Names and Da.pdf:application/pdf},
}

@misc{quoc_approximate_2018,
	title = {Approximate {Distributed} {Joins} in {Apache} {Spark}},
	url = {http://arxiv.org/abs/1805.05874},
	abstract = {The join operation is a fundamental building block of parallel data processing. Unfortunately, it is very resource-intensive to compute an equi-join across massive datasets. The approximate computing paradigm allows users to trade accuracy and latency for expensive data processing operations. The equi-join operator is thus a natural candidate for optimization using approximation techniques. Although sampling-based approaches are widely used for approximation, sampling over joins is a compelling but challenging task regarding the output quality. Naive approaches, which perform joins over dataset samples, would not preserve statistical properties of the join output. To realize this potential, we interweave Bloom filter sketching and stratified sampling with the join computation in a new operator, ApproxJoin, that preserves the statistical properties of the join output. ApproxJoin leverages a Bloom filter to avoid shuffling non-joinable data items around the network and then applies stratified sampling to obtain a representative sample of the join output. Our analysis shows that ApproxJoin scales well and significantly reduces data movement, without sacrificing tight error bounds on the accuracy of the final results. We implemented ApproxJoin in Apache Spark and evaluated ApproxJoin using microbenchmarks and real-world case studies. The evaluation shows that ApproxJoin achieves a speedup of 6-9x over unmodified Spark-based joins with the same sampling rate. Furthermore, the speedup is accompanied by a significant reduction in the shuffled data volume, which is 5-82x less than unmodified Spark-based joins.},
	language = {en},
	urldate = {2022-10-03},
	publisher = {arXiv},
	author = {Quoc, Do Le and Akkus, Istemi Ekin and Bhatotia, Pramod and Blanas, Spyros and Chen, Ruichuan and Fetzer, Christof and Strufe, Thorsten},
	month = may,
	year = {2018},
	note = {arXiv:1805.05874 [cs]},
	keywords = {Computer Science - Databases, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {Quoc et al. - 2018 - Approximate Distributed Joins in Apache Spark.pdf:/home/erosfabrici/Zotero/storage/YLQUKC3P/Quoc et al. - 2018 - Approximate Distributed Joins in Apache Spark.pdf:application/pdf},
}

@article{ertl_setsketch_2021,
	title = {{SetSketch}: filling the gap between {MinHash} and {HyperLogLog}},
	volume = {14},
	issn = {2150-8097},
	shorttitle = {{SetSketch}},
	url = {https://dl.acm.org/doi/10.14778/3476249.3476276},
	doi = {10.14778/3476249.3476276},
	abstract = {MinHash and HyperLogLog are sketching algorithms that have become indispensable for set summaries in big data applications. While HyperLogLog allows counting different elements with very little space, MinHash is suitable for the fast comparison of sets as it allows estimating the Jaccard similarity and other joint quantities. This work presents a new data structure called SetSketch that is able to continuously fill the gap between both use cases. Its commutative and idempotent insert operation and its mergeable state make it suitable for distributed environments. Fast, robust, and easy-toimplement estimators for cardinality and joint quantities, as well as the ability to use SetSketch for similarity search, enable versatile applications. The presented joint estimator can also be applied to other data structures such as MinHash, HyperLogLog, or HyperMinHash, where it even performs better than the corresponding state-of-the-art estimators in many cases.},
	language = {en},
	number = {11},
	urldate = {2022-10-05},
	journal = {Proc. VLDB Endow.},
	author = {Ertl, Otmar},
	month = jul,
	year = {2021},
	pages = {2244--2257},
	file = {Ertl - 2021 - SetSketch filling the gap between MinHash and Hyp.pdf:/home/erosfabrici/Zotero/storage/L6QDNWL3/Ertl - 2021 - SetSketch filling the gap between MinHash and Hyp.pdf:application/pdf},
}

@article{rao_hybrid_2019,
	title = {Hybrid {Private} {Record} {Linkage}: {Separating} {Differentially} {Private} {Synopses} from {Matching} {Records}},
	volume = {22},
	issn = {2471-2566, 2471-2574},
	shorttitle = {Hybrid {Private} {Record} {Linkage}},
	url = {https://dl.acm.org/doi/10.1145/3318462},
	doi = {10.1145/3318462},
	abstract = {Private record linkage protocols allow multiple parties to exchange matching records, which refer to the same entities or have similar values, while keeping the non-matching ones secret. Conventional protocols are based on computationally expensive cryptographic primitives and therefore do not scale. To address these scalability issues, hybrid protocols have been proposed that combine differential privacy techniques with secure multiparty computation techniques. However, a drawback of such protocols is that they disclose to the parties both the matching records and the differentially private synopses of the datasets involved in the linkage. Consequently, differential privacy is no longer always satisfied. To address this issue, we propose a novel framework that separates the private synopses from the matching records. The two parties do not access the synopses directly, but still use them to efficiently link records. We theoretically prove the security of our framework under the state-of-the-art privacy notion of differential privacy for record linkage (DPRL). In addition, we develop a simple but effective strategy for releasing private synopses. Extensive experimental results show that our framework is superior to the existing methods in terms of efficiency.},
	language = {en},
	number = {3},
	urldate = {2022-10-05},
	journal = {ACM Trans. Priv. Secur.},
	author = {Rao, Fang-Yu and Cao, Jianneng and Bertino, Elisa and Kantarcioglu, Murat},
	month = jul,
	year = {2019},
	pages = {1--36},
	file = {Rao et al. - 2019 - Hybrid Private Record Linkage Separating Differen.pdf:/home/erosfabrici/Zotero/storage/KFAAW8XX/Rao et al. - 2019 - Hybrid Private Record Linkage Separating Differen.pdf:application/pdf},
}

@article{near_differential_2021,
	title = {Differential {Privacy} for {Databases}},
	volume = {11},
	issn = {1931-7883, 1931-7891},
	url = {http://www.nowpublishers.com/article/Details/DBS-066},
	doi = {10.1561/1900000066},
	abstract = {Differential privacy is a promising approach to formalizing privacy—that is, for writing down what privacy means as a mathematical equation. This book is provides overview of differential privacy techniques for answering database-style queries. Within this area, we describe useful algorithms and their applications, and systems and tools that implement them.},
	language = {en},
	number = {2},
	urldate = {2022-10-05},
	journal = {FNT in Databases},
	author = {Near, Joseph P. and He, Xi},
	year = {2021},
	pages = {109--225},
	file = {Near and He - 2021 - Differential Privacy for Databases.pdf:/home/erosfabrici/Zotero/storage/A8D7JIDE/Near and He - 2021 - Differential Privacy for Databases.pdf:application/pdf},
}

@article{bater_saqe_2020,
	title = {{SAQE}: practical privacy-preserving approximate query processing for data federations},
	volume = {13},
	issn = {2150-8097},
	shorttitle = {{SAQE}},
	url = {https://dl.acm.org/doi/10.14778/3407790.3407854},
	doi = {10.14778/3407790.3407854},
	abstract = {A private data federation enables clients to query the union of data from multiple data providers without revealing any extra private information to the client or any other data providers. Unfortunately, this strong end-to-end privacy guarantee requires cryptographic protocols that incur a signiﬁcant performance overhead as high as 1,000× compared to executing the same query in the clear. As a result, private data federations are impractical for common database workloads. This gap reveals the following key challenge in a private data federation: offering signiﬁcantly fast and accurate query answers without compromising strong end-to-end privacy.},
	language = {en},
	number = {12},
	urldate = {2022-10-05},
	journal = {Proc. VLDB Endow.},
	author = {Bater, Johes and Park, Yongjoo and He, Xi and Wang, Xiao and Rogers, Jennie},
	month = aug,
	year = {2020},
	pages = {2691--2705},
	file = {Bater et al. - 2020 - SAQE practical privacy-preserving approximate que.pdf:/home/erosfabrici/Zotero/storage/RSTVEUIB/Bater et al. - 2020 - SAQE practical privacy-preserving approximate que.pdf:application/pdf},
}

@article{simonini_blast_2016,
	title = {{BLAST}: a loosely schema-aware meta-blocking approach for entity resolution},
	volume = {9},
	issn = {2150-8097},
	shorttitle = {{BLAST}},
	url = {https://dl.acm.org/doi/10.14778/2994509.2994533},
	doi = {10.14778/2994509.2994533},
	abstract = {Identifying records that refer to the same entity is a fundamental step for data integration. Since it is prohibitively expensive to compare every pair of records, blocking techniques are typically employed to reduce the complexity of this task. These techniques partition records into blocks and limit the comparison to records co-occurring in a block. Generally, to deal with highly heterogeneous and noisy data (e.g. semi-structured data of the Web), these techniques rely on redundancy to reduce the chance of missing matches.},
	language = {en},
	number = {12},
	urldate = {2022-10-08},
	journal = {Proc. VLDB Endow.},
	author = {Simonini, Giovanni and Bergamaschi, Sonia and Jagadish, H. V.},
	month = aug,
	year = {2016},
	pages = {1173--1184},
	file = {Simonini et al. - 2016 - BLAST a loosely schema-aware meta-blocking approa.pdf:/home/erosfabrici/Zotero/storage/GHEGTJAA/Simonini et al. - 2016 - BLAST a loosely schema-aware meta-blocking approa.pdf:application/pdf},
}

@inproceedings{wu_zeroer_2020,
	address = {Portland OR USA},
	title = {{ZeroER}: {Entity} {Resolution} using {Zero} {Labeled} {Examples}},
	isbn = {978-1-4503-6735-6},
	shorttitle = {{ZeroER}},
	url = {https://dl.acm.org/doi/10.1145/3318464.3389743},
	doi = {10.1145/3318464.3389743},
	abstract = {Entity resolution (ER) refers to the problem of matching records in one or more relations that refer to the same realworld entity. While supervised machine learning (ML) approaches achieve the state-of-the-art results, they require a large amount of labeled examples that are expensive to obtain and often times infeasible. We investigate an important problem that vexes practitioners: is it possible to design an effective algorithm for ER that requires Zero labeled examples, yet can achieve performance comparable to supervised approaches? In this paper, we answer in the affirmative through our proposed approach dubbed ZeroER. Our approach is based on a simple observation — the similarity vectors for matches should look different from that of unmatches. Operationalizing this insight requires a number of technical innovations. First, we propose a simple yet powerful generative model based on Gaussian Mixture Models for learning the match and unmatch distributions. Second, we propose an adaptive regularization technique customized for ER that ameliorates the issue of feature overfitting. Finally, we incorporate the transitivity property into the generative model in a novel way resulting in improved accuracy. On five benchmark ER datasets, we show that ZeroER greatly outperforms existing unsupervised approaches and achieves comparable performance to supervised approaches.},
	language = {en},
	urldate = {2022-10-09},
	booktitle = {Proceedings of the 2020 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Wu, Renzhi and Chaba, Sanya and Sawlani, Saurabh and Chu, Xu and Thirumuruganathan, Saravanan},
	month = jun,
	year = {2020},
	pages = {1149--1164},
	file = {Wu et al. - 2020 - ZeroER Entity Resolution using Zero Labeled Examp.pdf:/home/erosfabrici/Zotero/storage/5L8U2XDS/Wu et al. - 2020 - ZeroER Entity Resolution using Zero Labeled Examp.pdf:application/pdf},
}

@inproceedings{wu_zeroer_2020-1,
	address = {Portland OR USA},
	title = {{ZeroER}: {Entity} {Resolution} using {Zero} {Labeled} {Examples}},
	isbn = {978-1-4503-6735-6},
	shorttitle = {{ZeroER}},
	url = {https://dl.acm.org/doi/10.1145/3318464.3389743},
	doi = {10.1145/3318464.3389743},
	abstract = {Entity resolution (ER) refers to the problem of matching records in one or more relations that refer to the same realworld entity. While supervised machine learning (ML) approaches achieve the state-of-the-art results, they require a large amount of labeled examples that are expensive to obtain and often times infeasible. We investigate an important problem that vexes practitioners: is it possible to design an effective algorithm for ER that requires Zero labeled examples, yet can achieve performance comparable to supervised approaches? In this paper, we answer in the affirmative through our proposed approach dubbed ZeroER. Our approach is based on a simple observation — the similarity vectors for matches should look different from that of unmatches. Operationalizing this insight requires a number of technical innovations. First, we propose a simple yet powerful generative model based on Gaussian Mixture Models for learning the match and unmatch distributions. Second, we propose an adaptive regularization technique customized for ER that ameliorates the issue of feature overfitting. Finally, we incorporate the transitivity property into the generative model in a novel way resulting in improved accuracy. On five benchmark ER datasets, we show that ZeroER greatly outperforms existing unsupervised approaches and achieves comparable performance to supervised approaches.},
	language = {en},
	urldate = {2022-10-09},
	booktitle = {Proceedings of the 2020 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Wu, Renzhi and Chaba, Sanya and Sawlani, Saurabh and Chu, Xu and Thirumuruganathan, Saravanan},
	month = jun,
	year = {2020},
	pages = {1149--1164},
	file = {Wu et al. - 2020 - ZeroER Entity Resolution using Zero Labeled Examp.pdf:/home/erosfabrici/Zotero/storage/Z6TULATS/Wu et al. - 2020 - ZeroER Entity Resolution using Zero Labeled Examp.pdf:application/pdf},
}

@inproceedings{qinl_synthesizing_2022,
	address = {Kuala Lumpur, Malaysia},
	title = {Synthesizing {Privacy} {Preserving} {Entity} {Resolution} {Datasets}},
	isbn = {978-1-66540-883-7},
	url = {https://ieeexplore.ieee.org/document/9835693/},
	doi = {10.1109/ICDE53745.2022.00222},
	abstract = {Entity resolution (ER) is a core problem in data integration. Many companies have lots of datasets where ER needs to be conducted to integrate the data. On the one hand, it is nontrivial for non-ER experts within companies to design ER solutions. On the other hand, most companies are reluctant to release their real datasets for multiple reasons (e.g., privacy issues). A typical solution from the machine learning (ML) and the statistical community is to create surrogate (a.k.a. analogous) datasets based on the real dataset, release these surrogate datasets to the public to train ML models, such that these models trained on surrogate datasets can be either directly used or be adapted for the real dataset by the companies.},
	language = {en},
	urldate = {2022-10-09},
	booktitle = {2022 {IEEE} 38th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Qinl, Xuedi and Chai, Chengliang and Tang, Nan and Li, Jian and Luo, Yuyu and Li, Guoliang and Zhu, Yaoyu},
	month = may,
	year = {2022},
	pages = {2359--2371},
	file = {Qinl et al. - 2022 - Synthesizing Privacy Preserving Entity Resolution .pdf:/home/erosfabrici/Zotero/storage/I2A8ETE4/Qinl et al. - 2022 - Synthesizing Privacy Preserving Entity Resolution .pdf:application/pdf},
}

@inproceedings{dong_data_2018,
	address = {Houston TX USA},
	title = {Data {Integration} and {Machine} {Learning}: {A} {Natural} {Synergy}},
	isbn = {978-1-4503-4703-7},
	shorttitle = {Data {Integration} and {Machine} {Learning}},
	url = {https://dl.acm.org/doi/10.1145/3183713.3197387},
	doi = {10.1145/3183713.3197387},
	abstract = {There is now more data to analyze than ever before. As data volume and variety have increased, so have the ties between machine learning and data integration become stronger. For machine learning to be effective, one must utilize data from the greatest possible variety of sources; and this is why data integration plays a key role. At the same time machine learning is driving automation in data integration, resulting in overall reduction of integration costs and improved accuracy. This tutorial focuses on three aspects of the synergistic relationship between data integration and machine learning: (1) we survey how state-of-the-art data integration solutions rely on machine learning-based approaches for accurate results and effective human-in-the-loop pipelines, (2) we review how end-to-end machine learning applications rely on data integration to identify accurate, clean, and relevant data for their analytics exercises, and (3) we discuss open research challenges and opportunities that span across data integration and machine learning.},
	language = {en},
	urldate = {2022-10-09},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Dong, Xin Luna and Rekatsinas, Theodoros},
	month = may,
	year = {2018},
	pages = {1645--1650},
	file = {Dong and Rekatsinas - 2018 - Data Integration and Machine Learning A Natural S.pdf:/home/erosfabrici/Zotero/storage/8JXFADA4/Dong and Rekatsinas - 2018 - Data Integration and Machine Learning A Natural S.pdf:application/pdf},
}

@article{deeper_2018,
author = {Ebraheem, Muhammad and Thirumuruganathan, Saravanan and Joty, Shafiq and Ouzzani, Mourad and Tang, Nan},
title = {Distributed Representations of Tuples for Entity Resolution},
year = {2018},
issue_date = {July 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3236187.3236198},
doi = {10.14778/3236187.3236198},
abstract = {Despite the efforts in 70+ years in all aspects of entity resolution (ER), there is still a high demand for democratizing ER - by reducing the heavy human involvement in labeling data, performing feature engineering, tuning parameters, and defining blocking functions. With the recent advances in deep learning, in particular distributed representations of words (a.k.a. word embeddings), we present a novel ER system, called DeepER, that achieves good accuracy, high efficiency, as well as ease-of-use (i.e., much less human efforts). We use sophisticated composition methods, namely uni- and bi-directional recurrent neural networks (RNNs) with long short term memory (LSTM) hidden units, to convert each tuple to a distributed representation (i.e., a vector), which can in turn be used to effectively capture similarities between tuples. We consider both the case where pre-trained word embeddings are available as well the case where they are not; we present ways to learn and tune the distributed representations that are customized for a specific ER task under different scenarios. We propose a locality sensitive hashing (LSH) based blocking approach that takes all attributes of a tuple into consideration and produces much smaller blocks, compared with traditional methods that consider only a few attributes. We evaluate our algorithms on multiple datasets (including benchmarks, biomedical data, as well as multi-lingual data) and the extensive experimental results show that DeepER outperforms existing solutions.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1454–1467},
numpages = {14}
}

@misc{he_composing_2017,
	title = {Composing {Differential} {Privacy} and {Secure} {Computation}: {A} case study on scaling private record linkage},
	shorttitle = {Composing {Differential} {Privacy} and {Secure} {Computation}},
	url = {http://arxiv.org/abs/1702.00535},
	abstract = {Private record linkage (PRL) is the problem of identifying pairs of records that are similar as per an input matching rule from databases held by two parties that do not trust one another. We identify three key desiderata that a PRL solution must ensure: (1) perfect precision and high recall of matching pairs, (2) a proof of end-to-end privacy, and (3) communication and computational costs that scale subquadratically in the number of input records. We show that all of the existing solutions for PRL– including secure 2-party computation (S2PC), and their variants that use non-private or di erentially private (DP) blocking to ensure subquadratic cost – violate at least one of the three desiderata. In particular, S2PC techniques guarantee end-to-end privacy but have either low recall or quadratic cost. In contrast, no end-to-end privacy guarantee has been formalized for solutions that achieve subquadratic cost. is is true even for solutions that compose DP and S2PC: DP does not permit the release of any exact information about the databases, while S2PC algorithms for PRL allow the release of matching records.},
	language = {en},
	urldate = {2022-10-10},
	publisher = {arXiv},
	author = {He, Xi and Machanavajjhala, Ashwin and Flynn, Cheryl and Srivastava, Divesh},
	month = sep,
	year = {2017},
	note = {arXiv:1702.00535 [cs]},
	keywords = {Computer Science - Databases, Computer Science - Cryptography and Security},
	file = {He et al. - 2017 - Composing Differential Privacy and Secure Computat.pdf:/home/erosfabrici/Zotero/storage/66JUSQEV/He et al. - 2017 - Composing Differential Privacy and Secure Computat.pdf:application/pdf},
}

@article{nadal_graph-driven_2021,
	title = {Graph-driven {Federated} {Data} {Management}},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/9422168/},
	doi = {10.1109/TKDE.2021.3077044},
	abstract = {Modern data analysis applications, require the ability to provide on-demand integration of data sources while offering a ﬂexible and user-friendly query interface. Traditional techniques for answering queries using views, focused on a rather static setting, fail to address such requirements. To overcome these issues, we propose a fully-ﬂedged data integration approach based on graphbased constructs. The extensibility of graphs allows us to extend the traditional framework for data integration with view deﬁnitions. Furthermore, we also propose a query language based on subgraphs. We tackle query answering via a query rewriting algorithm based on well-known algorithms for answering queries using views. We experimentally show that the proposed method yields good performance and does not introduce a signiﬁcant overhead.},
	language = {en},
	urldate = {2022-10-10},
	journal = {IEEE Trans. Knowl. Data Eng.},
	author = {Nadal, Sergi and Abello, Alberto and Romero, Oscar and Vansummeren, Stijn and Vassiliadis, Panos},
	year = {2021},
	pages = {1--1},
	file = {Nadal et al. - 2021 - Graph-driven Federated Data Management.pdf:/home/erosfabrici/Zotero/storage/IJJ3CTDV/Nadal et al. - 2021 - Graph-driven Federated Data Management.pdf:application/pdf},
}

@incollection{christen_future_2020,
	address = {Cham},
	title = {Future {Research} {Challenges} and {Directions}},
	isbn = {978-3-030-59705-4 978-3-030-59706-1},
	url = {http://link.springer.com/10.1007/978-3-030-59706-1_14},
	language = {en},
	urldate = {2022-10-10},
	booktitle = {Linking {Sensitive} {Data}},
	publisher = {Springer International Publishing},
	author = {Christen, Peter and Ranbaduge, Thilina and Schnell, Rainer},
	collaborator = {Christen, Peter and Ranbaduge, Thilina and Schnell, Rainer},
	year = {2020},
	doi = {10.1007/978-3-030-59706-1_14},
	pages = {361--375},
	file = {Christen et al. - 2020 - Future Research Challenges and Directions.pdf:/home/erosfabrici/Zotero/storage/R2XWWWCD/Christen et al. - 2020 - Future Research Challenges and Directions.pdf:application/pdf},
}

@incollection{christen_future_2020-1,
	address = {Cham},
	title = {Future {Research} {Challenges} and {Directions}},
	isbn = {978-3-030-59705-4 978-3-030-59706-1},
	url = {http://link.springer.com/10.1007/978-3-030-59706-1_14},
	language = {en},
	urldate = {2022-10-11},
	booktitle = {Linking {Sensitive} {Data}},
	publisher = {Springer International Publishing},
	author = {Christen, Peter and Ranbaduge, Thilina and Schnell, Rainer},
	collaborator = {Christen, Peter and Ranbaduge, Thilina and Schnell, Rainer},
	year = {2020},
	doi = {10.1007/978-3-030-59706-1_14},
	pages = {361--375},
	file = {Christen et al. - 2020 - Future Research Challenges and Directions.pdf:/home/erosfabrici/Zotero/storage/PTX3BAXL/Christen et al. - 2020 - Future Research Challenges and Directions.pdf:application/pdf},
}

@book{flesca_comprehensive_2018,
	address = {Cham},
	series = {Studies in {Big} {Data}},
	title = {A {Comprehensive} {Guide} {Through} the {Italian} {Database} {Research} {Over} the {Last} 25 {Years}},
	volume = {31},
	isbn = {978-3-319-61892-0 978-3-319-61893-7},
	url = {http://link.springer.com/10.1007/978-3-319-61893-7},
	language = {en},
	urldate = {2022-10-11},
	publisher = {Springer International Publishing},
	editor = {Flesca, Sergio and Greco, Sergio and Masciari, Elio and Saccà, Domenico},
	year = {2018},
	doi = {10.1007/978-3-319-61893-7},
	file = {Flesca et al. - 2018 - A Comprehensive Guide Through the Italian Database.pdf:/home/erosfabrici/Zotero/storage/CEHRJ7T6/Flesca et al. - 2018 - A Comprehensive Guide Through the Italian Database.pdf:application/pdf},
}

@book{flesca_comprehensive_2018-1,
	address = {Cham},
	series = {Studies in {Big} {Data}},
	title = {A {Comprehensive} {Guide} {Through} the {Italian} {Database} {Research} {Over} the {Last} 25 {Years}},
	volume = {31},
	isbn = {978-3-319-61892-0 978-3-319-61893-7},
	url = {http://link.springer.com/10.1007/978-3-319-61893-7},
	language = {en},
	urldate = {2022-10-11},
	publisher = {Springer International Publishing},
	editor = {Flesca, Sergio and Greco, Sergio and Masciari, Elio and Saccà, Domenico},
	year = {2018},
	doi = {10.1007/978-3-319-61893-7},
	file = {Flesca et al. - 2018 - A Comprehensive Guide Through the Italian Database.pdf:/home/erosfabrici/Zotero/storage/G3YAJCYN/Flesca et al. - 2018 - A Comprehensive Guide Through the Italian Database.pdf:application/pdf},
}

@book{renz_database_2015,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Database {Systems} for {Advanced} {Applications}: 20th {International} {Conference}, {DASFAA} 2015, {Hanoi}, {Vietnam}, {April} 20-23, 2015, {Proceedings}, {Part} {II}},
	volume = {9050},
	isbn = {978-3-319-18122-6 978-3-319-18123-3},
	shorttitle = {Database {Systems} for {Advanced} {Applications}},
	url = {http://link.springer.com/10.1007/978-3-319-18123-3},
	language = {en},
	urldate = {2022-10-11},
	publisher = {Springer International Publishing},
	editor = {Renz, Matthias and Shahabi, Cyrus and Zhou, Xiaofang and Cheema, Muhammad Aamir},
	year = {2015},
	doi = {10.1007/978-3-319-18123-3},
	file = {Renz et al. - 2015 - Database Systems for Advanced Applications 20th I.pdf:/home/erosfabrici/Zotero/storage/C3P7JCGQ/Renz et al. - 2015 - Database Systems for Advanced Applications 20th I.pdf:application/pdf},
}

@article{dasu_mining_nodate,
	title = {Mining {Database} {Structure}; {Or}, {How} to {Build} a {Data} {Quality} {Browser}},
	abstract = {Data mining research typically assumes that the data to be analyzed has been identified, gathered, cleaned, and processed into a convenient form. While data mining tools greatly enhance the ability of the analyst to make datadriven discoveries, most of the time spent in performing an analysis is spent in data identification, gathering, cleaning and processing the data. Similarly, schema mapping tools have been developed to help automate the task of using legacy or federated data sources for a new purpose, but assume that the structure of the data sources is well understood. However the data sets to be federated may come from dozens of databases containing thousands of tables and tens of thousands of fields, with little reliable documentation about primary keys or foreign keys. We are developing a system, Bellman, which performs data mining on the structure of the database. In this paper, we present techniques for quickly identifying which fields have similar values, identifying join paths, estimating join directions and sizes, and identifyingstructures in the database. The results of the database structure mining allow the analyst to make sense of the database content. This information can be used to e.g., prepare data for data mining, find foreign key joins for schema mapping, or identify steps to be taken to prevent the database from collapsing under the weight of its complexity.},
	language = {en},
	author = {Dasu, Tamraparni and Johnson, Theodore and Muthukrishnan, S and Shkapenyuk, Vladislav and Labs-Research, T},
	pages = {12},
	file = {Dasu et al. - Mining Database Structure\; Or, How to Build a Data.pdf:/home/erosfabrici/Zotero/storage/4H6BCA6E/Dasu et al. - Mining Database Structure\; Or, How to Build a Data.pdf:application/pdf},
}

@inproceedings{cormode_differentially_2012,
	address = {Berlin, Germany},
	title = {Differentially private summaries for sparse data},
	isbn = {978-1-4503-0791-8},
	url = {http://dl.acm.org/citation.cfm?doid=2274576.2274608},
	doi = {10.1145/2274576.2274608},
	abstract = {Differential privacy is fast becoming the method of choice for releasing data under strong privacy guarantees. A standard mechanism is to add noise to the counts in contingency tables derived from the dataset. However, when the dataset is sparse in its underlying domain, this vastly increases the size of the published data, to the point of making the mechanism infeasible.},
	language = {en},
	urldate = {2022-10-11},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Database} {Theory} - {ICDT} '12},
	publisher = {ACM Press},
	author = {Cormode, Graham and Procopiuc, Cecilia and Srivastava, Divesh and Tran, Thanh T. L.},
	year = {2012},
	pages = {299},
	file = {Cormode et al. - 2012 - Differentially private summaries for sparse data.pdf:/home/erosfabrici/Zotero/storage/HSP8QNNS/Cormode et al. - 2012 - Differentially private summaries for sparse data.pdf:application/pdf},
}

@article{abedjan_profiling_2015,
	title = {Profiling relational data: a survey},
	volume = {24},
	issn = {1066-8888, 0949-877X},
	shorttitle = {Profiling relational data},
	url = {http://link.springer.com/10.1007/s00778-015-0389-y},
	doi = {10.1007/s00778-015-0389-y},
	abstract = {Proﬁling data to determine metadata about a given dataset is an important and frequent activity of any IT professional and researcher and is necessary for various use-cases. It encompasses a vast array of methods to examine datasets and produce metadata. Among the simpler results are statistics, such as the number of null values and distinct values in a column, its data type, or the most frequent patterns of its data values. Metadata that are more difﬁcult to compute involve multiple columns, namely correlations, unique column combinations, functional dependencies, and inclusion dependencies. Further techniques detect conditional properties of the dataset at hand. This survey provides a classiﬁcation of data proﬁling tasks and comprehensively reviews the state of the art for each class. In addition, we review data proﬁling tools and systems from research and industry. We conclude with an outlook on the future of data proﬁling beyond traditional proﬁling tasks and beyond relational databases.},
	language = {en},
	number = {4},
	urldate = {2022-10-11},
	journal = {The VLDB Journal},
	author = {Abedjan, Ziawasch and Golab, Lukasz and Naumann, Felix},
	month = aug,
	year = {2015},
	pages = {557--581},
	file = {Abedjan et al. - 2015 - Profiling relational data a survey.pdf:/home/erosfabrici/Zotero/storage/L4ZMIRIQ/Abedjan et al. - 2015 - Profiling relational data a survey.pdf:application/pdf},
}

@misc{karapiperis_summarization_2018,
	title = {Summarization {Algorithms} for {Record} {Linkage}},
	url = {https://openproceedings.org/2018/conf/edbt/paper-29.pdf},
	abstract = {Record linkage has received significant attention in recent years due to the plethora of data sources that have to be integrated to facilitate data analyses. In several cases, such an integration involves disparate data sources containing huge volumes of records and must be performed in near real-time in order to support critical applications. In this paper, we propose the first summarization algorithms for speeding up online record linkage tasks. Our first method, called SkipBloom, summarizes efficiently the participating data sets, using their blocking keys, to allow for very fast comparisons among them. The second method, called BlockSketch, summarizes a block to achieve a constant number of comparisons for a submitted query record, during the matching phase. Additionally, we extend BlockSketch to adapt its functionality to streaming data, where the objective is to use a constant amount of main memory to handle potentially unbounded data sets. Through extensive experimental evaluation, using three real-world data sets, we demonstrate the superiority of our methods against two state-of-the-art algorithms for online record linkage.},
	language = {en},
	urldate = {2022-10-12},
	publisher = {OpenProceedings.org},
	author = {Karapiperis, Dimitrios and Gkoulalas-Divanis, Aris and Verykios, Vassilios S.},
	year = {2018},
	doi = {10.5441/002/EDBT.2018.08},
	note = {Type: dataset},
	keywords = {Database Technology},
	file = {Karapiperis et al. - 2018 - Summarization Algorithms for Record Linkage.pdf:/home/erosfabrici/Zotero/storage/CD4ZQLD9/Karapiperis et al. - 2018 - Summarization Algorithms for Record Linkage.pdf:application/pdf},
}

@article{papadakis_blocking_2021,
	title = {Blocking and {Filtering} {Techniques} for {Entity} {Resolution}: {A} {Survey}},
	volume = {53},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Blocking and {Filtering} {Techniques} for {Entity} {Resolution}},
	url = {https://dl.acm.org/doi/10.1145/3377455},
	doi = {10.1145/3377455},
	abstract = {Entity Resolution (ER), a core task of Data Integration, detects different entity profiles that correspond to the same real-world object. Due to its inherently quadratic complexity, a series of techniques accelerate it so that it scales to voluminous data. In this survey, we review a large number of relevant works under two different but related frameworks: Blocking and Filtering. The former restricts comparisons to entity pairs that are more likely to match, while the latter identifies quickly entity pairs that are likely to satisfy predetermined similarity thresholds. We also elaborate on hybrid approaches that combine different characteristics. For each framework we provide a comprehensive list of the relevant works, discussing them in the greater context. We conclude with the most promising directions for future work in the field.},
	language = {en},
	number = {2},
	urldate = {2022-10-13},
	journal = {ACM Comput. Surv.},
	author = {Papadakis, George and Skoutas, Dimitrios and Thanos, Emmanouil and Palpanas, Themis},
	month = mar,
	year = {2021},
	pages = {1--42},
	file = {Papadakis et al. - 2021 - Blocking and Filtering Techniques for Entity Resol.pdf:/home/erosfabrici/Zotero/storage/4ERYJBRH/Papadakis et al. - 2021 - Blocking and Filtering Techniques for Entity Resol.pdf:application/pdf},
}

@article{christophides_overview_2021,
	title = {An {Overview} of {End}-to-{End} {Entity} {Resolution} for {Big} {Data}},
	volume = {53},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3418896},
	doi = {10.1145/3418896},
	abstract = {One of the most critical tasks for improving data quality and increasing the reliability of data analytics is
              Entity Resolution
              (ER), which aims to identify different descriptions that refer to the same real-world entity. Despite several decades of research, ER remains a challenging problem. In this survey, we highlight the novel aspects of resolving Big Data entities when we should satisfy more than one of the Big Data characteristics simultaneously (i.e., Volume and Velocity with Variety). We present the basic concepts, processing steps, and execution strategies that have been proposed by database, semantic Web, and machine learning communities in order to cope with the loose
              structuredness
              , extreme
              diversity
              , high
              speed,
              and large
              scale
              of entity descriptions used by real-world applications. We provide an end-to-end view of ER workflows for Big Data, critically review the pros and cons of existing methods, and conclude with the main open research directions.},
	language = {en},
	number = {6},
	urldate = {2022-10-13},
	journal = {ACM Comput. Surv.},
	author = {Christophides, Vassilis and Efthymiou, Vasilis and Palpanas, Themis and Papadakis, George and Stefanidis, Kostas},
	month = nov,
	year = {2021},
	pages = {1--42},
	file = {Christophides et al. - 2021 - An Overview of End-to-End Entity Resolution for Bi.pdf:/home/erosfabrici/Zotero/storage/HTGQL3RT/Christophides et al. - 2021 - An Overview of End-to-End Entity Resolution for Bi.pdf:application/pdf},
}

@misc{hardy_private_2017,
	title = {Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption},
	url = {http://arxiv.org/abs/1711.10677},
	abstract = {Consider two data providers, each maintaining private records of different feature sets about common entities. They aim to learn a linear model jointly in a federated setting, namely, data is local and a shared model is trained from locally computed updates. In contrast with most work on distributed learning, in this scenario (i) data is split vertically, i.e. by features, (ii) only one data provider knows the target variable and (iii) entities are not linked across the data providers. Hence, to the challenge of private learning, we add the potentially negative consequences of mistakes in entity resolution. Our contribution is twofold. First, we describe a three-party end-to-end solution in two phases—privacy-preserving entity resolution and federated logistic regression over messages encrypted with an additively homomorphic scheme—, secure against a honest-but-curious adversary. The system allows learning without either exposing data in the clear or sharing which entities the data providers have in common. Our implementation is as accurate as a naive non-private solution that brings all data in one place, and scales to problems with millions of entities with hundreds of features. Second, we provide what is to our knowledge the ﬁrst formal analysis of the impact of entity resolution’s mistakes on learning, with results on how optimal classiﬁers, empirical losses, margins and generalisation abilities are affected. Our results bring a clear and strong support for federated learning: under reasonable assumptions on the number and magnitude of entity resolution’s mistakes, it can be extremely beneﬁcial to carry out federated learning in the setting where each peer’s data provides a signiﬁcant uplift to the other.},
	language = {en},
	urldate = {2022-10-13},
	publisher = {arXiv},
	author = {Hardy, Stephen and Henecka, Wilko and Ivey-Law, Hamish and Nock, Richard and Patrini, Giorgio and Smith, Guillaume and Thorne, Brian},
	month = nov,
	year = {2017},
	note = {arXiv:1711.10677 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Hardy et al. - 2017 - Private federated learning on vertically partition.pdf:/home/erosfabrici/Zotero/storage/44S3PAZD/Hardy et al. - 2017 - Private federated learning on vertically partition.pdf:application/pdf},
}

@article{firmani_online_2016,
	title = {Online entity resolution using an {Oracle}},
	volume = {9},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/2876473.2876474},
	doi = {10.14778/2876473.2876474},
	abstract = {Entity resolution (ER) is the task of identifying all records in a database that refer to the same underlying entity. This is an expensive task, and can take a signiﬁcant amount of money and time; the end-user may want to take decisions during the process, rather than waiting for the task to be completed. We formalize an online version of the entity resolution task, and use an oracle which correctly labels matching and non-matching pairs through queries. In this setting, we design algorithms that seek to maximize progressive recall, and develop a novel analysis framework for prior proposals on entity resolution with an oracle, beyond their worst case guarantees. Finally, we provide both theoretical and experimental analysis of the proposed algorithms.},
	language = {en},
	number = {5},
	urldate = {2022-10-14},
	journal = {Proc. VLDB Endow.},
	author = {Firmani, Donatella and Saha, Barna and Srivastava, Divesh},
	month = jan,
	year = {2016},
	pages = {384--395},
	file = {Firmani et al. - 2016 - Online entity resolution using an Oracle.pdf:/home/erosfabrici/Zotero/storage/BHEXYLGG/Firmani et al. - 2016 - Online entity resolution using an Oracle.pdf:application/pdf},
}

@article{groce_cheaper_2019,
	title = {Cheaper {Private} {Set} {Intersection} via {Differentially} {Private} {Leakage}},
	volume = {2019},
	issn = {2299-0984},
	url = {https://petsymposium.org/popets/2019/popets-2019-0034.php},
	doi = {10.2478/popets-2019-0034},
	abstract = {Abstract
            In this work we demonstrate that allowing differentially private leakage can significantly improve the concrete performance of secure 2-party computation (2PC) protocols. Specifically, we focus on the private set intersection (PSI) protocol of Rindal and Rosulek (CCS 2017), which is the fastest PSI protocol with security against malicious participants. We show that if differentially private leakage is allowed, the cost of the protocol can be reduced by up to 63\%, depending on the desired level of differential privacy. On the technical side, we introduce a security model for differentially-private leakage in malicious-secure 2PC. We also introduce two new and improved mechanisms for “differentially private histogram overestimates,” the main technical challenge for differentially-private PSI.},
	language = {en},
	number = {3},
	urldate = {2022-10-18},
	journal = {Proceedings on Privacy Enhancing Technologies},
	author = {Groce, Adam and Rindal, Peter and Rosulek, Mike},
	month = jul,
	year = {2019},
	pages = {6--25},
	file = {Groce et al. - 2019 - Cheaper Private Set Intersection via Differentiall.pdf:/home/erosfabrici/Zotero/storage/6FF9JH46/Groce et al. - 2019 - Cheaper Private Set Intersection via Differentiall.pdf:application/pdf},
}

@misc{bater_shrinkwrap_2018,
	title = {Shrinkwrap: {Differentially}-{Private} {Query} {Processing} in {Private} {Data} {Federations}},
	shorttitle = {Shrinkwrap},
	url = {http://arxiv.org/abs/1810.01816},
	abstract = {A private data federation is a set of autonomous databases that share a uniﬁed query interface oﬀering in-situ evaluation of SQL queries over the union of the sensitive data of its members. Owing to privacy concerns, these systems do not have a trusted data collector that can see all their data and their member databases cannot learn about individual records of other engines. Federations currently achieve this goal by evaluating queries obliviously using secure multiparty computation. This hides the intermediate result cardinality of each query operator by exhaustively padding it. With cascades of such operators, this padding accumulates to a blow-up in the output size of each operator and a proportional loss in query performance. Hence, existing private data federations do not scale well to complex SQL queries over large datasets.},
	language = {en},
	urldate = {2022-10-18},
	publisher = {arXiv},
	author = {Bater, Johes and He, Xi and Ehrich, William and Machanavajjhala, Ashwin and Rogers, Jennie},
	month = oct,
	year = {2018},
	note = {arXiv:1810.01816 [cs]},
	keywords = {Computer Science - Databases},
	file = {Bater et al. - 2018 - Shrinkwrap Differentially-Private Query Processin.pdf:/home/erosfabrici/Zotero/storage/WKLZYCWN/Bater et al. - 2018 - Shrinkwrap Differentially-Private Query Processin.pdf:application/pdf},
}

@article{choi_di_nodate,
	title = {Di erentially-{Private} {Multi}-{Party} {Sketching} for {Large}-{Scale} {Statistics}},
	abstract = {We consider a scenario where multiple organizations holding large amounts of sensitive data from their users wish to compute aggregate statistics on this data while protecting the privacy of individual users. To support large-scale analytics we investigate how this privacy can be provided for the case of sketching algorithms running in time sub-linear of the input size.},
	language = {en},
	author = {Choi, Seung Geol and Dachman-Soled, Dana and Kulkarni, Mukul and Yerukhimovich, Arkady},
	pages = {34},
	file = {Choi et al. - Di erentially-Private Multi-Party Sketching for La.pdf:/home/erosfabrici/Zotero/storage/Z8YMPT3E/Choi et al. - Di erentially-Private Multi-Party Sketching for La.pdf:application/pdf},
}

@inproceedings{clifton_privacy-preserving_2004,
	address = {Paris, France},
	title = {Privacy-preserving data integration and sharing},
	isbn = {978-1-58113-908-2},
	url = {http://portal.acm.org/citation.cfm?doid=1008694.1008698},
	doi = {10.1145/1008694.1008698},
	language = {en},
	urldate = {2022-10-19},
	booktitle = {Proceedings of the 9th {ACM} {SIGMOD} workshop on {Research} issues in data mining and knowledge discovery  - {DMKD} '04},
	publisher = {ACM Press},
	author = {Clifton, Chris and Kantarcioǧlu, Murat and Doan, AnHai and Schadow, Gunther and Vaidya, Jaideep and Elmagarmid, Ahmed and Suciu, Dan},
	year = {2004},
	pages = {19},
	file = {Clifton et al. - 2004 - Privacy-preserving data integration and sharing.pdf:/home/erosfabrici/Zotero/storage/HYC7N8X6/Clifton et al. - 2004 - Privacy-preserving data integration and sharing.pdf:application/pdf},
}

@inproceedings{santos_sketch-based_2022,
	address = {Kuala Lumpur, Malaysia},
	title = {A {Sketch}-based {Index} for {Correlated} {Dataset} {Search}},
	isbn = {978-1-66540-883-7},
	url = {https://ieeexplore.ieee.org/document/9835690/},
	doi = {10.1109/ICDE53745.2022.00264},
	abstract = {Dataset search is emerging as a critical capability in both research and industry: it has spurred many novel applications, ranging from the enrichment of analyses of realworld phenomena to the improvement of machine learning models. Recent research in this ﬁeld has explored a new class of data-driven queries: queries consist of datasets and retrieve, from a large collection, related datasets. In this paper, we study a speciﬁc type of data-driven query that supports relational data augmentation through numerical data relationships: given an input query table, ﬁnd the top-k tables that are both joinable with it and contain columns that are correlated with a column in the query. We propose a novel hashing scheme that allows the construction of a sketch-based index to support efﬁcient correlated table search. We show that our proposed approach is effective and efﬁcient, and achieves better trade-offs that signiﬁcantly improve both the ranking accuracy and recall compared to the state-of-the-art solutions.},
	language = {en},
	urldate = {2022-10-21},
	booktitle = {2022 {IEEE} 38th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Santos, Aecio and Bessa, Aline and Musco, Christopher and Freire, Juliana},
	month = may,
	year = {2022},
	pages = {2928--2941},
	file = {Santos et al. - 2022 - A Sketch-based Index for Correlated Dataset Search.pdf:/home/erosfabrici/Zotero/storage/JG9BFQQF/Santos et al. - 2022 - A Sketch-based Index for Correlated Dataset Search.pdf:application/pdf},
}

@inproceedings{santos_correlation_2021,
	title = {Correlation {Sketches} for {Approximate} {Join}-{Correlation} {Queries}},
	url = {http://arxiv.org/abs/2104.03353},
	doi = {10.1145/3448016.3458456},
	abstract = {The increasing availability of structured datasets, from Web tables and open-data portals to enterprise data, opens up opportunities to enrich analytics and improve machine learning models through relational data augmentation. In this paper, we introduce a new class of data augmentation queries: join-correlation queries. Given a column 𝑄 and a join column 𝐾𝑄 from a query table T𝑄 , retrieve tables T𝑋 in a dataset collection such that T𝑋 is joinable with T𝑄 on 𝐾𝑄 and there is a column 𝐶 ∈ T𝑋 such that 𝑄 is correlated with 𝐶. A naïve approach to evaluate these queries, which first finds joinable tables and then explicitly joins and computes correlations between 𝑄 and all columns of the discovered tables, is prohibitively expensive. To efficiently support correlated column discovery, we 1) propose a sketching method that enables the construction of an index for a large number of tables and that provides accurate estimates for joincorrelation queries, and 2) explore different scoring strategies that effectively rank the query results based on how well the columns are correlated with the query. We carry out a detailed experimental evaluation, using both synthetic and real data, which shows that our sketches attain high accuracy and the scoring strategies lead to high-quality rankings.},
	language = {en},
	urldate = {2022-10-21},
	booktitle = {Proceedings of the 2021 {International} {Conference} on {Management} of {Data}},
	author = {Santos, Aécio and Bessa, Aline and Chirigati, Fernando and Musco, Christopher and Freire, Juliana},
	month = jun,
	year = {2021},
	note = {arXiv:2104.03353 [cs]},
	keywords = {Computer Science - Databases, Computer Science - Data Structures and Algorithms, Computer Science - Information Retrieval},
	pages = {1531--1544},
	file = {Santos et al. - 2021 - Correlation Sketches for Approximate Join-Correlat.pdf:/home/erosfabrici/Zotero/storage/HVLKB5G2/Santos et al. - 2021 - Correlation Sketches for Approximate Join-Correlat.pdf:application/pdf},
}

@article{benslimane_pairse_2013,
	title = {{PAIRSE}: a privacy-preserving service-oriented data integration system},
	volume = {42},
	issn = {0163-5808},
	shorttitle = {{PAIRSE}},
	url = {https://dl.acm.org/doi/10.1145/2536669.2536677},
	doi = {10.1145/2536669.2536677},
	abstract = {Privacy is among the key challenges to data integration in many sectors, including healthcare, e-government, etc. The PAIRSE project aims at providing a ﬂexible, looselycoupled and privacy-preserving data integration system in P2P environments. The project exploits recent Web standards and technologies such as Web services and ontologies to export data from autonomous data providers as reusable services, and proposes the use of service composition as a viable solution to answer data integration needs on the ﬂy. The project proposed new composition algorithms and service/composition execution models that preserve privacy of data manipulated by services and compositions. The proposed integration system was demonstrated at EDBT 2013 and VLDB 2011.},
	language = {en},
	number = {3},
	urldate = {2022-11-10},
	journal = {SIGMOD Rec.},
	author = {Benslimane, Djamal and Barhamgi, Mahmoud and Cuppens, Frederic and Morvan, Franck and Defude, Bruno and Nageba, Ebrahim and Mrissa, Michael and Paulus, Francois and Morucci, Stephane and Cuppens, Nora and Ghedira, Chirine and Mokadem, Riad and Oulmakhzoune, Said and Fayn, Jocelyne},
	month = oct,
	year = {2013},
	pages = {42--47},
	file = {Benslimane et al. - 2013 - PAIRSE a privacy-preserving service-oriented data.pdf:/home/erosfabrici/Zotero/storage/A5HX2HV4/Benslimane et al. - 2013 - PAIRSE a privacy-preserving service-oriented data.pdf:application/pdf},
}

@inproceedings{franke_parallel_2018,
	address = {Funchal, Madeira, Portugal},
	title = {Parallel {Privacy}-preserving {Record} {Linkage} using {LSH}-based {Blocking}:},
	isbn = {978-989-758-296-7},
	shorttitle = {Parallel {Privacy}-preserving {Record} {Linkage} using {LSH}-based {Blocking}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006682701950203},
	doi = {10.5220/0006682701950203},
	language = {en},
	urldate = {2022-11-10},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Internet} of {Things}, {Big} {Data} and {Security}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Franke, Martin and Sehili, Ziad and Rahm, Erhard},
	year = {2018},
	pages = {195--203},
	file = {Franke et al. - 2018 - Parallel Privacy-preserving Record Linkage using L.pdf:/home/erosfabrici/Zotero/storage/GQL2H736/Franke et al. - 2018 - Parallel Privacy-preserving Record Linkage using L.pdf:application/pdf},
}

@article{vatsalan_taxonomy_2013,
	title = {A taxonomy of privacy-preserving record linkage techniques},
	volume = {38},
	issn = {03064379},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306437912001470},
	doi = {10.1016/j.is.2012.11.005},
	abstract = {The process of identifying which records in two or more databases correspond to the same entity is an important aspect of data quality activities such as data pre-processing and data integration. Known as record linkage, data matching or entity resolution, this process has attracted interest from researchers in ﬁelds such as databases and data warehousing, data mining, information systems, and machine learning. Record linkage has various challenges, including scalability to large databases, accurate matching and classiﬁcation, and privacy and conﬁdentiality. The latter challenge arises because commonly personal identifying data, such as names, addresses and dates of birth of individuals, are used in the linkage process. When databases are linked across organizations, the issue of how to protect the privacy and conﬁdentiality of such sensitive information is crucial to successful application of record linkage.},
	language = {en},
	number = {6},
	urldate = {2022-11-09},
	journal = {Information Systems},
	author = {Vatsalan, Dinusha and Christen, Peter and Verykios, Vassilios S.},
	month = sep,
	year = {2013},
	pages = {946--969},
	file = {Vatsalan et al. - 2013 - A taxonomy of privacy-preserving record linkage te.pdf:/home/erosfabrici/Zotero/storage/PRLL47HX/Vatsalan et al. - 2013 - A taxonomy of privacy-preserving record linkage te.pdf:application/pdf},
}

@inproceedings{mullaymeri_two-party_2021,
	address = {Virtual Event Republic of Korea},
	title = {A two-party private string matching fuzzy vault scheme},
	isbn = {978-1-4503-8104-8},
	url = {https://dl.acm.org/doi/10.1145/3412841.3442079},
	doi = {10.1145/3412841.3442079},
	abstract = {A Fuzzy Vault is a cryptographic structure where a secret is being locked by a key and can be unlocked only by another key with significant overlap. In this paper, we introduce a two-party privacypreserving approximate string matching methodology based on a novel Fuzzy Vault scheme, combining the approximation and security properties of Fuzzy Vaults for privacy-preserving record linkage purposes.},
	language = {en},
	urldate = {2022-11-09},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Mullaymeri, Xhino and Karakasidis, Alexandros},
	month = mar,
	year = {2021},
	pages = {340--343},
	file = {Mullaymeri and Karakasidis - 2021 - A two-party private string matching fuzzy vault sc.pdf:/home/erosfabrici/Zotero/storage/EKFZK3M5/Mullaymeri and Karakasidis - 2021 - A two-party private string matching fuzzy vault sc.pdf:application/pdf},
}

@incollection{zomaya_privacy-preserving_2017,
	address = {Cham},
	title = {Privacy-{Preserving} {Record} {Linkage} for {Big} {Data}: {Current} {Approaches} and {Research} {Challenges}},
	isbn = {978-3-319-49339-8 978-3-319-49340-4},
	shorttitle = {Privacy-{Preserving} {Record} {Linkage} for {Big} {Data}},
	url = {http://link.springer.com/10.1007/978-3-319-49340-4_25},
	abstract = {The growth of Big Data, especially personal data dispersed in multiple data sources, presents enormous opportunities and insights for businesses to explore and leverage the value of linked and integrated data. However, privacy concerns impede sharing or exchanging data for linkage across diﬀerent organizations. Privacy-preserving record linkage (PPRL) aims to address this problem by identifying and linking records that correspond to the same real-world entity across several data sources held by diﬀerent parties without revealing any sensitive information about these entities. PPRL is increasingly being required in many realworld application areas. Examples range from public health surveillance to crime and fraud detection, and national security. PPRL for Big Data poses several challenges, with the three major ones being (1) scalability to multiple large databases, due to their massive volume and the ﬂow of data within Big Data applications, (2) achieving high quality results of the linkage in the presence of variety and veracity of Big Data, and (3) preserving privacy and conﬁdentiality of the entities represented in Big Data collections. In this chapter, we describe the challenges of PPRL in the context of Big Data, survey existing techniques for PPRL, and provide directions for future research.},
	language = {en},
	urldate = {2022-11-09},
	booktitle = {Handbook of {Big} {Data} {Technologies}},
	publisher = {Springer International Publishing},
	author = {Vatsalan, Dinusha and Sehili, Ziad and Christen, Peter and Rahm, Erhard},
	editor = {Zomaya, Albert Y. and Sakr, Sherif},
	year = {2017},
	doi = {10.1007/978-3-319-49340-4_25},
	pages = {851--895},
	file = {Vatsalan et al. - 2017 - Privacy-Preserving Record Linkage for Big Data Cu.pdf:/home/erosfabrici/Zotero/storage/YHCGZ2K7/Vatsalan et al. - 2017 - Privacy-Preserving Record Linkage for Big Data Cu.pdf:application/pdf},
}

@inproceedings{karakasidis_privacy_2009,
	address = {Thessaloniki, Greece},
	title = {Privacy {Preserving} {Record} {Linkage} {Using} {Phonetic} {Codes}},
	isbn = {978-0-7695-3783-2},
	url = {http://ieeexplore.ieee.org/document/5359317/},
	doi = {10.1109/BCI.2009.29},
	abstract = {Phonetic codes such as Soundex and Metaphone have been used in the past to address the Record Linkage Problem. However, to the best of our knowledge, no particular effort has been made within this context towards privacy assurance during the matching process. Phonetic codes have an interesting feature which can be cornerstone to providing privacy. They are mappings of strings which do not exhibit the one-to-one property.},
	language = {en},
	urldate = {2022-11-09},
	booktitle = {2009 {Fourth} {Balkan} {Conference} in {Informatics}},
	publisher = {IEEE},
	author = {Karakasidis, Alexandros and Verykios, Vassilios S.},
	year = {2009},
	pages = {101--106},
	file = {Karakasidis and Verykios - 2009 - Privacy Preserving Record Linkage Using Phonetic C.pdf:/home/erosfabrici/Zotero/storage/27DRK2QP/Karakasidis and Verykios - 2009 - Privacy Preserving Record Linkage Using Phonetic C.pdf:application/pdf},
}

@article{nock_impact_nodate,
	title = {The {Impact} of {Record} {Linkage} on {Learning} from {Feature} {Partitioned} {Data}},
	abstract = {There has been recently a signiﬁcant boost to machine learning with distributed data, in particular with the success of federated learning. A common and very challenging setting is that of vertical or feature partitioned data, when multiple data providers hold different features about common entities. In general, training needs to be preceded by record linkage (RL), a step that ﬁnds the correspondence between the observations of the datasets. RL is prone to mistakes in the real world. Despite the importance of the problem, there has been so far no formal assessment of the way in which RL errors impact learning models. Work in the area either use heuristics or assume that the optimal RL is known in advance. In this paper, we provide the ﬁrst assessment of the problem for supervised learning. For wide sets of losses, we provide technical conditions under which the classiﬁer learned after noisy RL converges (with the data size) to the best classiﬁer that would be learned from mistake-free RL. This yields new insights on the way the pipeline RL + ML operates, from the role of large margin classiﬁcation on dampening the impact of RL mistakes to clues on how to further optimize RL as a preprocessing step to ML. Experiments on a large UCI benchmark validate those formal observations.},
	language = {en},
	author = {Nock, Richard and Hardy, Stephen and Henecka, Wilko and Ivey-Law, Hamish and Nabaglo, Jakub and Patrini, Giorgio and Smith, Guillaume and Thorne, Brian},
	pages = {11},
	file = {Nock et al. - The Impact of Record Linkage on Learning from Feat.pdf:/home/erosfabrici/Zotero/storage/3T9GJGD5/Nock et al. - The Impact of Record Linkage on Learning from Feat.pdf:application/pdf},
}

@article{lee_privacy-preserving_2018,
	title = {Privacy-{Preserving} {Patient} {Similarity} {Learning} in a {Federated} {Environment}: {Development} and {Analysis}},
	volume = {6},
	issn = {2291-9694},
	shorttitle = {Privacy-{Preserving} {Patient} {Similarity} {Learning} in a {Federated} {Environment}},
	url = {http://medinform.jmir.org/2018/2/e20/},
	doi = {10.2196/medinform.7744},
	abstract = {Background: There is an urgent need for the development of global analytic frameworks that can perform analyses in a privacy-preserving federated environment across multiple institutions without privacy leakage. A few studies on the topic of federated medical analysis have been conducted recently with the focus on several algorithms. However, none of them have solved similar patient matching, which is useful for applications such as cohort construction for cross-institution observational studies, disease surveillance, and clinical trials recruitment.
Objective: The aim of this study was to present a privacy-preserving platform in a federated setting for patient similarity learning across institutions. Without sharing patient-level information, our model can find similar patients from one hospital to another.
Methods: We proposed a federated patient hashing framework and developed a novel algorithm to learn context-specific hash codes to represent patients across institutions. The similarities between patients can be efficiently computed using the resulting hash codes of corresponding patients. To avoid security attack from reverse engineering on the model, we applied homomorphic encryption to patient similarity search in a federated setting.
Results: We used sequential medical events extracted from the Multiparameter Intelligent Monitoring in Intensive Care-III database to evaluate the proposed algorithm in predicting the incidence of five diseases independently. Our algorithm achieved averaged area under the curves of 0.9154 and 0.8012 with balanced and imbalanced data, respectively, in κ-nearest neighbor with κ=3. We also confirmed privacy preservation in similarity search by using homomorphic encryption.
Conclusions: The proposed algorithm can help search similar patients across institutions effectively to support federated data analysis in a privacy-preserving manner.},
	language = {en},
	number = {2},
	urldate = {2022-11-08},
	journal = {JMIR Med Inform},
	author = {Lee, Junghye and Sun, Jimeng and Wang, Fei and Wang, Shuang and Jun, Chi-Hyuck and Jiang, Xiaoqian},
	month = apr,
	year = {2018},
	pages = {e20},
	file = {Lee et al. - 2018 - Privacy-Preserving Patient Similarity Learning in .pdf:/home/erosfabrici/Zotero/storage/C82YEGGX/Lee et al. - 2018 - Privacy-Preserving Patient Similarity Learning in .pdf:application/pdf},
}

@article{gkoulalas-divanis_modern_2021,
	title = {Modern {Privacy}-{Preserving} {Record} {Linkage} {Techniques}: {An} {Overview}},
	volume = {16},
	issn = {1556-6013, 1556-6021},
	shorttitle = {Modern {Privacy}-{Preserving} {Record} {Linkage} {Techniques}},
	url = {https://ieeexplore.ieee.org/document/9541149/},
	doi = {10.1109/TIFS.2021.3114026},
	abstract = {Record linkage is the challenging task of deciding which records, coming from disparate data sources, refer to the same entity. Established back in 1946 by Halbert L. Dunn, the area of record linkage has received tremendous attention over the years due to its numerous real-world applications, and has led to a plethora of technologies, methods, metrics, and systems. A major direction in record linkage regards methods for linking records in a privacy-preserving manner, where sensitive and personally identiﬁable information in the records is not leaked as part of the linkage process. In this article, we provide an overview of the large body of research literature in privacy-preserving record linkage, discuss the different generations of techniques that have been proposed, their advantages and limitations, and present a taxonomy as well as an extensive survey on the latest generation of methods. We conclude this work with a roadmap to the new generation of analytics-driven techniques that aims to address some of the major challenges in the ﬁeld.},
	language = {en},
	urldate = {2022-11-04},
	journal = {IEEE Trans.Inform.Forensic Secur.},
	author = {Gkoulalas-Divanis, Aris and Vatsalan, Dinusha and Karapiperis, Dimitrios and Kantarcioglu, Murat},
	year = {2021},
	pages = {4966--4987},
	file = {Gkoulalas-Divanis et al. - 2021 - Modern Privacy-Preserving Record Linkage Technique.pdf:/home/erosfabrici/Zotero/storage/P5CVP85K/Gkoulalas-Divanis et al. - 2021 - Modern Privacy-Preserving Record Linkage Technique.pdf:application/pdf},
}

@inproceedings{mullaymeri_two-party_2021-1,
	address = {Virtual Event Republic of Korea},
	title = {A two-party private string matching fuzzy vault scheme},
	isbn = {978-1-4503-8104-8},
	url = {https://dl.acm.org/doi/10.1145/3412841.3442079},
	doi = {10.1145/3412841.3442079},
	abstract = {A Fuzzy Vault is a cryptographic structure where a secret is being locked by a key and can be unlocked only by another key with significant overlap. In this paper, we introduce a two-party privacypreserving approximate string matching methodology based on a novel Fuzzy Vault scheme, combining the approximation and security properties of Fuzzy Vaults for privacy-preserving record linkage purposes.},
	language = {en},
	urldate = {2022-11-04},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Mullaymeri, Xhino and Karakasidis, Alexandros},
	month = mar,
	year = {2021},
	pages = {340--343},
	file = {Mullaymeri and Karakasidis - 2021 - A two-party private string matching fuzzy vault sc.pdf:/home/erosfabrici/Zotero/storage/G2RWHUNR/Mullaymeri and Karakasidis - 2021 - A two-party private string matching fuzzy vault sc.pdf:application/pdf},
}

@misc{adir_privacy-preserving_2022,
	title = {Privacy-preserving record linkage using local sensitive hash and private set intersection},
	url = {http://arxiv.org/abs/2203.14284},
	abstract = {The amount of data stored in data repositories increases every year. This makes it challenging to link records between diﬀerent datasets across companies and even internally, while adhering to privacy regulations. Address or name changes, and even diﬀerent spelling used for entity data, can prevent companies from using private deduplication or record-linking solutions such as private set intersection (PSI). To this end, we propose a new and eﬃcient privacy-preserving record linkage (PPRL) protocol that combines PSI and local sensitive hash (LSH) functions, and runs in linear time. We explain the privacy guarantees that our protocol provides and demonstrate its practicality by executing the protocol over two datasets with 220 records each, in 11 − 45 minutes, depending on network settings.},
	language = {en},
	urldate = {2022-11-04},
	publisher = {arXiv},
	author = {Adir, Allon and Aharoni, Ehud and Drucker, Nir and Kushnir, Eyal and Masalha, Ramy and Mirkin, Michael and Soceanu, Omri},
	month = mar,
	year = {2022},
	note = {arXiv:2203.14284 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	file = {Adir et al. - 2022 - Privacy-preserving record linkage using local sens.pdf:/home/erosfabrici/Zotero/storage/MV34R2GG/Adir et al. - 2022 - Privacy-preserving record linkage using local sens.pdf:application/pdf},
}

@article{aouedi_handling_2022,
	title = {Handling {Privacy}-{Sensitive} {Medical} {Data} {With} {Federated} {Learning}: {Challenges} and {Future} {Directions}},
	issn = {2168-2194, 2168-2208},
	shorttitle = {Handling {Privacy}-{Sensitive} {Medical} {Data} {With} {Federated} {Learning}},
	url = {https://ieeexplore.ieee.org/document/9804708/},
	doi = {10.1109/JBHI.2022.3185673},
	abstract = {Recent medical applications are largely dominated by the application of Machine Learning (ML) models to assist expert decisions, leading to disruptive innovations in radiology, pathology, genomics, and hence modern healthcare systems in general. Despite the proﬁtable usage of AI-based algorithms, these data-driven methods are facing issues such as the scarcity and privacy of user data, as well as the difﬁculty of institutions exchanging medical information. With insufﬁcient data, ML is prevented from reaching its full potential, which is only possible if the database consists of the full spectrum of possible anatomies, pathologies, and input data types. To solve these issues, Federated Learning (FL) appeared as a valuable approach in the medical ﬁeld, allowing patient data to stay where it is generated. Since an FL setting allows many clients to collaboratively train a model while keeping training data decentralized, it can protect privacy-sensitive medical data. However, FL is still unable to deliver all its promises and meets the more stringent requirements (e.g., latency, security) of a healthcare system based on multiple Internet of Medical Things (IoMT). For example, although no data are shared among the participants by deﬁnition in FL systems, some security risks are still present and can be considered as vulnerabilities from multiple aspects. This paper sheds light upon the emerging deployment of FL, provides a broad overview of current approaches and existing challenges, and outlines several directions of future work that are relevant to solving existing problems in federated healthcare, with a particular focus on security and privacy issues.},
	language = {en},
	urldate = {2022-11-02},
	journal = {IEEE J. Biomed. Health Inform.},
	author = {Aouedi, Ons and Sacco, Alessio and Piamrat, Kandaraj and Marchetto, Guido},
	year = {2022},
	pages = {1--14},
	file = {Aouedi et al. - 2022 - Handling Privacy-Sensitive Medical Data With Feder.pdf:/home/erosfabrici/Zotero/storage/83GH6NW3/Handling_Privacy-Sensitive_Medical_Data_With_Federated_Learning_Challenges_and_Future_Directions.pdf:application/pdf},
}

@inproceedings{khurram_sfour_2020,
	address = {Dallas, TX, USA},
	title = {{SFour}: {A} {Protocol} for {Cryptographically} {Secure} {Record} {Linkage} at {Scale}},
	isbn = {978-1-72812-903-7},
	shorttitle = {{SFour}},
	url = {https://ieeexplore.ieee.org/document/9101375/},
	doi = {10.1109/ICDE48307.2020.00031},
	abstract = {The prevalence of various (and increasingly large) datasets presents the challenging problem of discovering common entities dispersed across disparate datasets. Solutions to the private record linkage problem (PRL) aim to enable such explorations of datasets in a secure manner. A two-party PRL protocol allows two parties to determine for which entities they each possess a record (either an exact matching record or a fuzzy matching record) in their respective datasets — without revealing to one another information about any entities for which they do not both possess records. Although several solutions have been proposed to solve the PRL problem, no current solution offers a fully cryptographic security guarantee while maintaining both high accuracy of output and subquadratic runtime efﬁciency. To this end, we propose the ﬁrst known efﬁcient PRL protocol that runs in subquadratic time, provides high accuracy, and guarantees cryptographic security in the semi-honest security model.},
	language = {en},
	urldate = {2022-11-02},
	booktitle = {2020 {IEEE} 36th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Khurram, Basit and Kerschbaum, Florian},
	month = apr,
	year = {2020},
	pages = {277--288},
	file = {Khurram and Kerschbaum - 2020 - SFour A Protocol for Cryptographically Secure Rec.pdf:/home/erosfabrici/Zotero/storage/5BRDSKSU/Khurram and Kerschbaum - 2020 - SFour A Protocol for Cryptographically Secure Rec.pdf:application/pdf},
}

@article{karapiperis_summarizing_2021,
	title = {Summarizing and linking electronic health records},
	volume = {39},
	issn = {0926-8782, 1573-7578},
	url = {https://link.springer.com/10.1007/s10619-019-07263-0},
	doi = {10.1007/s10619-019-07263-0},
	abstract = {In recent years, several applications have emerged which require access to consolidated information that has to be computed and provided in near real-time. Traditional record linkage algorithms are unable to support such time-critical applications, as they perform the linkage ofﬂine and provide the result set only when the entire process has completed. To address this need, in this paper we propose the ﬁrst summarization algorithms that operate in the blocking and matching steps of record linkage to speed up online linkage tasks. Our ﬁrst method, called SkipBloom, efﬁciently summarizes the participating data sets, using their blocking keys, to allow for very fast comparisons among them. The second method, called BlockSketch, summarizes a block to achieve a constant number of comparisons for a submitted query record, during the matching phase. Our third method, SBlockSketch, operates on data streams, where the entire data set is unknown a-priori but, instead, there is a potentially unbounded stream of incoming data records. Finally, we introduce PBlockSketch, which adapts BlockSketch to privacy-preserving settings. Through extensive experimental evaluation, using real-world data sets, we show that our methods outperform the state-of-the-art algorithms for online record linkage in terms of the time needed, the memory used, and the recall and precision rates that are achieved during the linkage process. Following the evaluation of our approaches, we introduce SFEMRL, a novel framework that uses them to enable the linkage of electronic health records at large scale, while respecting patients’ privacy. Under this framework, patient records ﬁrst undergo a data masking process that perturbs sensitive information in data ﬁelds of the records to protect it. Subsequently, they participate in a parallel and distributed ecosystem, whose goal is to persist these records in order to be queried efﬁciently and accurately. We demonstrate that the integration of our framework with Map/Reduce offers robust distributed solutions for performing on-demand large-scale privacypreserving record linkage tasks in the health domain.},
	language = {en},
	number = {2},
	urldate = {2022-10-27},
	journal = {Distrib Parallel Databases},
	author = {Karapiperis, Dimitrios and Gkoulalas-Divanis, Aris and Verykios, Vassilios S.},
	month = jun,
	year = {2021},
	pages = {321--360},
	file = {Karapiperis et al. - 2021 - Summarizing and linking electronic health records.pdf:/home/erosfabrici/Zotero/storage/GYHWLF4U/Karapiperis et al. - 2021 - Summarizing and linking electronic health records.pdf:application/pdf},
}

@article{smith_role_2009,
	title = {The {Role} of {Schema} {Matching} in {Large} {Enterprises}},
	abstract = {To date, the principal use case for schema matching research has been as a precursor for code generation, i.e., constructing mappings between schema elements with the end goal of data transfer. In this paper, we argue that schema matching plays valuable roles independent of mapping construction, especially as schemata grow to industrial scales. Specifically, in large enterprises human decision makers and planners are often the immediate consumer of information derived from schema matchers, instead of schema mapping tools. We list a set of real application areas illustrating this role for schema matching, and then present our experiences tackling a customer problem in one of these areas. We describe the matcher used, where the tool was effective, where it fell short, and our lessons learned about how well current schema matching technology is suited for use in large enterprises. Finally, we suggest a new agenda for schema matching research based on these experiences.},
	language = {en},
	author = {Smith, Ken and Mork, Peter and Seligman, Len and Rosenthal, Arnon and Morse, Michael and Wolf, Christopher and Allen, David and Li, Maya},
	year = {2009},
	pages = {7},
	file = {Smith et al. - 2009 - The Role of Schema Matching in Large Enterprises.pdf:/home/erosfabrici/Zotero/storage/7PFNUM2R/Smith et al. - 2009 - The Role of Schema Matching in Large Enterprises.pdf:application/pdf},
}

@article{cormode_current_2022,
	title = {Current {Trends} in {Data} {Summaries}},
	volume = {50},
	issn = {0163-5808},
	url = {https://dl.acm.org/doi/10.1145/3516431.3516433},
	doi = {10.1145/3516431.3516433},
	abstract = {The research area of data summarization seeks to ﬁnd small data structures that can be updated ﬂexibly, and answer certain queries on the input accurately. Summaries are widely used across the area of data management, and are studied from both theoretical and practical perspectives. They are the subject of ongoing research to improve their performance and broaden their applicability. In this column, recent developments in data summarization are surveyed, with the intent of inspiring further advances.},
	language = {en},
	number = {4},
	urldate = {2022-10-27},
	journal = {SIGMOD Rec.},
	author = {Cormode, Graham},
	month = jan,
	year = {2022},
	pages = {6--15},
	file = {Cormode - 2022 - Current Trends in Data Summaries.pdf:/home/erosfabrici/Zotero/storage/8V9TMG3D/Cormode - 2022 - Current Trends in Data Summaries.pdf:application/pdf},
}

@article{altowim_progressive_2014,
	title = {Progressive approach to relational entity resolution},
	volume = {7},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/2732967.2732975},
	doi = {10.14778/2732967.2732975},
	abstract = {This paper proposes a progressive approach to entity resolution (ER) that allows users to explore a trade-oﬀ between the resolution cost and the achieved quality of the resolved data. In particular, our approach aims to produce the highest quality result given a constraint on the resolution budget, speciﬁed by the user. Our proposed method monitors and dynamically reassesses the resolution progress to determine which parts of the data should be resolved next and how they should be resolved. The comprehensive empirical evaluation of the proposed approach demonstrates its signiﬁcant advantage in terms of eﬃciency over the traditional ER techniques for the given problem settings.},
	language = {en},
	number = {11},
	urldate = {2022-10-26},
	journal = {Proc. VLDB Endow.},
	author = {Altowim, Yasser and Kalashnikov, Dmitri V. and Mehrotra, Sharad},
	month = jul,
	year = {2014},
	pages = {999--1010},
	file = {Altowim et al. - 2014 - Progressive approach to relational entity resoluti.pdf:/home/erosfabrici/Zotero/storage/F58TEXYW/Altowim et al. - 2014 - Progressive approach to relational entity resoluti.pdf:application/pdf},
}

@misc{patrini_fast_2016,
	title = {Fast {Learning} from {Distributed} {Datasets} without {Entity} {Matching}},
	url = {http://arxiv.org/abs/1603.04002},
	abstract = {Consider the following data fusion scenario: two datasets/peers contain the same realworld entities described using partially shared features, e.g. banking and insurance company records of the same customer base. Our goal is to learn a classiﬁer in the cross product space of the two domains, in the hard case in which no shared ID is available –e.g. due to anonymization. Traditionally, the problem is approached by ﬁrst addressing entity matching and subsequently learning the classiﬁer in a standard manner. We present an end-to-end solution which bypasses matching entities, based on the recently introduced concept of Rademacher observations (rados). Informally, we replace the minimisation of a loss over examples, which requires to solve entity resolution, by the equivalent minimisation of a (different) loss over rados. Among others, key properties we show are (i) a potentially huge subset of these rados does not require to perform entity matching, and (ii) the algorithm that provably minimizes the rado loss over these rados has time and space complexities smaller than the algorithm minimizing the equivalent example loss. Last, we relax a key assumption of the model, that the data is vertically partitioned among peers — in this case, we would not even know the existence of a solution to entity resolution. In this more general setting, experiments validate the possibility of signiﬁcantly beating even the optimal peer in hindsight.},
	language = {en},
	urldate = {2022-11-23},
	publisher = {arXiv},
	author = {Patrini, Giorgio and Nock, Richard and Hardy, Stephen and Caetano, Tiberio},
	month = mar,
	year = {2016},
	note = {arXiv:1603.04002 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, I.2.6},
	file = {Patrini et al. - 2016 - Fast Learning from Distributed Datasets without En.pdf:/home/erosfabrici/Zotero/storage/3YQET6AF/Patrini et al. - 2016 - Fast Learning from Distributed Datasets without En.pdf:application/pdf},
}

@article{joshi_federated_2022,
	title = {Federated {Learning} for {Healthcare} {Domain} - {Pipeline}, {Applications} and {Challenges}},
	volume = {3},
	issn = {2691-1957, 2637-8051},
	url = {https://dl.acm.org/doi/10.1145/3533708},
	doi = {10.1145/3533708},
	abstract = {Federated learning is the process of developing machine learning models over datasets distributed across data centers such as hospitals, clinical research labs, and mobile devices while preventing data leakage. This survey examines previous research and studies on federated learning in the healthcare sector across a range of use cases and applications. Our survey shows what challenges, methods, and applications a practitioner should be aware of in the topic of federated learning. This paper aims to lay out existing research and list the possibilities of federated learning for healthcare industries.},
	language = {en},
	number = {4},
	urldate = {2022-11-22},
	journal = {ACM Trans. Comput. Healthcare},
	author = {Joshi, Madhura and Pal, Ankit and Sankarasubbu, Malaikannan},
	month = oct,
	year = {2022},
	pages = {1--36},
	file = {Joshi et al. - 2022 - Federated Learning for Healthcare Domain - Pipelin.pdf:/home/erosfabrici/Zotero/storage/U9YX627T/Joshi et al. - 2022 - Federated Learning for Healthcare Domain - Pipelin.pdf:application/pdf},
}

@misc{kairouz_advances_2021,
	title = {Advances and {Open} {Problems} in {Federated} {Learning}},
	url = {http://arxiv.org/abs/1912.04977},
	abstract = {Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.},
	language = {en},
	urldate = {2022-11-21},
	publisher = {arXiv},
	author = {Kairouz, Peter and McMahan, H. Brendan and Avent, Brendan and Bellet, Aurélien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Eichner, Hubert and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gascón, Adrià and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Konečný, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancrède and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and Özgür, Ayfer and Pagh, Rasmus and Raykova, Mariana and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tramèr, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
	month = mar,
	year = {2021},
	note = {arXiv:1912.04977 [cs, stat]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Kairouz et al. - 2021 - Advances and Open Problems in Federated Learning.pdf:/home/erosfabrici/Zotero/storage/PWVUDJ8I/Kairouz et al. - 2021 - Advances and Open Problems in Federated Learning.pdf:application/pdf},
}

@article{nock_rademacher_nodate,
	title = {Rademacher {Observations}, {Private} {Data}, and {Boosting}},
	abstract = {The minimization of the logistic loss is a popular approach to batch supervised learning. Our paper starts from the surprising observation that, when ﬁtting linear classiﬁers, the minimization of the logistic loss is equivalent to the minimization of an exponential rado-loss computed (i) over transformed data that we call Rademacher observations (rados), and (ii) over the same classiﬁer as the one of the logistic loss. Thus, a classiﬁer learnt from rados can be directly used to classify observations. We provide a learning algorithm over rados with boosting-compliant convergence rates on the logistic loss (computed over examples). Experiments on domains with up to millions of examples, backed up by theoretical arguments, display that learning over a small set of random rados can challenge the state of the art that learns over the complete set of examples. We show that rados comply with various privacy requirements that make them good candidates for machine learning in a privacy framework. We give several algebraic, geometric and computational hardness results on reconstructing examples from rados. We also show how it is possible to craft, and efﬁciently learn from, rados in a differential privacy framework. Tests reveal that learning from differentially private rados brings non-trivial privacy vs accuracy tradeoffs.},
	language = {en},
	author = {Nock, Richard and Patrini, Giorgio and Friedman, Arik},
	pages = {9},
	file = {Nock et al. - Rademacher Observations, Private Data, and Boostin.pdf:/home/erosfabrici/Zotero/storage/IFC742QV/Nock et al. - Rademacher Observations, Private Data, and Boostin.pdf:application/pdf},
}

@article{patrini_fast_nodate,
	title = {Fast {Learning} from {Distributed} {Datasets} without {Entity} {Matching}},
	abstract = {Consider the following scenario: two datasets/peers contain the same real-world entities described using partially shared features, e.g. banking and insurance company records of the same customer base. Our goal is to learn a classiﬁer in the cross product space of the two domains, in the hard case in which no shared ID is available –e.g. due to anonymization. Traditionally, the problem is approached by ﬁrst addressing entity matching and subsequently learning the classiﬁer in a standard manner. We present an end-to-end solution which bypasses matching entities, based on the recently introduced concept of Rademacher observations (rados). Informally, we replace the minimisation of a loss over examples, which requires entity resolution, by the equivalent minimisation of a (different) loss over rados. We show that (i) a potentially exponential-size subset of these rados does not require to perform entity matching, and (ii) the algorithm that provably minimizes the loss over rados has time and space complexities smaller than the algorithm minimizing the equivalent example loss. Last, we relax a key assumption, that the data is vertically partitioned among peers — in this case, we would not even know the existence of a solution to entity resolution. In this more general setting, experiments validate the possibility of beating even the optimal peer in hindsight.},
	language = {en},
	author = {Patrini, Giorgio and Nock, Richard and Hardy, Stephen and Caetano, Tiberio},
	pages = {9},
	file = {Patrini et al. - Fast Learning from Distributed Datasets without En.pdf:/home/erosfabrici/Zotero/storage/ANMQBRKN/Patrini et al. - Fast Learning from Distributed Datasets without En.pdf:application/pdf},
}

@incollection{kanade_efficient_2004,
	address = {Berlin, Heidelberg},
	title = {Efficient {Private} {Matching} and {Set} {Intersection}},
	volume = {3027},
	isbn = {978-3-540-21935-4 978-3-540-24676-3},
	url = {http://link.springer.com/10.1007/978-3-540-24676-3_1},
	abstract = {We consider the problem of computing the intersection of private datasets of two parties, where the datasets contain lists of elements taken from a large domain. This problem has many applications for online collaboration. We present protocols, based on the use of homomorphic encryption and balanced hashing, for both semi-honest and malicious environments. For lists of length k, we obtain O(k) communication overhead and O(k ln ln k) computation. The protocol for the semihonest environment is secure in the standard model, while the protocol for the malicious environment is secure in the random oracle model. We also consider the problem of approximating the size of the intersection, show a linear lower-bound for the communication overhead of solving this problem, and provide a suitable secure protocol. Lastly, we investigate other variants of the matching problem, including extending the protocol to the multi-party setting as well as considering the problem of approximate matching.},
	language = {en},
	urldate = {2022-11-18},
	booktitle = {Advances in {Cryptology} - {EUROCRYPT} 2004},
	publisher = {Springer Berlin Heidelberg},
	author = {Freedman, Michael J. and Nissim, Kobbi and Pinkas, Benny},
	editor = {Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Cachin, Christian and Camenisch, Jan L.},
	year = {2004},
	doi = {10.1007/978-3-540-24676-3_1},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {1--19},
	file = {Freedman et al. - 2004 - Efficient Private Matching and Set Intersection.pdf:/home/erosfabrici/Zotero/storage/NY6WSPXD/Freedman et al. - 2004 - Efficient Private Matching and Set Intersection.pdf:application/pdf},
}

@article{gkoulalas-divanis_modern_2021-1,
	title = {Modern {Privacy}-{Preserving} {Record} {Linkage} {Techniques}: {An} {Overview}},
	volume = {16},
	issn = {1556-6013, 1556-6021},
	shorttitle = {Modern {Privacy}-{Preserving} {Record} {Linkage} {Techniques}},
	url = {https://ieeexplore.ieee.org/document/9541149/},
	doi = {10.1109/TIFS.2021.3114026},
	abstract = {Record linkage is the challenging task of deciding which records, coming from disparate data sources, refer to the same entity. Established back in 1946 by Halbert L. Dunn, the area of record linkage has received tremendous attention over the years due to its numerous real-world applications, and has led to a plethora of technologies, methods, metrics, and systems. A major direction in record linkage regards methods for linking records in a privacy-preserving manner, where sensitive and personally identiﬁable information in the records is not leaked as part of the linkage process. In this article, we provide an overview of the large body of research literature in privacy-preserving record linkage, discuss the different generations of techniques that have been proposed, their advantages and limitations, and present a taxonomy as well as an extensive survey on the latest generation of methods. We conclude this work with a roadmap to the new generation of analytics-driven techniques that aims to address some of the major challenges in the ﬁeld.},
	language = {en},
	urldate = {2022-11-18},
	journal = {IEEE Trans.Inform.Forensic Secur.},
	author = {Gkoulalas-Divanis, Aris and Vatsalan, Dinusha and Karapiperis, Dimitrios and Kantarcioglu, Murat},
	year = {2021},
	pages = {4966--4987},
	file = {Gkoulalas-Divanis et al. - 2021 - Modern Privacy-Preserving Record Linkage Technique.pdf:/home/erosfabrici/Zotero/storage/93K4YK4I/Gkoulalas-Divanis et al. - 2021 - Modern Privacy-Preserving Record Linkage Technique.pdf:application/pdf},
}

@article{pinkas_scalable_2018,
	title = {Scalable {Private} {Set} {Intersection} {Based} on {OT} {Extension}},
	volume = {21},
	issn = {2471-2566, 2471-2574},
	url = {https://dl.acm.org/doi/10.1145/3154794},
	doi = {10.1145/3154794},
	abstract = {Private set intersection (PSI) allows two parties to compute the intersection of their sets without revealing any information about items that are not in the intersection. It is one of the best studied applications of secure computation and many PSI protocols have been proposed. However, the variety of existing PSI protocols makes it difficult to identify the solution that performs best in a respective scenario, especially since they were not compared in the same setting. In addition, existing PSI protocols are several orders of magnitude slower than an insecure naïve hashing solution, which is used in practice.
            In this article, we review the progress made on PSI protocols and give an overview of existing protocols in various security models. We then focus on PSI protocols that are secure against semi-honest adversaries and take advantage of the most recent efficiency improvements in Oblivious Transfer (OT) extension, propose significant optimizations to previous PSI protocols, and suggest a new PSI protocol whose runtime is superior to that of existing protocols. We compare the performance of the protocols, both theoretically and experimentally, by implementing all protocols on the same platform, give recommendations on which protocol to use in a particular setting, and evaluate the progress on PSI protocols by comparing them to the currently employed insecure naïve hashing protocol. We demonstrate the feasibility of our new PSI protocol by processing two sets with a billion elements each.},
	language = {en},
	number = {2},
	urldate = {2022-11-18},
	journal = {ACM Trans. Priv. Secur.},
	author = {Pinkas, Benny and Schneider, Thomas and Zohner, Michael},
	month = feb,
	year = {2018},
	pages = {1--35},
	file = {Pinkas et al. - 2018 - Scalable Private Set Intersection Based on OT Exte.pdf:/home/erosfabrici/Zotero/storage/J24KEYLY/Pinkas et al. - 2018 - Scalable Private Set Intersection Based on OT Exte.pdf:application/pdf},
}

@article{miller_open_2018,
	title = {Open data integration},
	volume = {11},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3229863.3240491},
	doi = {10.14778/3229863.3240491},
	abstract = {Open data plays a major role in supporting both governmental and organizational transparency. Many organizations are adopting Open Data Principles promising to make their open data complete, primary, and timely. These properties make this data tremendously valuable to data scientists. However, scientists generally do not have a priori knowledge about what data is available (its schema or content). Nevertheless, they want to be able to use open data and integrate it with other public or private data they are studying. Traditionally, data integration is done using a framework called query discovery where the main task is to discover a query (or transformation) that translates data from one form into another. The goal is to ﬁnd the right operators to join, nest, group, link, and twist data into a desired form. We introduce a new paradigm for thinking about integration where the focus is on data discovery, but highly efﬁcient internet-scale discovery that is driven by data analysis needs. We describe a research agenda and recent progress in developing scalable data-analysis or query-aware data discovery algorithms that provide high recall and accuracy over massive data repositories.},
	language = {en},
	number = {12},
	urldate = {2022-11-16},
	journal = {Proc. VLDB Endow.},
	author = {Miller, Renée J.},
	month = aug,
	year = {2018},
	pages = {2130--2139},
	file = {Miller - 2018 - Open data integration.pdf:/home/erosfabrici/Zotero/storage/WZF4LRAL/Miller - 2018 - Open data integration.pdf:application/pdf},
}

@article{naumann_data_2014,
	title = {Data profiling revisited},
	volume = {42},
	issn = {0163-5808},
	url = {https://dl.acm.org/doi/10.1145/2590989.2590995},
	doi = {10.1145/2590989.2590995},
	abstract = {Data proﬁling comprises a broad range of methods to efﬁciently analyze a given data set. In a typical scenario, which mirrors the capabilities of commercial data proﬁling tools, tables of a relational database are scanned to derive metadata, such as data types and value patterns, completeness and uniqueness of columns, keys and foreign keys, and occasionally functional dependencies and association rules. Individual research projects have proposed several additional proﬁling tasks, such as the discovery of inclusion dependencies or conditional functional dependencies.},
	language = {en},
	number = {4},
	urldate = {2022-11-16},
	journal = {SIGMOD Rec.},
	author = {Naumann, Felix},
	month = feb,
	year = {2014},
	pages = {40--49},
	file = {Naumann - 2014 - Data profiling revisited.pdf:/home/erosfabrici/Zotero/storage/3YGCVCDP/Naumann - 2014 - Data profiling revisited.pdf:application/pdf},
}

@misc{jafari_survey_2021,
	title = {A {Survey} on {Locality} {Sensitive} {Hashing} {Algorithms} and their {Applications}},
	url = {http://arxiv.org/abs/2102.08942},
	abstract = {Finding nearest neighbors in high-dimensional spaces is a fundamental operation in many diverse application domains. Locality Sensitive Hashing (LSH) is one of the most popular techniques for finding approximate nearest neighbor searches in high-dimensional spaces. The main benefits of LSH are its sub-linear query performance and theoretical guarantees on the query accuracy. In this survey paper, we provide a review of state-of-the-art LSH and Distributed LSH techniques. Most importantly, unlike any other prior survey, we present how Locality Sensitive Hashing is utilized in different application domains.},
	language = {en},
	urldate = {2022-11-16},
	publisher = {arXiv},
	author = {Jafari, Omid and Maurya, Preeti and Nagarkar, Parth and Islam, Khandker Mushfiqul and Crushev, Chidambaram},
	month = feb,
	year = {2021},
	note = {arXiv:2102.08942 [cs]},
	keywords = {Computer Science - Databases, H.2.4},
	file = {Jafari et al. - 2021 - A Survey on Locality Sensitive Hashing Algorithms .pdf:/home/erosfabrici/Zotero/storage/5JXN9FPI/Jafari et al. - 2021 - A Survey on Locality Sensitive Hashing Algorithms .pdf:application/pdf},
}

@inproceedings{franke_parallel_2018-1,
	address = {Funchal, Madeira, Portugal},
	title = {Parallel {Privacy}-preserving {Record} {Linkage} using {LSH}-based {Blocking}:},
	isbn = {978-989-758-296-7},
	shorttitle = {Parallel {Privacy}-preserving {Record} {Linkage} using {LSH}-based {Blocking}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006682701950203},
	doi = {10.5220/0006682701950203},
	language = {en},
	urldate = {2022-11-15},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Internet} of {Things}, {Big} {Data} and {Security}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Franke, Martin and Sehili, Ziad and Rahm, Erhard},
	year = {2018},
	pages = {195--203},
	file = {Franke et al. - 2018 - Parallel Privacy-preserving Record Linkage using L.pdf:/home/erosfabrici/Zotero/storage/2GYCMHVR/Franke et al. - 2018 - Parallel Privacy-preserving Record Linkage using L.pdf:application/pdf},
}

@inproceedings{yakout_efficient_2009,
	address = {Shanghai, China},
	title = {Efficient {Private} {Record} {Linkage}},
	isbn = {978-1-4244-3422-0},
	url = {http://ieeexplore.ieee.org/document/4812521/},
	doi = {10.1109/ICDE.2009.221},
	abstract = {Record linkage is the computation of the associations among records of multiple databases. It arises in contexts like the integration of such databases, online interactions and negotiations, and many others. The autonomous entities who wish to carry out the record matching computation are often reluctant to fully share their data. In such a framework where the entities are unwilling to share data with each other, the problem of carrying out the linkage computation without full data exchange has been called private record linkage. Previous private record linkage techniques have made use of a third party. We provide efficient techniques for private record linkage that improve on previous work in that (i) they make no use of a third party; (ii) they achieve much better performance than that of previous schemes in terms of execution time and quality of output (i.e., practically without false negatives and minimal false positives). Our software implementation provides experimental validation of our approach and the above claims.},
	language = {en},
	urldate = {2022-11-14},
	booktitle = {2009 {IEEE} 25th {International} {Conference} on {Data} {Engineering}},
	publisher = {IEEE},
	author = {Yakout, Mohamed and Atallah, Mikhail J. and Elmagarmid, Ahmed},
	month = mar,
	year = {2009},
	note = {ISSN: 1084-4627},
	pages = {1283--1286},
	file = {Yakout et al. - 2009 - Efficient Private Record Linkage.pdf:/home/erosfabrici/Zotero/storage/IY2PITZY/Yakout et al. - 2009 - Efficient Private Record Linkage.pdf:application/pdf},
}

@inproceedings{bonomi_frequent_2012,
	address = {Maui, Hawaii, USA},
	title = {Frequent grams based embedding for privacy preserving record linkage},
	isbn = {978-1-4503-1156-4},
	url = {http://dl.acm.org/citation.cfm?doid=2396761.2398480},
	doi = {10.1145/2396761.2398480},
	abstract = {In this paper, we study the problem of privacy preserving record linkage which aims to perform record linkage without revealing anything about the non-linked records. We propose a new secure embedding strategy based on frequent variable length grams which allows record linkage on the embedded space. The frequent grams used for constructing the embedding base are mined from the original database under the framework of differential privacy. Compared with the state-of-the-art secure matching schema [15], our approach provides formal, provable privacy guarantees and achieves better scalability while providing comparable utility.},
	language = {en},
	urldate = {2022-11-14},
	booktitle = {Proceedings of the 21st {ACM} international conference on {Information} and knowledge management - {CIKM} '12},
	publisher = {ACM Press},
	author = {Bonomi, Luca and Xiong, Li and Chen, Rui and Fung, Benjamin C.M.},
	year = {2012},
	pages = {1597},
	file = {Bonomi et al. - 2012 - Frequent grams based embedding for privacy preserv.pdf:/home/erosfabrici/Zotero/storage/THUMJGGX/Bonomi et al. - 2012 - Frequent grams based embedding for privacy preserv.pdf:application/pdf},
}

@ARTICLE{sparsemap,
  author={Hjaltason, G.R. and Samet, H.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Properties of embedding methods for similarity searching in metric spaces}, 
  year={2003},
  volume={25},
  number={5},
  pages={530-549},
  doi={10.1109/TPAMI.2003.1195989}}

@inproceedings{scannapieco_privacy_2007,
	address = {Beijing, China},
	title = {Privacy preserving schema and data matching},
	isbn = {978-1-59593-686-8},
	url = {http://portal.acm.org/citation.cfm?doid=1247480.1247553},
	doi = {10.1145/1247480.1247553},
	abstract = {In many business scenarios record matching is performed across diﬀerent data sources with the aim of identifying common information shared among these sources. Such need is however often in contrast with privacy requirements concerning the data stored by the sources, like it is the case in e-Health and e-Government applications. In this paper, we propose a protocol for record matching that preserves privacy both at the data level and at the schema level. Specifically, if two sources need to identify their common data, by running the protocol they can compute the matching of their datasets without sharing their data in clear and only sharing the result of the matching. The protocol allows each source to hide the records not to be shared with the other source, the detail of the attributes in its schema, and several other features that the source may want to keep private. The protocol uses a third party, and maps records into a vector space in order to preserve their privacy. So far, the mapping of records into a vector space has been used only to improve the matching eﬃciency; by contrast we demonstrate that a proper embedding of records can also be used for assuring privacy. Experimental results show the eﬃciency of the matching protocol in terms of precision and recall as well as the good computational performance.},
	language = {en},
	urldate = {2022-11-14},
	booktitle = {Proceedings of the 2007 {ACM} {SIGMOD} international conference on {Management} of data  - {SIGMOD} '07},
	publisher = {ACM Press},
	author = {Scannapieco, Monica and Figotin, Ilya and Bertino, Elisa and Elmagarmid, Ahmed K.},
	year = {2007},
	pages = {653},
	file = {Scannapieco et al. - 2007 - Privacy preserving schema and data matching.pdf:/home/erosfabrici/Zotero/storage/HJTZK6JG/Scannapieco et al. - 2007 - Privacy preserving schema and data matching.pdf:application/pdf},
}

@incollection{fernandes_locality_2021,
	title = {Locality {Sensitive} {Hashing} with {Extended} {Differential} {Privacy}},
	volume = {12973},
	url = {http://arxiv.org/abs/2010.09393},
	abstract = {Extended diﬀerential privacy, a generalization of standard diﬀerential privacy (DP) using a general metric, has been widely studied to provide rigorous privacy guarantees while keeping high utility. However, existing works on extended DP are limited to few metrics, such as the Euclidean metric. Consequently, they have only a small number of applications, such as location-based services and document processing.},
	language = {en},
	urldate = {2022-11-25},
	author = {Fernandes, Natasha and Kawamoto, Yusuke and Murakami, Takao},
	year = {2021},
	doi = {10.1007/978-3-030-88428-4_28},
	note = {arXiv:2010.09393 [cs, math]},
	keywords = {Computer Science - Databases, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Information Retrieval, Computer Science - Information Theory},
	pages = {563--583},
	file = {Fernandes et al. - 2021 - Locality Sensitive Hashing with Extended Different.pdf:/home/erosfabrici/Zotero/storage/XJMSYEUN/Fernandes et al. - 2021 - Locality Sensitive Hashing with Extended Different.pdf:application/pdf},
}

@inproceedings{al-lawati_blocking-aware_2005,
	address = {Baltimore Maryland},
	title = {Blocking-aware private record linkage},
	isbn = {978-1-59593-160-3},
	url = {https://dl.acm.org/doi/10.1145/1077501.1077513},
	doi = {10.1145/1077501.1077513},
	abstract = {In this paper, the problem of quickly matching records (i.e., record linkage problem) from two autonomous sources without revealing privacy to the other parties is considered. In particular, our focus is to devise secure blocking scheme to improve the performance of record linkage signiﬁcantly while being secure. Although there have been works on private record linkage, none has considered adopting the blocking framework. Therefore, our proposed blocking-aware private record linkage can perform large-scale record linkage without revealing privacy. Preliminary experimental results showing the potential of the proposal are reported.},
	language = {en},
	urldate = {2023-01-31},
	booktitle = {Proceedings of the 2nd international workshop on {Information} quality in information systems},
	publisher = {ACM},
	author = {Al-Lawati, Ali and Lee, Dongwon and McDaniel, Patrick},
	month = jun,
	year = {2005},
	pages = {59--68},
	file = {Al-Lawati et al. - 2005 - Blocking-aware private record linkage.pdf:/home/erosfabrici/Zotero/storage/6HU5Y4PK/Al-Lawati et al. - 2005 - Blocking-aware private record linkage.pdf:application/pdf},
}

@article{papenbrock_functional_nodate,
	title = {Functional {Dependency} {Discovery}: {An} {Experimental} {Evaluation} of {Seven} {Algorithms}},
	abstract = {Functional dependencies are important metadata used for schema normalization, data cleansing and many other tasks. The eﬃcient discovery of functional dependencies in tables is a well-known challenge in database research and has seen several approaches. Because no comprehensive comparison between these algorithms exist at the time, it is hard to choose the best algorithm for a given dataset. In this experimental paper, we describe, evaluate, and compare the seven most cited and most important algorithms, all solving this same problem.},
	language = {en},
	author = {Papenbrock, Thorsten and Ehrlich, Jens and Marten, Jannik and Neubert, Tommy and Rudolph, Jan-Peer},
	file = {Papenbrock et al. - Functional Dependency Discovery An Experimental E.pdf:/home/erosfabrici/Zotero/storage/8DXD8LZR/Papenbrock et al. - Functional Dependency Discovery An Experimental E.pdf:application/pdf},
}

@inproceedings{he_practical_2021,
	address = {Virtual Event China},
	title = {Practical {Security} and {Privacy} for {Database} {Systems}},
	isbn = {978-1-4503-8343-1},
	url = {https://dl.acm.org/doi/10.1145/3448016.3457544},
	doi = {10.1145/3448016.3457544},
	abstract = {Computing technology has enabled massive digital traces of our personal lives to be collected and stored. These datasets play an important role in numerous real-life applications and research analysis, such as contact tracing for COVID 19, but they contain sensitive information about individuals. When managing these datasets, privacy is usually addressed as an afterthought, engineered on top of a database system optimized for performance and usability. This has led to a plethora of unexpected privacy attacks in the news. Specialized privacy-preserving solutions usually require a group of privacy experts and they are not directly transferable to other domains. There is an urgent need for a general trustworthy database system that offers end-to-end security and privacy guarantees. In this tutorial, we will first describe the security and privacy requirements for database systems in different settings and cover the state-of-the-art tools that achieve these requirements. We will also show challenges in integrating these techniques together and demonstrate the design principles and optimization opportunities for these security and privacy-aware database systems. This is designed to be a three hour tutorial.},
	language = {en},
	urldate = {2023-01-24},
	booktitle = {Proceedings of the 2021 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {He, Xi and Rogers, Jennie and Bater, Johes and Machanavajjhala, Ashwin and Wang, Chenghong and Wang, Xiao},
	month = jun,
	year = {2021},
	pages = {2839--2845},
	file = {He et al. - 2021 - Practical Security and Privacy for Database System.pdf:/home/erosfabrici/Zotero/storage/TZV3R64A/He et al. - 2021 - Practical Security and Privacy for Database System.pdf:application/pdf},
}

@article{mohammed_centralized_2010,
	title = {Centralized and {Distributed} {Anonymization} for {High}-{Dimensional} {Healthcare} {Data}},
	volume = {4},
	issn = {1556-4681, 1556-472X},
	url = {https://dl.acm.org/doi/10.1145/1857947.1857950},
	doi = {10.1145/1857947.1857950},
	abstract = {Sharing healthcare data has become a vital requirement in healthcare system management; however, inappropriate sharing and usage of healthcare data could threaten patients’ privacy. In this article, we study the privacy concerns of sharing patient information between the Hong Kong Red Cross Blood Transfusion Service (BTS) and the public hospitals. We generalize their information and privacy requirements to the problems of
              centralized anonymization
              and
              distributed anonymization
              , and identify the major challenges that make traditional data anonymization methods not applicable. Furthermore, we propose a new privacy model called
              LKC-privacy
              to overcome the challenges and present two anonymization algorithms to achieve LKC-privacy in both the centralized and the distributed scenarios. Experiments on real-life data demonstrate that our anonymization algorithms can effectively retain the essential information in anonymous data for data analysis and is scalable for anonymizing large datasets.},
	language = {en},
	number = {4},
	urldate = {2023-01-20},
	journal = {ACM Trans. Knowl. Discov. Data},
	author = {Mohammed, Noman and Fung, Benjamin C. M. and Hung, Patrick C. K. and Lee, Cheuk-Kwong},
	month = oct,
	year = {2010},
	pages = {1--33},
	file = {Mohammed et al. - 2010 - Centralized and Distributed Anonymization for High.pdf:/home/erosfabrici/Zotero/storage/C3BQLC3U/Mohammed et al. - 2010 - Centralized and Distributed Anonymization for High.pdf:application/pdf},
}

@article{jiang_secure_2006,
	title = {A secure distributed framework for achieving k-anonymity},
	volume = {15},
	issn = {1066-8888, 0949-877X},
	url = {http://link.springer.com/10.1007/s00778-006-0008-z},
	doi = {10.1007/s00778-006-0008-z},
	language = {en},
	number = {4},
	urldate = {2023-01-19},
	journal = {The VLDB Journal},
	author = {Jiang, Wei and Clifton, Chris},
	month = nov,
	year = {2006},
	pages = {316--333},
	file = {Jiang and Clifton - 2006 - A secure distributed framework for achieving k-ano.pdf:/home/erosfabrici/Zotero/storage/FG9NLK88/Jiang and Clifton - 2006 - A secure distributed framework for achieving k-ano.pdf:application/pdf},
}

@inproceedings{inan_private_2010,
	address = {Lausanne Switzerland},
	title = {Private record matching using differential privacy},
	isbn = {978-1-60558-945-9},
	url = {https://dl.acm.org/doi/10.1145/1739041.1739059},
	doi = {10.1145/1739041.1739059},
	abstract = {Private matching between datasets owned by distinct parties is a challenging problem with several applications. Private matching allows two parties to identify the records that are close to each other according to some distance functions, such that no additional information other than the join result is disclosed to any party. Private matching can be solved securely and accurately using secure multi-party computation (SMC) techniques, but such an approach is prohibitively expensive in practice. Previous work proposed the release of sanitized versions of the sensitive datasets which allows blocking, i.e., ﬁltering out sub-sets of records that cannot be part of the join result. This way, SMC is applied only to a small fraction of record pairs, reducing the matching cost to acceptable levels. The blocking step is essential for the privacy, accuracy and efﬁciency of matching. However, the state-of-the-art focuses on sanitization based on k-anonymity, which does not provide sufﬁcient privacy. We propose an alternative design centered on differential privacy, a novel paradigm that provides strong privacy guarantees. The realization of the new model presents difﬁcult challenges, such as the evaluation of distance-based matching conditions with the help of only a statistical queries interface. Specialized versions of data indexing structures (e.g., kd-trees) also need to be devised, in order to comply with differential privacy. Experiments conducted on the real-world Census-income dataset show that, although our methods provide strong privacy, their effectiveness in reducing matching cost is not far from that of k-anonymity based counterparts.},
	language = {en},
	urldate = {2023-01-18},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Extending} {Database} {Technology}},
	publisher = {ACM},
	author = {Inan, Ali and Kantarcioglu, Murat and Ghinita, Gabriel and Bertino, Elisa},
	month = mar,
	year = {2010},
	pages = {123--134},
	file = {Inan et al. - 2010 - Private record matching using differential privacy.pdf:/home/erosfabrici/Zotero/storage/XJCIZQYR/Inan et al. - 2010 - Private record matching using differential privacy.pdf:application/pdf},
}

@inproceedings{inan_hybrid_2008,
	address = {Cancun, Mexico},
	title = {A {Hybrid} {Approach} to {Private} {Record} {Linkage}},
	isbn = {978-1-4244-1836-7 978-1-4244-1837-4},
	url = {http://ieeexplore.ieee.org/document/4497458/},
	doi = {10.1109/ICDE.2008.4497458},
	abstract = {Real-world entities are not always represented by the same set of features in different data sets. Therefore matching and linking records corresponding to the same real-world entity distributed across these data sets is a challenging task. If the data sets contain private information, the problem becomes even harder due to privacy concerns. Existing solutions of this problem mostly follow two approaches: sanitization techniques and cryptographic techniques. The former achieves privacy by perturbing sensitive data at the expense of degrading matching accuracy. The later, on the other hand, attains both privacy and high accuracy under heavy communication and computation costs. In this paper, we propose a method that combines these two approaches and enables users to trade off between privacy, accuracy and cost. Experiments conducted on real data sets show that our method has significantly lower costs than cryptographic techniques and yields much more accurate matching results compared to sanitization techniques, even when the data sets are perturbed extensively.},
	language = {en},
	urldate = {2023-01-18},
	booktitle = {2008 {IEEE} 24th {International} {Conference} on {Data} {Engineering}},
	publisher = {IEEE},
	author = {Inan, Ali and Kantarcioglu, Murat and Bertino, Elisa and Scannapieco, Monica},
	month = apr,
	year = {2008},
	pages = {496--505},
	file = {Inan et al. - 2008 - A Hybrid Approach to Private Record Linkage.pdf:/home/erosfabrici/Zotero/storage/HBY57KIW/Inan et al. - 2008 - A Hybrid Approach to Private Record Linkage.pdf:application/pdf},
}

@article{jiang_secure_2006-1,
	title = {A secure distributed framework for achieving k-anonymity},
	volume = {15},
	issn = {1066-8888, 0949-877X},
	url = {http://link.springer.com/10.1007/s00778-006-0008-z},
	doi = {10.1007/s00778-006-0008-z},
	language = {en},
	number = {4},
	urldate = {2023-01-18},
	journal = {The VLDB Journal},
	author = {Jiang, Wei and Clifton, Chris},
	month = nov,
	year = {2006},
	pages = {316--333},
	file = {Jiang and Clifton - 2006 - A secure distributed framework for achieving k-ano.pdf:/home/erosfabrici/Zotero/storage/9DE4B53G/Jiang and Clifton - 2006 - A secure distributed framework for achieving k-ano.pdf:application/pdf},
}

@article{mohammed_anonymity_2011,
	title = {Anonymity meets game theory: secure data integration with malicious participants},
	volume = {20},
	issn = {1066-8888, 0949-877X},
	shorttitle = {Anonymity meets game theory},
	url = {http://link.springer.com/10.1007/s00778-010-0214-6},
	doi = {10.1007/s00778-010-0214-6},
	abstract = {Data integration methods enable different data providers to ﬂexibly integrate their expertise and deliver highly customizable services to their customers. Nonetheless, combining data from different sources could potentially reveal person-speciﬁc sensitive information. In VLDBJ 2006, Jiang and Clifton (Very Large Data Bases J (VLDBJ) 15(4):316–333, 2006) propose a secure Distributed k-Anonymity (DkA) framework for integrating two private data tables to a k-anonymous table in which each private table is a vertical partition on the same set of records. Their proposed DkA framework is not scalable to large data sets. Moreover, DkA is limited to a two-party scenario and the parties are assumed to be semi-honest. In this paper, we propose two algorithms to securely integrate private data from multiple parties (data providers). Our ﬁrst algorithm achieves the k-anonymity privacy model in a semi-honest adversary model. Our second algorithm employs a game-theoretic approach to thwart malicious participants and to ensure fair and honest participation of multiple data providers in the data integration process. Moreover, we study and resolve a reallife privacy problem in data sharing for the ﬁnancial industry in Sweden. Experiments on the real-life data demonstrate that our proposed algorithms can effectively retain the essential information in anonymous data for data analysis and are scalable for anonymizing large data sets.},
	language = {en},
	number = {4},
	urldate = {2023-01-18},
	journal = {The VLDB Journal},
	author = {Mohammed, Noman and Fung, Benjamin C. M. and Debbabi, Mourad},
	month = aug,
	year = {2011},
	pages = {567--588},
	file = {Mohammed et al. - 2011 - Anonymity meets game theory secure data integrati.pdf:/home/erosfabrici/Zotero/storage/Z6B4Q2C2/Mohammed et al. - 2011 - Anonymity meets game theory secure data integrati.pdf:application/pdf},
}

@inproceedings{Inan2010PrivateRM,
  title={Private record matching using differential privacy},
  author={Ali Inan and Murat Kantarcioglu and Gabriel Ghinita and Elisa Bertino},
  booktitle={International Conference on Extending Database Technology},
  year={2010}
}

@inproceedings{schnell_randomized_2016,
	address = {Barcelona, Spain},
	title = {Randomized {Response} and {Balanced} {Bloom} {Filters} for {Privacy} {Preserving} {Record} {Linkage}},
	isbn = {978-1-5090-5910-2},
	url = {http://ieeexplore.ieee.org/document/7836669/},
	doi = {10.1109/ICDMW.2016.0038},
	abstract = {In most European settings, record linkage across different institutions is based on encrypted personal identiﬁers –such as names, birthdays, or places of birth – to protect privacy. However, in practice up to 20\% of the records may contain errors in identiﬁers. Thus, exact record linkage on encrypted identiﬁers usually results in the loss of large subsets of the data. Such losses usually imply biased statistical estimates since the causes of errors might be correlated with the variables of interest in many applications. Over the past 10 years, the ﬁeld of Privacy Preserving Record Linkage (PPRL) has developed different techniques to link data without revealing the identity of the described entity. However, only few techniques are suitable for applied research with large data bases that include millions of records, which is typical for administrative or medical data bases. Bloom ﬁlters were found to be one successful technique for PPRL when large scale applications are concerned.},
	language = {en},
	urldate = {2023-01-18},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Data} {Mining} {Workshops} ({ICDMW})},
	publisher = {IEEE},
	author = {Schnell, Rainer and Borgs, Christian},
	month = dec,
	year = {2016},
	pages = {218--224},
	file = {Schnell and Borgs - 2016 - Randomized Response and Balanced Bloom Filters for.pdf:/home/erosfabrici/Zotero/storage/QPFTSGY7/Schnell and Borgs - 2016 - Randomized Response and Balanced Bloom Filters for.pdf:application/pdf},
}

@article{schnell2009privacy,
  title={Privacy-preserving record linkage using Bloom filters},
  author={Schnell, Rainer and Bachteler, Tobias and Reiher, J{\"o}rg},
  journal={BMC medical informatics and decision making},
  volume={9},
  number={1},
  pages={1--11},
  year={2009},
  publisher={BioMed Central}
}
@inproceedings{castro_fernandez_seeping_2018,
	address = {Paris},
	title = {Seeping {Semantics}: {Linking} {Datasets} {Using} {Word} {Embeddings} for {Data} {Discovery}},
	isbn = {978-1-5386-5520-7},
	shorttitle = {Seeping {Semantics}},
	url = {https://ieeexplore.ieee.org/document/8509314/},
	doi = {10.1109/ICDE.2018.00093},
	abstract = {Employees that spend more time ﬁnding relevant data than analyzing it suffer from a data discovery problem. The large volume of data in enterprises, and sometimes the lack of knowledge of the schemas aggravates this problem. Similar to how we navigate the Web, we propose to identify semantic links that assist analysts in their discovery tasks. These links relate tables to each other, to facilitate navigating the schemas. They also relate data to external data sources, such as ontologies and dictionaries, to help explain the schema meaning. We materialize the links in an enterprise knowledge graph, where they become available to analysts. The main challenge is how to ﬁnd pairs of objects that are semantically related. We propose SEMPROP, a DAG of different components that ﬁnd links based on syntactic and semantic similarities. SEMPROP is commanded by a semantic matcher which leverages word embeddings to ﬁnd objects that are semantically related. We introduce coherent group, a technique to combine word embeddings that works better than other state of the art combination alternatives. We implement SEMPROP as part of Aurum, a data discovery system we are building, and conduct user studies, real deployments and a quantitative evaluation to understand the beneﬁts of links for data discovery tasks, as well as the beneﬁts of SEMPROP and coherent groups to ﬁnd those links.},
	language = {en},
	urldate = {2023-01-17},
	booktitle = {2018 {IEEE} 34th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Castro Fernandez, Raul and Mansour, Essam and Qahtan, Abdulhakim A. and Elmagarmid, Ahmed and Ilyas, Ihab and Madden, Samuel and Ouzzani, Mourad and Stonebraker, Michael and Tang, Nan},
	month = apr,
	year = {2018},
	pages = {989--1000},
	file = {Castro Fernandez et al. - 2018 - Seeping Semantics Linking Datasets Using Word Emb.pdf:/home/erosfabrici/Zotero/storage/Z5MATQ4H/Castro Fernandez et al. - 2018 - Seeping Semantics Linking Datasets Using Word Emb.pdf:application/pdf},
}

@inproceedings{rindal_malicious-secure_2017,
	address = {Dallas Texas USA},
	title = {Malicious-{Secure} {Private} {Set} {Intersection} via {Dual} {Execution}},
	isbn = {978-1-4503-4946-8},
	url = {https://dl.acm.org/doi/10.1145/3133956.3134044},
	doi = {10.1145/3133956.3134044},
	abstract = {Private set intersection (PSI) allows two parties, who each hold a set of items, to compute the intersection of those sets without revealing anything about other items. Recent advances in PSI have significantly improved its performance for the case of semi-honest security, making semi-honest PSI a practical alternative to insecure methods for computing intersections. However, the semi-honest security model is not always a good fit for real-world problems.},
	language = {en},
	urldate = {2023-01-17},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Rindal, Peter and Rosulek, Mike},
	month = oct,
	year = {2017},
	pages = {1229--1242},
	file = {Rindal and Rosulek - 2017 - Malicious-Secure Private Set Intersection via Dual.pdf:/home/erosfabrici/Zotero/storage/L35XR4ZC/Rindal and Rosulek - 2017 - Malicious-Secure Private Set Intersection via Dual.pdf:application/pdf},
}

@article{wang_improving_2020,
	title = {Improving utility and security of the shuffler-based differential privacy},
	volume = {13},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3424573.3424576},
	doi = {10.14778/3424573.3424576},
	abstract = {When collecting information, local differential privacy (LDP) alleviates privacy concerns of users because their private information is randomized before being sent it to the central aggregator. LDP imposes large amount of noise as each user executes the randomization independently. To address this issue, recent work introduced an intermediate server with the assumption that this intermediate server does not collude with the aggregator. Under this assumption, less noise can be added to achieve the same privacy guarantee as LDP, thus improving utility for the data collection task.},
	language = {en},
	number = {13},
	urldate = {2023-01-17},
	journal = {Proc. VLDB Endow.},
	author = {Wang, Tianhao and Ding, Bolin and Xu, Min and Huang, Zhicong and Hong, Cheng and Zhou, Jingren and Li, Ninghui and Jha, Somesh},
	month = sep,
	year = {2020},
	pages = {3545--3558},
	file = {Wang et al. - 2020 - Improving utility and security of the shuffler-bas.pdf:/home/erosfabrici/Zotero/storage/AQGJDHEM/Wang et al. - 2020 - Improving utility and security of the shuffler-bas.pdf:application/pdf},
}

@techreport{kissner_private_2004,
	address = {Fort Belvoir, VA},
	title = {Private and {Threshold} {Set}-{Intersection}:},
	shorttitle = {Private and {Threshold} {Set}-{Intersection}},
	url = {http://www.dtic.mil/docs/citations/ADA461119},
	language = {en},
	urldate = {2023-01-16},
	institution = {Defense Technical Information Center},
	author = {Kissner, Lea and Song, Dawn},
	month = nov,
	year = {2004},
	doi = {10.21236/ADA461119},
	file = {Kissner and Song - 2004 - Private and Threshold Set-Intersection.pdf:/home/erosfabrici/Zotero/storage/69YSPD3N/Kissner and Song - 2004 - Private and Threshold Set-Intersection.pdf:application/pdf},
}

@article{agrawal_information_nodate,
	title = {Information {Sharing} {Across} {Private} {Databases}},
	abstract = {Literature on information integration across databases tacitly assumes that the data in each database can be revealed to the other databases. However, there is an increasing need for sharing information across autonomous entities in such a way that no information apart from the answer to the query is revealed. We formalize the notion of minimal information sharing across private databases, and develop protocols for intersection, equijoin, intersection size, and equijoin size. We also show how new applications can be built using the proposed protocols.},
	language = {en},
	author = {Agrawal, Rakesh and Evﬁmievski, Alexandre and Srikant, Ramakrishnan},
	file = {Agrawal et al. - Information Sharing Across Private Databases.pdf:/home/erosfabrici/Zotero/storage/9XIX6QSG/Agrawal et al. - Information Sharing Across Private Databases.pdf:application/pdf},
}

@inproceedings{alserafi_towards_2016,
	address = {Barcelona, Spain},
	title = {Towards {Information} {Profiling}: {Data} {Lake} {Content} {Metadata} {Management}},
	isbn = {978-1-5090-5910-2},
	shorttitle = {Towards {Information} {Profiling}},
	url = {http://ieeexplore.ieee.org/document/7836664/},
	doi = {10.1109/ICDMW.2016.0033},
	abstract = {There is currently a burst of Big Data (BD) processed and stored in huge raw data repositories, commonly called Data Lakes (DL). These BD require new techniques of data integration and schema alignment in order to make the data usable by its consumers and to discover the relationships linking their content. This can be provided by metadata services which discover and describe their content. However, there is currently a lack of a systematic approach for such kind of metadata discovery and management. Thus, we propose a framework for the proﬁling of informational content stored in the DL, which we call information proﬁling. The proﬁles are stored as metadata to support data analysis. We formally deﬁne a metadata management process which identiﬁes the key activities required to effectively handle this. We demonstrate the alternative techniques and performance of our process using a prototype implementation handling a real-life case-study from the OpenML DL, which showcases the value and feasibility of our approach.},
	language = {en},
	urldate = {2023-01-12},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Data} {Mining} {Workshops} ({ICDMW})},
	publisher = {IEEE},
	author = {Alserafi, Ayman and Abello, Alberto and Romero, Oscar and Calders, Toon},
	month = dec,
	year = {2016},
	pages = {178--185},
	file = {Alserafi et al. - 2016 - Towards Information Profiling Data Lake Content M.pdf:/home/erosfabrici/Zotero/storage/NY6FDDTB/Alserafi et al. - 2016 - Towards Information Profiling Data Lake Content M.pdf:application/pdf},
}

@inproceedings{cappuzzo_creating_2020,
	address = {Portland OR USA},
	title = {Creating {Embeddings} of {Heterogeneous} {Relational} {Datasets} for {Data} {Integration} {Tasks}},
	isbn = {978-1-4503-6735-6},
	url = {https://dl.acm.org/doi/10.1145/3318464.3389742},
	doi = {10.1145/3318464.3389742},
	abstract = {Deep learning based techniques have been recently used with promising results for data integration problems. Some methods directly use pre-trained embeddings that were trained on a large corpus such as Wikipedia. However, they may not always be an appropriate choice for enterprise datasets with custom vocabulary. Other methods adapt techniques from natural language processing to obtain embeddings for the enterprise’s relational data. However, this approach blindly treats a tuple as a sentence, thus losing a large amount of contextual information present in the tuple.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Proceedings of the 2020 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Cappuzzo, Riccardo and Papotti, Paolo and Thirumuruganathan, Saravanan},
	month = jun,
	year = {2020},
	pages = {1335--1349},
	file = {Cappuzzo et al. - 2020 - Creating Embeddings of Heterogeneous Relational Da.pdf:/home/erosfabrici/Zotero/storage/P538Q2LF/Cappuzzo et al. - 2020 - Creating Embeddings of Heterogeneous Relational Da.pdf:application/pdf},
}

@inproceedings{zhang_statistical_2020,
	address = {Portland OR USA},
	title = {A {Statistical} {Perspective} on {Discovering} {Functional} {Dependencies} in {Noisy} {Data}},
	isbn = {978-1-4503-6735-6},
	url = {https://dl.acm.org/doi/10.1145/3318464.3389749},
	doi = {10.1145/3318464.3389749},
	abstract = {We study the problem of discovering functional dependencies (FD) from a noisy data set. We adopt a statistical perspective and draw connections between FD discovery and structure learning in probabilistic graphical models. We show that discovering FDs from a noisy data set is equivalent to learning the structure of a model over binary random variables, where each random variable corresponds to a functional of the data set attributes. We build upon this observation to introduce FDX a conceptually simple framework in which learning functional dependencies corresponds to solving a sparse regression problem. We show that FDX can recover true functional dependencies across a diverse array of realworld and synthetic data sets, even in the presence of noisy or missing data. We find that FDX scales to large data instances with millions of tuples and hundreds of attributes while it yields an average F1 improvement of 2× against state-of-the-art FD discovery methods.},
	language = {en},
	urldate = {2023-01-11},
	booktitle = {Proceedings of the 2020 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Zhang, Yunjia and Guo, Zhihan and Rekatsinas, Theodoros},
	month = jun,
	year = {2020},
	pages = {861--876},
	file = {Zhang et al. - 2020 - A Statistical Perspective on Discovering Functiona.pdf:/home/erosfabrici/Zotero/storage/4G696A6D/Zhang et al. - 2020 - A Statistical Perspective on Discovering Functiona.pdf:application/pdf},
}

@inproceedings{hai_constance_2016,
	address = {San Francisco California USA},
	title = {Constance: {An} {Intelligent} {Data} {Lake} {System}},
	isbn = {978-1-4503-3531-7},
	shorttitle = {Constance},
	url = {https://dl.acm.org/doi/10.1145/2882903.2899389},
	doi = {10.1145/2882903.2899389},
	abstract = {As the challenge of our time, Big Data still has many research hassles, especially the variety of data. The high diversity of data sources often results in information silos, a collection of non-integrated data management systems with heterogeneous schemas, query languages, and APIs. Data Lake systems have been proposed as a solution to this problem, by providing a schema-less repository for raw data with a common access interface. However, just dumping all data into a data lake without any metadata management, would only lead to a ‘data swamp’. To avoid this, we propose Constance1, a Data Lake system with sophisticated metadata management over raw data extracted from heterogeneous data sources. Constance discovers, extracts, and summarizes the structural metadata from the data sources, and annotates data and metadata with semantic information to avoid ambiguities. With embedded query rewriting engines supporting structured data and semi-structured data, Constance provides users a uniﬁed interface for query processing and data exploration. During the demo, we will walk through each functional component of Constance. Constance will be applied to two real-life use cases in order to show attendees the importance and usefulness of our generic and extensible data lake system.},
	language = {en},
	urldate = {2023-01-09},
	booktitle = {Proceedings of the 2016 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Hai, Rihan and Geisler, Sandra and Quix, Christoph},
	month = jun,
	year = {2016},
	pages = {2097--2100},
	file = {Hai et al. - 2016 - Constance An Intelligent Data Lake System.pdf:/home/erosfabrici/Zotero/storage/PEXCJ5W7/Hai et al. - 2016 - Constance An Intelligent Data Lake System.pdf:application/pdf},
}

@article{bernstein_generic_2011,
	title = {Generic schema matching, ten years later},
	volume = {4},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3402707.3402710},
	doi = {10.14778/3402707.3402710},
	abstract = {In a paper published in the 2001 VLDB Conference, we proposed treating generic schema matching as an independent problem. We developed a taxonomy of existing techniques, a new schema matching algorithm, and an approach to comparative evaluation. Since then, the field has grown into a major research topic. We briefly summarize the new techniques that have been developed and applications of the techniques in the commercial world. We conclude by discussing future trends and recommendations for further work.},
	language = {en},
	number = {11},
	urldate = {2023-01-09},
	journal = {Proc. VLDB Endow.},
	author = {Bernstein, Philip A. and Madhavan, Jayant and Rahm, Erhard},
	month = aug,
	year = {2011},
	pages = {695--701},
	file = {Bernstein et al. - 2011 - Generic schema matching, ten years later.pdf:/home/erosfabrici/Zotero/storage/JZRF6N3V/Bernstein et al. - 2011 - Generic schema matching, ten years later.pdf:application/pdf},
}

@incollection{hutchison_instance-based_2012,
	address = {Berlin, Heidelberg},
	title = {Instance-{Based} {Matching} of {Large} {Ontologies} {Using} {Locality}-{Sensitive} {Hashing}},
	volume = {7649},
	isbn = {978-3-642-35175-4 978-3-642-35176-1},
	url = {http://link.springer.com/10.1007/978-3-642-35176-1_4},
	abstract = {In this paper, we describe a mechanism for ontology alignment using instance based matching of types (or classes). Instance-based matching is known to be a useful technique for matching ontologies that have diﬀerent names and diﬀerent structures. A key problem in instance matching of types, however, is scaling the matching algorithm to (a) handle types with a large number of instances, and (b) eﬃciently match a large number of type pairs. We propose the use of state-of-the art locality-sensitive hashing (LSH) techniques to vastly improve the scalability of instance matching across multiple types. We show the feasibility of our approach with DBpedia and Freebase, two diﬀerent type systems with hundreds and thousands of types, respectively. We describe how these techniques can be used to estimate containment or equivalence relations between two type systems, and we compare two diﬀerent LSH techniques for computing instance similarity.},
	language = {en},
	urldate = {2023-01-08},
	booktitle = {The {Semantic} {Web} – {ISWC} 2012},
	publisher = {Springer Berlin Heidelberg},
	author = {Duan, Songyun and Fokoue, Achille and Hassanzadeh, Oktie and Kementsietsidis, Anastasios and Srinivas, Kavitha and Ward, Michael J.},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Cudré-Mauroux, Philippe and Heflin, Jeff and Sirin, Evren and Tudorache, Tania and Euzenat, Jérôme and Hauswirth, Manfred and Parreira, Josiane Xavier and Hendler, Jim and Schreiber, Guus and Bernstein, Abraham and Blomqvist, Eva},
	year = {2012},
	doi = {10.1007/978-3-642-35176-1_4},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {49--64},
	file = {Duan et al. - 2012 - Instance-Based Matching of Large Ontologies Using .pdf:/home/erosfabrici/Zotero/storage/52YLA47R/Duan et al. - 2012 - Instance-Based Matching of Large Ontologies Using .pdf:application/pdf},
}

@article{gopi_differentially_2021,
	title = {Differentially {Private} {Set} {Union}},
	volume = {11},
	issn = {2575-8527},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/780},
	doi = {10.29012/jpc.780},
	abstract = {We study the basic operation of set union in the global model of differential privacy. In this problem, we are given a universe U of items, possibly of inﬁnite size, and a database D of users. Each user i contributes a subset Wi ⊆ U of items. We want an (ε,δ)-differentially private Algorithm which outputs a subset S ⊂ ∪iWi such that the size of S is as large as possible. The problem arises in countless real world applications, and is particularly ubiquitous in natural language processing (NLP) applications. For example, discovering words, sentences, n-grams etc., from private text data belonging to users is an instance of the set union problem. In this paper we design new algorithms for this problem that signiﬁcantly outperform the best known algorithms.},
	language = {en},
	number = {3},
	urldate = {2023-01-08},
	journal = {JPC},
	author = {Gopi, Sivakanth and Gulhane, Pankaj and Kulkarni, Janardhan and Shen, Judy Hanwen and Shokouhi, Milad and Yekhanin, Sergey},
	month = dec,
	year = {2021},
	file = {Gopi et al. - 2021 - Differentially Private Set Union.pdf:/home/erosfabrici/Zotero/storage/I4QYQ9BN/Gopi et al. - 2021 - Differentially Private Set Union.pdf:application/pdf},
}

@inproceedings{zhu_lsh_2016,
	title = {{LSH} {Ensemble}: {Internet}-{Scale} {Domain} {Search}},
	shorttitle = {{LSH} {Ensemble}},
	url = {http://arxiv.org/abs/1603.07410},
	abstract = {We study the problem of domain search where a domain is a set of distinct values from an unspeciﬁed universe. We use Jaccard set containment score, deﬁned as {\textbar}Q ∩ X{\textbar}/{\textbar}Q{\textbar}, as the measure of relevance of a domain X to a query domain Q. Our choice of Jaccard set containment over Jaccard similarity as a measure of relevance makes our work particularly suitable for searching Open Data and data on the web, as Jaccard similarity is known to have poor performance over sets with large diﬀerences in their domain sizes. We demonstrate that the domains found in several real-life Open Data and web data repositories show a power-law distribution over their domain sizes.},
	language = {en},
	urldate = {2023-01-06},
	publisher = {arXiv},
	author = {Zhu, Erkang and Nargesian, Fatemeh and Pu, Ken Q. and Miller, Renée J.},
	month = jul,
	year = {2016},
	note = {arXiv:1603.07410 [cs]},
	keywords = {Computer Science - Databases, H.2.5, H.3.1, H.3.3},
	file = {Zhu et al. - 2016 - LSH Ensemble Internet-Scale Domain Search.pdf:/home/erosfabrici/Zotero/storage/2MBRILSH/Zhu et al. - 2016 - LSH Ensemble Internet-Scale Domain Search.pdf:application/pdf},
}

@inproceedings{cormode_differentially_2012-1,
	address = {Berlin, Germany},
	title = {Differentially private summaries for sparse data},
	isbn = {978-1-4503-0791-8},
	url = {http://dl.acm.org/citation.cfm?doid=2274576.2274608},
	doi = {10.1145/2274576.2274608},
	abstract = {Differential privacy is fast becoming the method of choice for releasing data under strong privacy guarantees. A standard mechanism is to add noise to the counts in contingency tables derived from the dataset. However, when the dataset is sparse in its underlying domain, this vastly increases the size of the published data, to the point of making the mechanism infeasible.},
	language = {en},
	urldate = {2022-12-25},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Database} {Theory} - {ICDT} '12},
	publisher = {ACM Press},
	author = {Cormode, Graham and Procopiuc, Cecilia and Srivastava, Divesh and Tran, Thanh T. L.},
	year = {2012},
	pages = {299},
	file = {Cormode et al. - 2012 - Differentially private summaries for sparse data.pdf:/home/erosfabrici/Zotero/storage/DJMWELAL/Cormode et al. - 2012 - Differentially private summaries for sparse data.pdf:application/pdf},
}

@article{cormode_evaluation_2018,
	title = {An evaluation of multi-probe locality sensitive hashing for computing similarities over web-scale query logs},
	volume = {13},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0191175},
	doi = {10.1371/journal.pone.0191175},
	language = {en},
	number = {1},
	urldate = {2022-12-25},
	journal = {PLoS ONE},
	author = {Cormode, Graham and Dasgupta, Anirban and Goyal, Amit and Lee, Chi Hoon},
	editor = {Wang, Yeng-Tseng},
	month = jan,
	year = {2018},
	pages = {e0191175},
	file = {Cormode et al. - 2018 - An evaluation of multi-probe locality sensitive ha.pdf:/home/erosfabrici/Zotero/storage/6KD3XGBE/Cormode et al. - 2018 - An evaluation of multi-probe locality sensitive ha.pdf:application/pdf},
}

@misc{chen_communication_2022,
	title = {The communication cost of security and privacy in federated frequency estimation},
	url = {http://arxiv.org/abs/2211.10041},
	abstract = {We consider the federated frequency estimation problem, where each user holds a private item \$X\_i\$ from a size-\$d\$ domain and a server aims to estimate the empirical frequency (i.e., histogram) of \$n\$ items with \$n {\textbackslash}ll d\$. Without any security and privacy considerations, each user can communicate its item to the server by using \${\textbackslash}log d\$ bits. A naive application of secure aggregation protocols would, however, require \$d{\textbackslash}log n\$ bits per user. Can we reduce the communication needed for secure aggregation, and does security come with a fundamental cost in communication? In this paper, we develop an information-theoretic model for secure aggregation that allows us to characterize the fundamental cost of security and privacy in terms of communication. We show that with security (and without privacy) \${\textbackslash}Omega{\textbackslash}left( n {\textbackslash}log d {\textbackslash}right)\$ bits per user are necessary and sufficient to allow the server to compute the frequency distribution. This is significantly smaller than the \$d{\textbackslash}log n\$ bits per user needed by the naive scheme, but significantly higher than the \${\textbackslash}log d\$ bits per user needed without security. To achieve differential privacy, we construct a linear scheme based on a noisy sketch which locally perturbs the data and does not require a trusted server (a.k.a. distributed differential privacy). We analyze this scheme under \${\textbackslash}ell\_2\$ and \${\textbackslash}ell\_{\textbackslash}infty\$ loss. By using our information-theoretic framework, we show that the scheme achieves the optimal accuracy-privacy trade-off with optimal communication cost, while matching the performance in the centralized case where data is stored in the central server.},
	language = {en},
	urldate = {2022-12-25},
	publisher = {arXiv},
	author = {Chen, Wei-Ning and Özgür, Ayfer and Cormode, Graham and Bharadwaj, Akash},
	month = nov,
	year = {2022},
	note = {arXiv:2211.10041 [cs, math]},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Information Theory},
	file = {Chen et al. - 2022 - The communication cost of security and privacy in .pdf:/home/erosfabrici/Zotero/storage/8YXAXYVW/Chen et al. - 2022 - The communication cost of security and privacy in .pdf:application/pdf},
}

@misc{huang_frequency_2021,
	title = {Frequency {Estimation} {Under} {Multiparty} {Differential} {Privacy}: {One}-shot and {Streaming}},
	shorttitle = {Frequency {Estimation} {Under} {Multiparty} {Differential} {Privacy}},
	url = {http://arxiv.org/abs/2104.01808},
	abstract = {We study the fundamental problem of frequency estimation under both privacy and communication constraints, where the data is distributed among \$k\$ parties. We consider two application scenarios: (1) one-shot, where the data is static and the aggregator conducts a one-time computation; and (2) streaming, where each party receives a stream of items over time and the aggregator continuously monitors the frequencies. We adopt the model of multiparty differential privacy (MDP), which is more general than local differential privacy (LDP) and (centralized) differential privacy. Our protocols achieve optimality (up to logarithmic factors) permissible by the more stringent of the two constraints. In particular, when specialized to the \${\textbackslash}varepsilon\$-LDP model, our protocol achieves an error of \${\textbackslash}sqrt\{k\}/(e{\textasciicircum}\{{\textbackslash}Theta({\textbackslash}varepsilon)\}-1)\$ using \$O(k{\textbackslash}max{\textbackslash}\{ {\textbackslash}varepsilon, {\textbackslash}frac\{1\}\{{\textbackslash}varepsilon\} {\textbackslash}\})\$ bits of communication and \$O(k {\textbackslash}log u)\$ bits of public randomness, where \$u\$ is the size of the domain.},
	language = {en},
	urldate = {2022-12-25},
	publisher = {arXiv},
	author = {Huang, Ziyue and Qiu, Yuan and Yi, Ke and Cormode, Graham},
	month = may,
	year = {2021},
	note = {arXiv:2104.01808 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Data Structures and Algorithms},
	file = {Huang et al. - 2021 - Frequency Estimation Under Multiparty Differential.pdf:/home/erosfabrici/Zotero/storage/CG3MSDSC/Huang et al. - 2021 - Frequency Estimation Under Multiparty Differential.pdf:application/pdf},
}

@inproceedings{zhang_finding_2020,
	address = {Portland OR USA},
	title = {Finding {Related} {Tables} in {Data} {Lakes} for {Interactive} {Data} {Science}},
	isbn = {978-1-4503-6735-6},
	url = {https://dl.acm.org/doi/10.1145/3318464.3389726},
	doi = {10.1145/3318464.3389726},
	abstract = {Many modern data science applications build on data lakes, schema-agnostic repositories of data files and data products that offer limited organization and management capabilities. There is a need to build data lake search capabilities into data science environments, so scientists and analysts can find tables, schemas, workflows, and datasets useful to their task at hand. We develop search and management solutions for the Jupyter Notebook data science platform, to enable scientists to augment training data, find potential features to extract, clean data, and find joinable or linkable tables. Our core methods also generalize to other settings where computational tasks involve execution of programs or scripts.},
	language = {en},
	urldate = {2022-12-24},
	booktitle = {Proceedings of the 2020 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Zhang, Yi and Ives, Zachary G.},
	month = jun,
	year = {2020},
	pages = {1951--1966},
	file = {Zhang and Ives - 2020 - Finding Related Tables in Data Lakes for Interacti.pdf:/home/erosfabrici/Zotero/storage/4IL4VYMA/Zhang and Ives - 2020 - Finding Related Tables in Data Lakes for Interacti.pdf:application/pdf},
}

@inproceedings{zhang_automatic_2011,
	address = {Athens, Greece},
	title = {Automatic discovery of attributes in relational databases},
	isbn = {978-1-4503-0661-4},
	url = {http://portal.acm.org/citation.cfm?doid=1989323.1989336},
	doi = {10.1145/1989323.1989336},
	abstract = {In this work we design algorithms for clustering relational columns into attributes, i.e., for identifying strong relationships between columns based on the common properties and characteristics of the values they contain. For example, identifying whether a certain set of columns refers to telephone numbers versus social security numbers, or names of customers versus names of nations. Traditional relational database schema languages use very limited primitive data types and simple foreign key constraints to express relationships between columns. Object oriented schema languages allow the deﬁnition of custom data types; still, certain relationships between columns might be unknown at design time or they might appear only in a particular database instance. Nevertheless, these relationships are an invaluable tool for schema matching, and generally for better understanding and working with the data. Here, we introduce data oriented solutions (we do not consider solutions that assume the existence of any external knowledge) that use statistical measures to identify strong relationships between the values of a set of columns. Interpreting the database as a graph where nodes correspond to database columns and edges correspond to column relationships, we decompose the graph into connected components and cluster sets of columns into attributes. To test the quality of our solution, we also provide a comprehensive experimental evaluation using real and synthetic datasets.},
	language = {en},
	urldate = {2022-12-22},
	booktitle = {Proceedings of the 2011 international conference on {Management} of data - {SIGMOD} '11},
	publisher = {ACM Press},
	author = {Zhang, Meihui and Hadjieleftheriou, Marios and Ooi, Beng Chin and Procopiuc, Cecilia M. and Srivastava, Divesh},
	year = {2011},
	pages = {109},
	file = {Zhang et al. - 2011 - Automatic discovery of attributes in relational da.pdf:/home/erosfabrici/Zotero/storage/TWWX4SYB/Zhang et al. - 2011 - Automatic discovery of attributes in relational da.pdf:application/pdf},
}

@inproceedings{mudgal_deep_2018,
	address = {Houston TX USA},
	title = {Deep {Learning} for {Entity} {Matching}: {A} {Design} {Space} {Exploration}},
	isbn = {978-1-4503-4703-7},
	shorttitle = {Deep {Learning} for {Entity} {Matching}},
	url = {https://dl.acm.org/doi/10.1145/3183713.3196926},
	doi = {10.1145/3183713.3196926},
	abstract = {Entity matching (EM) finds data instances that refer to the same real-world entity. In this paper we examine applying deep learning (DL) to EM, to understand DL’s benefits and limitations. We review many DL solutions that have been developed for related matching tasks in text processing (e.g., entity linking, textual entailment, etc.). We categorize these solutions and define a space of DL solutions for EM, as embodied by four solutions with varying representational power: SIF, RNN, Attention, and Hybrid. Next, we investigate the types of EM problems for which DL can be helpful. We consider three such problem types, which match structured data instances, textual instances, and dirty instances, respectively. We empirically compare the above four DL solutions with Magellan, a state-of-the-art learning-based EM solution. The results show that DL does not outperform current solutions on structured EM, but it can significantly outperform them on textual and dirty EM. For practitioners, this suggests that they should seriously consider using DL for textual and dirty EM problems. Finally, we analyze DL’s performance and discuss future research directions.},
	language = {en},
	urldate = {2022-12-22},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Mudgal, Sidharth and Li, Han and Rekatsinas, Theodoros and Doan, AnHai and Park, Youngchoon and Krishnan, Ganesh and Deep, Rohit and Arcaute, Esteban and Raghavendra, Vijay},
	month = may,
	year = {2018},
	pages = {19--34},
	file = {Mudgal et al. - 2018 - Deep Learning for Entity Matching A Design Space .pdf:/home/erosfabrici/Zotero/storage/5J4NFCKC/Mudgal et al. - 2018 - Deep Learning for Entity Matching A Design Space .pdf:application/pdf},
}

@inproceedings{golshan_data_2017,
	address = {Chicago Illinois USA},
	title = {Data {Integration}: {After} the {Teenage} {Years}},
	isbn = {978-1-4503-4198-1},
	shorttitle = {Data {Integration}},
	url = {https://dl.acm.org/doi/10.1145/3034786.3056124},
	doi = {10.1145/3034786.3056124},
	abstract = {The ﬁeld of data integration has expanded signiﬁcantly over the years, from providing a uniform query and update interface to structured databases within an enterprise to the ability to search, exchange, and even update, structured or unstructured data that are within or external to the enterprise.},
	language = {en},
	urldate = {2022-12-22},
	booktitle = {Proceedings of the 36th {ACM} {SIGMOD}-{SIGACT}-{SIGAI} {Symposium} on {Principles} of {Database} {Systems}},
	publisher = {ACM},
	author = {Golshan, Behzad and Halevy, Alon and Mihaila, George and Tan, Wang-Chiew},
	month = may,
	year = {2017},
	pages = {101--106},
	file = {Golshan et al. - 2017 - Data Integration After the Teenage Years.pdf:/home/erosfabrici/Zotero/storage/U2KEJWVS/Golshan et al. - 2017 - Data Integration After the Teenage Years.pdf:application/pdf},
}

@article{sagi_schema_2013,
	title = {Schema matching prediction with applications to data source discovery and dynamic ensembling},
	volume = {22},
	issn = {1066-8888, 0949-877X},
	url = {http://link.springer.com/10.1007/s00778-013-0325-y},
	doi = {10.1007/s00778-013-0325-y},
	abstract = {Web-scale data integration involves fully automated efforts which lack knowledge of the exact match between data descriptions. In this paper, we introduce schema matching prediction, an assessment mechanism to support schema matchers in the absence of an exact match. Given attribute pair-wise similarity measures, a predictor predicts the success of a matcher in identifying correct correspondences. We present a comprehensive framework in which predictors can be deﬁned, designed, and evaluated. We formally deﬁne schema matching evaluation and schema matching prediction using similarity spaces and discuss a set of four desirable properties of predictors, namely correlation, robustness, tunability, and generalization. We present a method for constructing predictors, supporting generalization, and introduce prediction models as means of tuning prediction toward various quality measures. We deﬁne the empirical properties of correlation and robustness and provide concrete measures for their evaluation. We illustrate the usefulness of schema matching prediction by presenting three use cases: We propose a method for ranking the relevance of deep Web sources with respect to given user needs. We show how predictors can assist in the design of schema matching systems. Finally, we show how prediction can support dynamic weight setting of matchers in an ensemble, thus improving upon current stateof-the-art weight setting methods. An extensive empirical evaluation shows the usefulness of predictors in these use cases and demonstrates the usefulness of prediction models in increasing the performance of schema matching.},
	language = {en},
	number = {5},
	urldate = {2022-12-21},
	journal = {The VLDB Journal},
	author = {Sagi, Tomer and Gal, Avigdor},
	month = oct,
	year = {2013},
	pages = {689--710},
	file = {Sagi and Gal - 2013 - Schema matching prediction with applications to da.pdf:/home/erosfabrici/Zotero/storage/LX75895G/Sagi and Gal - 2013 - Schema matching prediction with applications to da.pdf:application/pdf},
}

@article{esmailoghli_mate_2022,
	title = {{MATE}: multi-attribute table extraction},
	volume = {15},
	issn = {2150-8097},
	shorttitle = {{MATE}},
	url = {https://dl.acm.org/doi/10.14778/3529337.3529353},
	doi = {10.14778/3529337.3529353},
	abstract = {A core operation in data discovery is to find joinable tables for a given table. Real-world tables include both unary and n-ary join keys. However, existing table discovery systems are optimized for unary joins and are ineffective and slow in the existence of n-ary keys. In this paper, we introduce Mate, a table discovery system that leverages a novel hash-based index that enables n-ary join discovery through a space-efficient super key. We design a filtering layer that uses a novel hash, Xash. This hash function encodes the syntactic features of all column values and aggregates them into a super key, which allows the system to efficiently prune tables with non-joinable rows. Our join discovery system is able to prune up to 1000𝑥 more false positives and leads to over 60𝑥 faster table discovery in comparison to state-of-the-art.},
	language = {en},
	number = {8},
	urldate = {2022-12-21},
	journal = {Proc. VLDB Endow.},
	author = {Esmailoghli, Mahdi and Quiané-Ruiz, Jorge-Arnulfo and Abedjan, Ziawasch},
	month = apr,
	year = {2022},
	pages = {1684--1696},
	file = {Esmailoghli et al. - 2022 - MATE multi-attribute table extraction.pdf:/home/erosfabrici/Zotero/storage/BUKP6GKH/Esmailoghli et al. - 2022 - MATE multi-attribute table extraction.pdf:application/pdf},
}

@article{jaiswal_uninterpreted_2010,
	title = {Uninterpreted {Schema} {Matching} with {Embedded} {Value} {Mapping} under {Opaque} {Column} {Names} and {Data} {Values}},
	volume = {22},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/4799783/},
	doi = {10.1109/TKDE.2009.69},
	abstract = {Schema matching and value mapping across two heterogenous information sources are critical tasks in applications involving data integration, data warehousing, and federation of databases. Before data can be integrated from multiple tables, the columns and the values appearing in the tables must be matched. The complexity of the problem grows quickly with the number of data attributes/columns to be matched and due to multiple semantics of data values. Traditional research has tackled schema matching and value mapping independently. We propose a novel method that optimizes embedded value mappings to enhance schema matching in the presence of opaque data values and column names. In this approach, the fitness objective for matching a pair of attributes from two schemas depends on the value mapping function for each of the two attributes. Suitable fitness objectives include the euclidean distance measure, which we use in our experimental study, as well as relative (cross) entropy. We propose a heuristic local descent optimization strategy that uses sorting and two-opt switching to jointly optimize value mappings and attribute matches. Our experiments show that our proposed technique outperforms earlier uninterpreted schema matching methods, and thus, should form a useful addition to a suite of (semi) automated tools for resolving structural heterogeneity.},
	language = {en},
	number = {2},
	urldate = {2022-12-21},
	journal = {IEEE Trans. Knowl. Data Eng.},
	author = {Jaiswal, Anuj and Miller, David J. and Mitra, Prasenjit},
	month = feb,
	year = {2010},
	pages = {291--304},
	file = {Jaiswal et al. - 2010 - Uninterpreted Schema Matching with Embedded Value .pdf:/home/erosfabrici/Zotero/storage/K4Y9J9AA/Jaiswal et al. - 2010 - Uninterpreted Schema Matching with Embedded Value .pdf:application/pdf},
}

@misc{suchanek_paris_2011,
	title = {{PARIS}: {Probabilistic} {Alignment} of {Relations}, {Instances}, and {Schema}},
	shorttitle = {{PARIS}},
	url = {http://arxiv.org/abs/1111.7164},
	abstract = {One of the main challenges that the Semantic Web faces is the integration of a growing number of independently designed ontologies. In this work, we present paris, an approach for the automatic alignment of ontologies. paris aligns not only instances, but also relations and classes. Alignments at the instance level cross-fertilize with alignments at the schema level. Thereby, our system provides a truly holistic solution to the problem of ontology alignment. The heart of the approach is probabilistic, i.e., we measure degrees of matchings based on probability estimates. This allows paris to run without any parameter tuning. We demonstrate the eﬃciency of the algorithm and its precision through extensive experiments. In particular, we obtain a precision of around 90 \% in experiments with some of the world’s largest ontologies.},
	language = {en},
	urldate = {2022-12-21},
	publisher = {arXiv},
	author = {Suchanek, Fabian M. and Abiteboul, Serge and Senellart, Pierre},
	month = nov,
	year = {2011},
	note = {arXiv:1111.7164 [cs]},
	keywords = {Computer Science - Databases},
	file = {Suchanek et al. - 2011 - PARIS Probabilistic Alignment of Relations, Insta.pdf:/home/erosfabrici/Zotero/storage/CV5FBBWV/Suchanek et al. - 2011 - PARIS Probabilistic Alignment of Relations, Insta.pdf:application/pdf},
}

@inproceedings{gubanov_polyfuse_2017,
	address = {San Diego, CA, USA},
	title = {{PolyFuse}: {A} {Large}-{Scale} {Hybrid} {Data} {Fusion} {System}},
	isbn = {978-1-5090-6543-1},
	shorttitle = {{PolyFuse}},
	url = {http://ieeexplore.ieee.org/document/7930127/},
	doi = {10.1109/ICDE.2017.230},
	language = {en},
	urldate = {2022-12-21},
	booktitle = {2017 {IEEE} 33rd {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Gubanov, Michael},
	month = apr,
	year = {2017},
	pages = {1575--1578},
	file = {Gubanov - 2017 - PolyFuse A Large-Scale Hybrid Data Fusion System.pdf:/home/erosfabrici/Zotero/storage/FSS3Y4VP/Gubanov - 2017 - PolyFuse A Large-Scale Hybrid Data Fusion System.pdf:application/pdf},
}

@article{mohammed_anonymity_2011-1,
	title = {Anonymity meets game theory: secure data integration with malicious participants},
	volume = {20},
	issn = {1066-8888, 0949-877X},
	shorttitle = {Anonymity meets game theory},
	url = {http://link.springer.com/10.1007/s00778-010-0214-6},
	doi = {10.1007/s00778-010-0214-6},
	abstract = {Data integration methods enable different data providers to ﬂexibly integrate their expertise and deliver highly customizable services to their customers. Nonetheless, combining data from different sources could potentially reveal person-speciﬁc sensitive information. In VLDBJ 2006, Jiang and Clifton (Very Large Data Bases J (VLDBJ) 15(4):316–333, 2006) propose a secure Distributed k-Anonymity (DkA) framework for integrating two private data tables to a k-anonymous table in which each private table is a vertical partition on the same set of records. Their proposed DkA framework is not scalable to large data sets. Moreover, DkA is limited to a two-party scenario and the parties are assumed to be semi-honest. In this paper, we propose two algorithms to securely integrate private data from multiple parties (data providers). Our ﬁrst algorithm achieves the k-anonymity privacy model in a semi-honest adversary model. Our second algorithm employs a game-theoretic approach to thwart malicious participants and to ensure fair and honest participation of multiple data providers in the data integration process. Moreover, we study and resolve a reallife privacy problem in data sharing for the ﬁnancial industry in Sweden. Experiments on the real-life data demonstrate that our proposed algorithms can effectively retain the essential information in anonymous data for data analysis and are scalable for anonymizing large data sets.},
	language = {en},
	number = {4},
	urldate = {2022-12-21},
	journal = {The VLDB Journal},
	author = {Mohammed, Noman and Fung, Benjamin C. M. and Debbabi, Mourad},
	month = aug,
	year = {2011},
	pages = {567--588},
	file = {Mohammed et al. - 2011 - Anonymity meets game theory secure data integrati.pdf:/home/erosfabrici/Zotero/storage/BN6A3LW7/Mohammed et al. - 2011 - Anonymity meets game theory secure data integrati.pdf:application/pdf},
}

@article{zhao_survey_2022,
	title = {A {Survey} on {Differential} {Privacy} for {Unstructured} {Data} {Content}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3490237},
	doi = {10.1145/3490237},
	abstract = {Huge amounts of unstructured data including image, video, audio, and text are ubiquitously generated and shared, and it is a challenge to protect sensitive personal information in them, such as human faces, voiceprints, and authorships. Differential privacy is the standard privacy protection technology that provides rigorous privacy guarantees for various data. This survey summarizes and analyzes differential privacy solutions to protect unstructured data content before it is shared with untrusted parties. These differential privacy methods obfuscate unstructured data after they are represented with vectors and then reconstruct them with obfuscated vectors. We summarize specific privacy models and mechanisms together with possible challenges in them. We also discuss their privacy guarantees against AI attacks and utility losses. Finally, we discuss several possible directions for future research.},
	language = {en},
	number = {10s},
	urldate = {2022-12-16},
	journal = {ACM Comput. Surv.},
	author = {Zhao, Ying and Chen, Jinjun},
	month = jan,
	year = {2022},
	pages = {1--28},
	file = {Zhao and Chen - 2022 - A Survey on Differential Privacy for Unstructured .pdf:/home/erosfabrici/Zotero/storage/96HK8JR9/Zhao and Chen - 2022 - A Survey on Differential Privacy for Unstructured .pdf:application/pdf},
}

@inproceedings{kimmig_collective_2017,
	address = {San Diego, CA, USA},
	title = {A {Collective}, {Probabilistic} {Approach} to {Schema} {Mapping}},
	isbn = {978-1-5090-6543-1},
	url = {http://ieeexplore.ieee.org/document/7930036/},
	doi = {10.1109/ICDE.2017.140},
	abstract = {We propose a probabilistic approach to the problem of schema mapping. Our approach is declarative, scalable, and extensible. It builds upon recent results in both schema mapping and probabilistic reasoning and contributes novel techniques in both ﬁelds. We introduce the problem of mapping selection, that is, choosing the best mapping from a space of potential mappings, given both metadata constraints and a data example. As selection has to reason holistically about the inputs and the dependencies between the chosen mappings, we deﬁne a new schema mapping optimization problem which captures interactions between mappings. We then introduce Collective Mapping Discovery (CMD), our solution to this problem using stateof-the-art probabilistic reasoning techniques, which allows for inconsistencies and incompleteness. Using hundreds of realistic integration scenarios, we demonstrate that the accuracy of CMD is more than 33\% above that of metadata-only approaches already for small data examples, and that CMD routinely ﬁnds perfect mappings even if a quarter of the data is inconsistent.},
	language = {en},
	urldate = {2022-12-16},
	booktitle = {2017 {IEEE} 33rd {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Kimmig, Angelika and Memory, Alex and Miller, Renee J. and Getoor, Lise},
	month = apr,
	year = {2017},
	pages = {921--932},
	file = {Kimmig et al. - 2017 - A Collective, Probabilistic Approach to Schema Map.pdf:/home/erosfabrici/Zotero/storage/GJFVR9BR/Kimmig et al. - 2017 - A Collective, Probabilistic Approach to Schema Map.pdf:application/pdf},
}

@article{bonomi_mining_2013,
	title = {Mining frequent patterns with differential privacy},
	volume = {6},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/2536274.2536329},
	doi = {10.14778/2536274.2536329},
	abstract = {The mining of frequent patterns is a fundamental component in many data mining tasks. A considerable amount of research on this problem has led to a wide series of efﬁcient and scalable algorithms for mining frequent patterns. However, releasing these patterns is posing concerns on the privacy of the users participating in the data. Indeed the information from the patterns can be linked with a large amount of data available from other sources creating opportunities for adversaries to break the individual privacy of the users and disclose sensitive information. In this proposal, we study the mining of frequent patterns in a privacy preserving setting. We ﬁrst investigate the difference between sequential and itemset patterns, and second we extend the deﬁnition of patterns by considering the absence and presence of noise in the data. This leads us in distinguishing the patterns between exact and noisy. For exact patterns, we describe two novel mining techniques that we previously developed. The ﬁrst approach has been applied in a privacy preserving record linkage setting, where our solution is used to mine frequent patterns which are employed in a secure transformation procedure to link records that are similar. The second approach improves the mining utility results using a two-phase strategy which allows to effectively mine frequent substrings as well as preﬁxes patterns. For noisy patterns, ﬁrst we formally deﬁne the patterns according to the type of noise and second we provide a set of potential applications that require the mining of these patterns. We conclude the paper by stating the challenges in this new setting and possible future research directions.},
	language = {en},
	number = {12},
	urldate = {2022-12-16},
	journal = {Proc. VLDB Endow.},
	author = {Bonomi, Luca and Xiong, Li},
	month = aug,
	year = {2013},
	pages = {1422--1427},
	file = {Bonomi and Xiong - 2013 - Mining frequent patterns with differential privacy.pdf:/home/erosfabrici/Zotero/storage/JW9XX9AQ/Bonomi and Xiong - 2013 - Mining frequent patterns with differential privacy.pdf:application/pdf},
}

@article{zhang_privbayes_nodate,
	title = {{PrivBayes}: {Private} {Data} {Release} via {Bayesian} {Networks}},
	abstract = {Privacy-preserving data publishing is an important problem that has been the focus of extensive study. The state-of-the-art goal for this problem is differential privacy, which offers a strong degree of privacy protection without making restrictive assumptions about the adversary. Existing techniques using differential privacy, however, cannot effectively handle the publication of high-dimensional data. In particular, when the input dataset contains a large number of attributes, existing methods require injecting a prohibitive amount of noise compared to the signal in the data, which renders the published data next to useless.},
	language = {en},
	author = {Zhang, Jun and Cormode, Graham and Procopiuc, Cecilia M and Srivastava, Divesh and Xiao, Xiaokui},
	file = {Zhang et al. - PrivBayes Private Data Release via Bayesian Netwo.pdf:/home/erosfabrici/Zotero/storage/6HWXZXKN/Zhang et al. - PrivBayes Private Data Release via Bayesian Netwo.pdf:application/pdf},
}

@article{nazi_efficient_2018,
	title = {Efficient estimation of inclusion coefficient using hyperloglog sketches},
	volume = {11},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3231751.3231759},
	doi = {10.14778/3231751.3231759},
	abstract = {Efﬁciently estimating the inclusion coefﬁcient – the fraction of values of one column that are contained in another column – is useful for tasks such as data proﬁling and foreign-key detection. We present a new estimator, BML, for inclusion coefﬁcient based on Hyperloglog sketches that results in signiﬁcantly lower error compared to the state-of-the art approach that uses Bottom-k sketches. We evaluate the error of the BML estimator using experiments on industry benchmarks such as TPC-H and TPC-DS, and several realworld databases. As an independent contribution, we show how Hyperloglog sketches can be maintained incrementally with data deletions using only a constant amount of additional memory.},
	language = {en},
	number = {10},
	urldate = {2022-12-15},
	journal = {Proc. VLDB Endow.},
	author = {Nazi, Azade and Ding, Bolin and Narasayya, Vivek and Chaudhuri, Surajit},
	month = jun,
	year = {2018},
	pages = {1097--1109},
	file = {Nazi et al. - 2018 - Efficient estimation of inclusion coefficient usin.pdf:/home/erosfabrici/Zotero/storage/RYMZJ6C6/Nazi et al. - 2018 - Efficient estimation of inclusion coefficient usin.pdf:application/pdf},
}

@article{kim_harra_nodate,
	title = {{HARRA}: fast iterative hashed record linkage for large-scale data collections},
	abstract = {We study the performance issue of the “iterative” record linkage (RL) problem, where match and merge operations may occur together in iterations until convergence emerges. We ﬁrst propose the Iterative Locality-Sensitive Hashing (ILSH) that dynamically merges LSH-based hash tables for quick and accurate blocking. Then, by exploiting inherent characteristics within/across data sets, we develop a suite of I-LSH-based RL algorithms, named as HARRA (HAshed RecoRd linkAge). The superiority of HARRA in speed over competing RL solutions is thoroughly validated using various real data sets. While maintaining equivalent or comparable accuracy levels, for instance, HARRA runs: (1) 4.5 and 10.5 times faster than StringMap and R-Swoosh in iteratively linking 4,000 × 4,000 short records (i.e., one of the small test cases), and (2) 5.6 and 3.4 times faster than basic LSH and Multi-Probe LSH algorithms in iteratively linking 400,000 × 400,000 long records (i.e., the largest test case).},
	language = {en},
	author = {Kim, Hung-sik and Lee, Dongwon},
	file = {Kim and Lee - HARRA fast iterative hashed record linkage for la.pdf:/home/erosfabrici/Zotero/storage/ZJ3UBL3S/Kim and Lee - HARRA fast iterative hashed record linkage for la.pdf:application/pdf},
}

@article{li_survey_nodate,
	title = {A {Survey} on {Federated} {Learning} {Systems}: {Vision}, {Hype} and {Reality} for {Data} {Privacy} and {Protection}},
	abstract = {As data privacy increasingly becomes a critical societal concern, federated learning has been a hot research topic in enabling the collaborative training of machine learning models among different organizations under the privacy restrictions. As researchers try to support more machine learning models with different privacy-preserving approaches, there is a requirement in developing systems and infrastructures to ease the development of various federated learning algorithms. Similar to deep learning systems such as PyTorch and TensorFlow that boost the development of deep learning, federated learning systems (FLSs) are equivalently important, and face challenges from various aspects such as effectiveness, efﬁciency, and privacy. In this survey, we conduct a comprehensive review on federated learning systems. To understand the key design system components and guide future research, we introduce the deﬁnition of federated learning systems and analyze the system components. Moreover, we provide a thorough categorization for federated learning systems according to six different aspects, including data distribution, machine learning model, privacy mechanism, communication architecture, scale of federation and motivation of federation. The categorization can help the design of federated learning systems as shown in our case studies. By systematically summarizing the existing federated learning systems, we present the design factors, case studies, and future research opportunities.},
	language = {en},
	author = {Li, Qinbin and Wen, Zeyi and Wu, Zhaomin and Hu, Sixu and Wang, Naibo and Li, Yuan and Liu, Xu and He, Bingsheng},
	file = {Li et al. - A Survey on Federated Learning Systems Vision, Hy.pdf:/home/erosfabrici/Zotero/storage/IKHVHY84/Li et al. - A Survey on Federated Learning Systems Vision, Hy.pdf:application/pdf},
}

@article{nargesian_table_2018,
	title = {Table union search on open data},
	volume = {11},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3192965.3192973},
	doi = {10.14778/3192965.3192973},
	abstract = {We deﬁne the table union search problem and present a probabilistic solution for ﬁnding tables that are unionable with a query table within massive repositories. Two tables are unionable if they share attributes from the same domain. Our solution formalizes three statistical models that describe how unionable attributes are generated from set domains, semantic domains with values from an ontology, and natural language domains. We propose a datadriven approach that automatically determines the best model to use for each pair of attributes. Through a distribution-aware algorithm, we are able to ﬁnd the optimal number of attributes in two tables that can be unioned. To evaluate accuracy, we created and open-sourced a benchmark of Open Data tables. We show that our table union search outperforms in speed and accuracy existing algorithms for ﬁnding related tables and scales to provide efﬁcient search over Open Data repositories containing more than one million attributes.},
	language = {en},
	number = {7},
	urldate = {2022-12-12},
	journal = {Proc. VLDB Endow.},
	author = {Nargesian, Fatemeh and Zhu, Erkang and Pu, Ken Q. and Miller, Renée J.},
	month = mar,
	year = {2018},
	pages = {813--825},
	file = {Nargesian et al. - 2018 - Table union search on open data.pdf:/home/erosfabrici/Zotero/storage/QCGAL5G6/Nargesian et al. - 2018 - Table union search on open data.pdf:application/pdf},
}

@incollection{renz_large-scale_2015,
	address = {Cham},
	title = {Large-{Scale} {Multi}-party {Counting} {Set} {Intersection} {Using} a {Space} {Efficient} {Global} {Synopsis}},
	volume = {9050},
	isbn = {978-3-319-18122-6 978-3-319-18123-3},
	url = {http://link.springer.com/10.1007/978-3-319-18123-3_20},
	abstract = {Privacy-preserving set intersection (PPSI) of very large data sets is increasingly being required in many real application areas including health-care, national security, and law enforcement. Various techniques have been developed to address this problem, where the majority of them rely on computationally expensive cryptographic techniques. Moreover, conventional data structures cannot be used eﬃciently for providing count estimates of the elements of the intersection of very large data sets. We consider the problem of eﬃcient PPSI by integrating sets from multiple (three or more) sources in order to create a global synopsis which is the result of the intersection of eﬃcient data structures, known as Count-Min sketches. This global synopsis furthermore provides count estimates of the intersected elements. We propose two protocols for the creation of this global synopsis which are based on homomorphic computations, a secure distributed summation scheme, and a symmetric noise addition technique. Experiments conducted on large synthetic and real data sets show the eﬃciency and accuracy of our protocols, while at the same time privacy under the Honest-but-Curious model is preserved.},
	language = {en},
	urldate = {2022-12-09},
	booktitle = {Database {Systems} for {Advanced} {Applications}},
	publisher = {Springer International Publishing},
	author = {Karapiperis, Dimitrios and Vatsalan, Dinusha and Verykios, Vassilios S. and Christen, Peter},
	editor = {Renz, Matthias and Shahabi, Cyrus and Zhou, Xiaofang and Cheema, Muhammad Aamir},
	year = {2015},
	doi = {10.1007/978-3-319-18123-3_20},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {329--345},
	file = {Karapiperis et al. - 2015 - Large-Scale Multi-party Counting Set Intersection .pdf:/home/erosfabrici/Zotero/storage/GVFBVLG6/Karapiperis et al. - 2015 - Large-Scale Multi-party Counting Set Intersection .pdf:application/pdf},
}

@article{dwork_algorithmic_2013,
	title = {The {Algorithmic} {Foundations} of {Differential} {Privacy}},
	volume = {9},
	issn = {1551-305X, 1551-3068},
	url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-theoretical-computer-science/TCS-042},
	doi = {10.1561/0400000042},
	language = {en},
	number = {3-4},
	urldate = {2022-12-08},
	journal = {FNT in Theoretical Computer Science},
	author = {Dwork, Cynthia and Roth, Aaron},
	year = {2013},
	pages = {211--407},
	file = {Dwork and Roth - 2013 - The Algorithmic Foundations of Differential Privac.pdf:/home/erosfabrici/Zotero/storage/LUJB3664/Dwork and Roth - 2013 - The Algorithmic Foundations of Differential Privac.pdf:application/pdf},
}

@inproceedings{vatsalan_scalable_2014,
	address = {Shanghai China},
	title = {Scalable {Privacy}-{Preserving} {Record} {Linkage} for {Multiple} {Databases}},
	isbn = {978-1-4503-2598-1},
	url = {https://dl.acm.org/doi/10.1145/2661829.2661875},
	doi = {10.1145/2661829.2661875},
	abstract = {Privacy-preserving record linkage (PPRL) is the process of identifying records that correspond to the same real-world entities across several databases without revealing any sensitive information about these entities. Various techniques have been developed to tackle the problem of PPRL, with the majority of them only considering linking two databases. However, in many real-world applications data from more than two sources need to be linked. In this paper we consider the problem of linking data from three or more sources in an eﬃcient and secure way. We propose a protocol that combines the use of Bloom ﬁlters, secure summation, and Dice coeﬃcient similarity calculation with the aim to identify all records held by the diﬀerent data sources that have a similarity above a certain threshold. Our protocol is secure in that no party learns any sensitive information about the other parties’ data, but all parties learn which of their records have a high similarity with records held by the other parties. We evaluate our protocol on a large dataset showing the scalability, linkage quality, and privacy of our protocol.},
	language = {en},
	urldate = {2022-12-07},
	booktitle = {Proceedings of the 23rd {ACM} {International} {Conference} on {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Vatsalan, Dinusha and Christen, Peter},
	month = nov,
	year = {2014},
	pages = {1795--1798},
	file = {Vatsalan and Christen - 2014 - Scalable Privacy-Preserving Record Linkage for Mul.pdf:/home/erosfabrici/Zotero/storage/R4D2RW8J/Vatsalan and Christen - 2014 - Scalable Privacy-Preserving Record Linkage for Mul.pdf:application/pdf},
}

@inproceedings{ranbaduge_scalable_2016,
	address = {Barcelona, Spain},
	title = {Scalable {Block} {Scheduling} for {Efficient} {Multi}-database {Record} {Linkage}},
	isbn = {978-1-5090-5473-2},
	url = {http://ieeexplore.ieee.org/document/7837966/},
	doi = {10.1109/ICDM.2016.0153},
	abstract = {Record linkage (RL) is a task in data integration that aims to identify matching records that refer to the same entity from different databases. When records from more than two databases are to be linked RL is signiﬁcantly challenged by the intrinsic exponential growth in the number of potential record comparisons to be conducted. We propose a scalable metablocking protocol to be used for Multi-Database RL (MDRL) to signiﬁcantly reduce the complexity of the matching (comparison and classiﬁcation) phase. Our approach uses a graph structure to schedule the comparison of pairs of blocks with the aim of minimizing the number of repeated and superﬂuous comparisons between records. We provide an analysis of our approach and conduct an empirical study on large real-world databases.},
	language = {en},
	urldate = {2022-12-07},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Ranbaduge, Thilina and Vatsalan, Dinusha and Christen, Peter},
	month = dec,
	year = {2016},
	pages = {1161--1166},
	file = {Ranbaduge et al. - 2016 - Scalable Block Scheduling for Efficient Multi-data.pdf:/home/erosfabrici/Zotero/storage/WI5SG93E/Ranbaduge et al. - 2016 - Scalable Block Scheduling for Efficient Multi-data.pdf:application/pdf},
}

@inproceedings{christiani_scalable_2018,
	address = {Paris},
	title = {Scalable and {Robust} {Set} {Similarity} {Join}},
	isbn = {978-1-5386-5520-7},
	url = {https://ieeexplore.ieee.org/document/8509341/},
	doi = {10.1109/ICDE.2018.00120},
	abstract = {Set similarity join is a fundamental and well-studied database operator. It is usually studied in the exact setting where the goal is to compute all pairs of sets that exceed a given similarity threshold (measured e.g. as Jaccard similarity). But set similarity join is often used in settings where 100\% recall may not be important — indeed, where the exact set similarity join is itself only an approximation of the desired result set.},
	language = {en},
	urldate = {2022-12-07},
	booktitle = {2018 {IEEE} 34th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Christiani, Tobias and Pagh, Rasmus and Sivertsen, Johan},
	month = apr,
	year = {2018},
	pages = {1240--1243},
	file = {Christiani et al. - 2018 - Scalable and Robust Set Similarity Join.pdf:/home/erosfabrici/Zotero/storage/25RIYXG4/Christiani et al. - 2018 - Scalable and Robust Set Similarity Join.pdf:application/pdf},
}

@article{rastogi_large-scale_2011,
	title = {Large-scale collective entity matching},
	volume = {4},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/1938545.1938546},
	doi = {10.14778/1938545.1938546},
	abstract = {There have been several recent advancements in Machine Learning community on the Entity Matching (EM) problem. However, their lack of scalability has prevented them from being applied in practical settings on large real-life datasets. Towards this end, we propose a principled framework to scale any generic EM algorithm. Our technique consists of running multiple instances of the EM algorithm on small neighborhoods of the data and passing messages across neighborhoods to construct a global solution. We prove formal properties of our framework and experimentally demonstrate the effectiveness of our approach in scaling EM algorithms.},
	language = {en},
	number = {4},
	urldate = {2022-12-07},
	journal = {Proc. VLDB Endow.},
	author = {Rastogi, Vibhor and Dalvi, Nilesh and Garofalakis, Minos},
	month = jan,
	year = {2011},
	pages = {208--218},
	file = {Rastogi et al. - 2011 - Large-scale collective entity matching.pdf:/home/erosfabrici/Zotero/storage/NM7KAFQ9/Rastogi et al. - 2011 - Large-scale collective entity matching.pdf:application/pdf},
}

@misc{christophides_end--end_2020,
	title = {End-to-{End} {Entity} {Resolution} for {Big} {Data}: {A} {Survey}},
	shorttitle = {End-to-{End} {Entity} {Resolution} for {Big} {Data}},
	url = {http://arxiv.org/abs/1905.06397},
	abstract = {One of the most important tasks for improving data quality and the reliability of data analytics results is Entity Resolution (ER). ER aims to identify different descriptions that refer to the same real-world entity, and remains a challenging problem. While previous works have studied specific aspects of ER (and mostly in traditional settings), in this survey, we provide for the first time an end-to-end view of modern ER workflows, and of the novel aspects of entity indexing and matching methods in order to cope with more than one of the Big Data characteristics simultaneously. We present the basic concepts, processing steps and execution strategies that have been proposed by different communities, i.e., database, semantic Web and machine learning, in order to cope with the loose structuredness, extreme diversity, high speed and large scale of entity descriptions used by real-world applications. Finally, we provide a synthetic discussion of the existing approaches, and conclude with a detailed presentation of open research directions.},
	language = {en},
	urldate = {2022-12-07},
	publisher = {arXiv},
	author = {Christophides, Vassilis and Efthymiou, Vasilis and Palpanas, Themis and Papadakis, George and Stefanidis, Kostas},
	month = aug,
	year = {2020},
	note = {arXiv:1905.06397 [cs]},
	keywords = {Computer Science - Databases},
	file = {Christophides et al. - 2020 - End-to-End Entity Resolution for Big Data A Surve.pdf:/home/erosfabrici/Zotero/storage/HHLWLIGT/Christophides et al. - 2020 - End-to-End Entity Resolution for Big Data A Surve.pdf:application/pdf},
}

@incollection{hutchison_broadening_2013,
	address = {Berlin, Heidelberg},
	title = {Broadening the {Scope} of {Differential} {Privacy} {Using} {Metrics}},
	volume = {7981},
	isbn = {978-3-642-39076-0 978-3-642-39077-7},
	url = {http://link.springer.com/10.1007/978-3-642-39077-7_5},
	abstract = {Differential Privacy is one of the most prominent frameworks used to deal with disclosure prevention in statistical databases. It provides a formal privacy guarantee, ensuring that sensitive information relative to individuals cannot be easily inferred by disclosing answers to aggregate queries. If two databases are adjacent, i.e. differ only for an individual, then the query should not allow to tell them apart by more than a certain factor. This induces a bound also on the distinguishability of two generic databases, which is determined by their distance on the Hamming graph of the adjacency relation.},
	language = {en},
	urldate = {2022-12-06},
	booktitle = {Privacy {Enhancing} {Technologies}},
	publisher = {Springer Berlin Heidelberg},
	author = {Chatzikokolakis, Konstantinos and Andrés, Miguel E. and Bordenabe, Nicolás Emilio and Palamidessi, Catuscia},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and De Cristofaro, Emiliano and Wright, Matthew},
	year = {2013},
	doi = {10.1007/978-3-642-39077-7_5},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {82--102},
	file = {Chatzikokolakis et al. - 2013 - Broadening the Scope of Differential Privacy Using.pdf:/home/erosfabrici/Zotero/storage/2PPGVU62/Chatzikokolakis et al. - 2013 - Broadening the Scope of Differential Privacy Using.pdf:application/pdf},
}

@inproceedings{christiani_scalable_2018-1,
	address = {Paris},
	title = {Scalable and {Robust} {Set} {Similarity} {Join}},
	isbn = {978-1-5386-5520-7},
	url = {https://ieeexplore.ieee.org/document/8509341/},
	doi = {10.1109/ICDE.2018.00120},
	abstract = {Set similarity join is a fundamental and well-studied database operator. It is usually studied in the exact setting where the goal is to compute all pairs of sets that exceed a given similarity threshold (measured e.g. as Jaccard similarity). But set similarity join is often used in settings where 100\% recall may not be important — indeed, where the exact set similarity join is itself only an approximation of the desired result set.},
	language = {en},
	urldate = {2022-12-06},
	booktitle = {2018 {IEEE} 34th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Christiani, Tobias and Pagh, Rasmus and Sivertsen, Johan},
	month = apr,
	year = {2018},
	pages = {1240--1243},
	file = {Christiani et al. - 2018 - Scalable and Robust Set Similarity Join.pdf:/home/erosfabrici/Zotero/storage/7Z7JUKIP/Christiani et al. - 2018 - Scalable and Robust Set Similarity Join.pdf:application/pdf},
}

@article{karapiperis_lsh-based_2015,
	title = {An {LSH}-{Based} {Blocking} {Approach} with a {Homomorphic} {Matching} {Technique} for {Privacy}-{Preserving} {Record} {Linkage}},
	volume = {27},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/6880802/},
	doi = {10.1109/TKDE.2014.2349916},
	abstract = {We present a L-fold Redundant Blocking Framework, that relies on the Locality-Sensitive Hashing technique for identifying candidate record pairs, which have undergone an anonymization transformation. In this context, we demonstrate the usage and evaluate the performance of a variety of families of hash functions used for blocking. We illustrate that the performance attained is highly correlated to the distance-preserving properties of the anonymization format used. The parameters, of the blocking scheme, are optimally selected so that we achieve the highest possible accuracy in the least possible running time. We also introduce an SMC-based protocol in order to compare the formulated record pairs homomorphically, without running the risk of breaching the privacy of the underlying records.},
	language = {en},
	number = {4},
	urldate = {2022-12-06},
	journal = {IEEE Trans. Knowl. Data Eng.},
	author = {Karapiperis, Dimitrios and Verykios, Vassilios S.},
	month = apr,
	year = {2015},
	pages = {909--921},
	file = {Karapiperis and Verykios - 2015 - An LSH-Based Blocking Approach with a Homomorphic .pdf:/home/erosfabrici/Zotero/storage/WXDC562S/Karapiperis and Verykios - 2015 - An LSH-Based Blocking Approach with a Homomorphic .pdf:application/pdf},
}

@misc{dwork_concentrated_2016,
	title = {Concentrated {Differential} {Privacy}},
	url = {http://arxiv.org/abs/1603.01887},
	abstract = {We introduce Concentrated Diﬀerential Privacy, a relaxation of Diﬀerential Privacy enjoying better accuracy than both pure diﬀerential privacy and its popular “(ε, δ)” relaxation without compromising on cumulative privacy loss over multiple computations.},
	language = {en},
	urldate = {2022-11-30},
	publisher = {arXiv},
	author = {Dwork, Cynthia and Rothblum, Guy N.},
	month = mar,
	year = {2016},
	note = {arXiv:1603.01887 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Data Structures and Algorithms},
	file = {Dwork and Rothblum - 2016 - Concentrated Differential Privacy.pdf:/home/erosfabrici/Zotero/storage/N3F3F83D/Dwork and Rothblum - 2016 - Concentrated Differential Privacy.pdf:application/pdf},
}

@article{xue_sequence_2020,
	title = {Sequence {Data} {Matching} and {Beyond}: {New} {Privacy}-{Preserving} {Primitives} {Based} on {Bloom} {Filters}},
	volume = {15},
	issn = {1556-6013, 1556-6021},
	shorttitle = {Sequence {Data} {Matching} and {Beyond}},
	url = {https://ieeexplore.ieee.org/document/9037114/},
	doi = {10.1109/TIFS.2020.2980835},
	abstract = {Bloom ﬁlter encoding has widely been used as an efﬁcient masking technique for privacy-preserving matching functions. The existing matching techniques, however, are limited to relatively simple types such as string, categorical and signal numerical values. In this paper, we propose a new scheme that signiﬁcantly extends the class of matching primitives that are based on privacy-preserving Bloom ﬁlter mechanism. These primitives include sequence data matching and popular distancebased machine learning algorithms such as KNN and SVM. Our scheme hash-maps a sequence data vector into the Bloom ﬁlter space while checking the similarity of the data points efﬁciently with negligible utility loss by adding a timestamp (bit) for each element in the data represented with its neighboring values. Furthermore, it includes a Laplace-like perturbation method on the constructed Bloom ﬁlters to address the weakness of deterministic probability led by encoding techniques. As a result, the proposed work guarantee the private data records are difﬁcult to be discriminated due to collisions and differential privacy. The experimental results on three real-scenario based datasets illustrate that our method can achieve a signiﬁcantly better trade-off between utility and privacy than the state-of-the-art differential privacy-based method by adding Laplace noise to the data directly.},
	language = {en},
	urldate = {2023-02-08},
	journal = {IEEE Trans.Inform.Forensic Secur.},
	author = {Xue, Wanli and Vatsalan, Dinusha and Hu, Wen and Seneviratne, Aruna},
	year = {2020},
	pages = {2973--2987},
	file = {Xue et al. - 2020 - Sequence Data Matching and Beyond New Privacy-Pre.pdf:/home/erosfabrici/Zotero/storage/4ABHQ7H7/Xue et al. - 2020 - Sequence Data Matching and Beyond New Privacy-Pre.pdf:application/pdf},
}

@article{lindell_secure_nodate,
	title = {Secure {Multiparty} {Computation} ({MPC})},
	abstract = {Protocols for secure multiparty computation (MPC) enable a set of parties to interact and compute a joint function of their private inputs while revealing nothing but the output. The potential applications for MPC are huge: privacy-preserving auctions, private DNA comparisons, private machine learning, threshold cryptography, and more. Due to this, MPC has been an intensive topic of research in academia ever since it was introduced in the 1980s by Yao for the two-party case (FOCS 1986), and by Goldreich, Micali and Wigderson for the multiparty case (STOC 1987). Recently, MPC has become eﬃcient enough to be used in practice, and has made the transition from an object of theoretical study to a technology being used in industry. In this article, we will review what MPC is, what problems it solves, and how it is being currently used.},
	language = {en},
	author = {Lindell, Yehuda},
	file = {Lindell - Secure Multiparty Computation (MPC).pdf:/home/erosfabrici/Zotero/storage/7GTFIW4G/Lindell - Secure Multiparty Computation (MPC).pdf:application/pdf},
}

@inproceedings{ren_online_2021,
	address = {Virtual Event China},
	title = {Online {Topic}-{Aware} {Entity} {Resolution} {Over} {Incomplete} {Data} {Streams}},
	isbn = {978-1-4503-8343-1},
	url = {https://dl.acm.org/doi/10.1145/3448016.3457238},
	doi = {10.1145/3448016.3457238},
	abstract = {In many real applications such as the data integration, social network analysis, and the Semantic Web, the entity resolution (ER) is an important and fundamental problem, which identifies and links the same real-world entities from various data sources. While prior works usually consider ER over static and complete data, in practice, application data are usually collected in a streaming fashion, and often incur missing attributes (due to the inaccuracy of data extraction techniques). Therefore, in this paper, we will formulate and tackle a novel problem, topic-aware entity resolution over incomplete data streams (TER-iDS), which online imputes incomplete tuples and detects pairs of topic-related matching entities from incomplete data streams. In order to effectively and efficiently tackle the TERiDS problem, we propose an effective imputation strategy, carefully design effective pruning strategies, as well as indexes/synopsis, and develop an efficient TER-iDS algorithm via index joins. Extensive experiments have been conducted to evaluate the effectiveness and efficiency of our proposed TER-iDS approach over real data sets.},
	language = {en},
	urldate = {2023-02-15},
	booktitle = {Proceedings of the 2021 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Ren, Weilong and Lian, Xiang and Ghazinour, Kambiz},
	month = jun,
	year = {2021},
	pages = {1478--1490},
	file = {Ren et al. - 2021 - Online Topic-Aware Entity Resolution Over Incomple.pdf:/home/erosfabrici/Zotero/storage/UBHQIPQY/Ren et al. - 2021 - Online Topic-Aware Entity Resolution Over Incomple.pdf:application/pdf},
}

@article{jain_deep_2021,
	title = {Deep {Indexed} {Active} {Learning} for {Matching} {Heterogeneous} {Entity} {Representations}},
	volume = {15},
	issn = {2150-8097},
	url = {http://arxiv.org/abs/2104.03986},
	doi = {10.14778/3485450.3485455},
	abstract = {Given two large lists of records, the task in entity resolution (ER) is to find the pairs from the Cartesian product of the lists that correspond to the same real world entity. Typically, passive learning methods on such tasks require large amounts of labeled data to yield useful models. Active Learning is a promising approach for ER in low resource settings. However, the search space, to find informative samples for the user to label, grows quadratically for instance-pair tasks making active learning hard to scale. Previous works, in this setting, rely on hand-crafted predicates, pre-trained language model embeddings, or rule learning to prune away unlikely pairs from the Cartesian product. This blocking step can miss out on important regions in the product space leading to low recall. We propose DIAL, a scalable active learning approach that jointly learns embeddings to maximize recall for blocking and accuracy for matching blocked pairs. DIAL uses an Index-By-Committee framework, where each committee member learns representations based on powerful pre-trained transformer language models. We highlight surprising differences between the matcher and the blocker in the creation of the training data and the objective used to train their parameters. Experiments on five benchmark datasets and a multilingual record matching dataset show the effectiveness of our approach in terms of precision, recall and running time.},
	language = {en},
	number = {1},
	urldate = {2023-02-15},
	journal = {Proc. VLDB Endow.},
	author = {Jain, Arjit and Sarawagi, Sunita and Sen, Prithviraj},
	month = sep,
	year = {2021},
	note = {arXiv:2104.03986 [cs, stat]},
	keywords = {Computer Science - Databases, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {31--45},
	file = {Jain et al. - 2021 - Deep Indexed Active Learning for Matching Heteroge.pdf:/home/erosfabrici/Zotero/storage/RASHF3M3/Jain et al. - 2021 - Deep Indexed Active Learning for Matching Heteroge.pdf:application/pdf},
}

@article{ebraheem_deeper_2018,
	title = {{DeepER} -- {Deep} {Entity} {Resolution}},
	volume = {11},
	issn = {2150-8097},
	url = {http://arxiv.org/abs/1710.00597},
	doi = {10.14778/3236187.3236198},
	abstract = {Despite the eﬀorts in 70+ years in all aspects of entity resolution (ER), there is still a high demand for democratizing ER – by reducing the heavy human involvement in labeling data, performing feature engineering, tuning parameters, and deﬁning blocking functions. With the recent advances in deep learning, in particular distributed representations of words (a.k.a. word embeddings), we present a novel ER system, called DeepER, that achieves good accuracy, high eﬃciency, as well as ease-of-use (i.e., much less human eﬀorts). We use sophisticated composition methods, namely uni- and bi-directional recurrent neural networks (RNNs) with long short term memory (LSTM) hidden units, to convert each tuple to a distributed representation (i.e., a vector), which can in turn be used to eﬀectively capture similarities between tuples. We consider both the case where pre-trained word embeddings are available as well the case where they are not; we present ways to learn and tune the distributed representations that are customized for a speciﬁc ER task under diﬀerent scenarios. We propose a locality sensitive hashing (LSH) based blocking approach that takes all attributes of a tuple into consideration and produces much smaller blocks, compared with traditional methods that consider only a few attributes. We evaluate our algorithms on multiple datasets (including benchmarks, biomedical data, as well as multi-lingual data) and the extensive experimental results show that DeepER outperforms existing solutions.},
	language = {en},
	number = {11},
	urldate = {2023-02-15},
	journal = {Proc. VLDB Endow.},
	author = {Ebraheem, Muhammad and Thirumuruganathan, Saravanan and Joty, Shafiq and Ouzzani, Mourad and Tang, Nan},
	month = jul,
	year = {2018},
	note = {arXiv:1710.00597 [cs]},
	keywords = {Computer Science - Databases},
	pages = {1454--1467},
	file = {Ebraheem et al. - 2018 - DeepER -- Deep Entity Resolution.pdf:/home/erosfabrici/Zotero/storage/HYIQ7ZBG/Ebraheem et al. - 2018 - DeepER -- Deep Entity Resolution.pdf:application/pdf},
}

@article{rao_privacy_2019,
	title = {Privacy {Techniques} for {Edge} {Computing} {Systems}},
	volume = {107},
	issn = {0018-9219, 1558-2256},
	url = {https://ieeexplore.ieee.org/document/8737758/},
	doi = {10.1109/JPROC.2019.2918749},
	abstract = {In an edge enabled data management and computing environment, it is critical to ensure the privacy of the information acquired, processed, and exchanged among the different parties. The problem is complex because of the large scale, mobility, device and protocol heterogeneity. Also, unlike in conventional environments, communication may be fragmented and portions of the environment be physically unprotected. To date there are several privacy-enhancing techniques, such as secure multi-party computation techniques, private information retrieval (PIR), and data sanitization techniques. However there is not a single technique that works for all possible uses of the data in edge systems. In addition, these techniques are computationally expensive and thus may not be suitable for edge devices. In this paper, we ﬁrst cover basic privacy building blocks, including differential privacy, and homomorphic encryption. We then discuss privacy solutions speciﬁc to three different types of data use that are relevant for edge-based applications: data aggregation techniques, point of interest (POI) services and trafﬁc information services, and crowdsourcing. These applications have been selected as they provide a broad spectrum of edge computing applications. Throughout the paper, we outline open research directions.},
	language = {en},
	number = {8},
	urldate = {2023-02-14},
	journal = {Proc. IEEE},
	author = {Rao, Fang-Yu and Bertino, Elisa},
	month = aug,
	year = {2019},
	pages = {1632--1654},
	file = {Rao and Bertino - 2019 - Privacy Techniques for Edge Computing Systems.pdf:/home/erosfabrici/Zotero/storage/NJ26URFW/Rao and Bertino - 2019 - Privacy Techniques for Edge Computing Systems.pdf:application/pdf},
}

@article{mouris_delegated_nodate,
	title = {Delegated {Private} {Matching} for {Compute}},
	abstract = {Private matching for compute (PMC) establishes a match between two databases owned by mutually distrusted parties (C and P ) and allows the parties to input more data for the matched records for arbitrary downstream secure computation without rerunning the private matching component. The state-of-the-art PMC protocols only support two parties and assume that both parties can participate in computationally intensive secure computation. We observe that such operational overhead limits the adoption of these protocols to solely powerful entities as small data owners or devices with minimal computing power will not be able to participate.},
	language = {en},
	author = {Mouris, Dimitris and Masny, Daniel and Trieu, Ni and Sengupta, Shubho and Buddhavarapu, Prasad and Case, Benjamin},
	file = {Mouris et al. - Delegated Private Matching for Compute.pdf:/home/erosfabrici/Zotero/storage/49WPS3V8/Mouris et al. - Delegated Private Matching for Compute.pdf:application/pdf},
}

@article{buddhavarapu_private_nodate,
	title = {Private {Matching} for {Compute}},
	abstract = {We revisit the problem of two-party private set intersection for aggregate computation which we refer to as private matching for compute. In this problem, two parties want to perform various downstream computation on the intersection of their two datasets according to a previously agreed-upon identifier. We observe that prior solutions to this problem have important limitations. For example, any change or update to the records in either party’s dataset triggers a rerun of the private matching component; and it is not clear how to support a streaming arrival of one party’s set in small batches without revealing the match rate for each individual batch.},
	language = {en},
	author = {Buddhavarapu, Prasad and Knox, Andrew and Mohassel, Payman and Taubeneck, Erik and Vlaskin, Vlad and Sengupta, Shubho},
	file = {Buddhavarapu et al. - Private Matching for Compute.pdf:/home/erosfabrici/Zotero/storage/GBK6MSKL/Buddhavarapu et al. - Private Matching for Compute.pdf:application/pdf},
}

@article{buddhavarapu_multi-key_nodate,
	title = {Multi-key {Private} {Matching} for {Compute}},
	abstract = {We extend two-party private set union for secure computation, by considering matching between records having multiple identiﬁers (or keys), for example email and phone. In the classical setting of this problem, two parties want to perform various downstream computations on the union of two datasets. The union is computed by joining two datasets with the help of a single agreed upon identiﬁer, say email. By extending this to joining records with multiple identiﬁers, we bring it much closer to real world uses where the match rate and match quality can be greatly improved by considering multiple identiﬁers.},
	language = {en},
	author = {Buddhavarapu, Prasad and Mohassel, Payman and Case, Benjamin M and Gore, Logan and Knox, Andrew and Sengupta, Shubho and Taubeneck, Erik and Xue, Min},
	file = {Buddhavarapu et al. - Multi-key Private Matching for Compute.pdf:/home/erosfabrici/Zotero/storage/MXJJIDN8/Buddhavarapu et al. - Multi-key Private Matching for Compute.pdf:application/pdf},
}

@article{yi_privacy-preserving_2020,
	title = {Privacy-{Preserving} {User} {Profile} {Matching} in {Social} {Networks}},
	volume = {32},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/8695745/},
	doi = {10.1109/TKDE.2019.2912748},
	abstract = {In this paper, we consider a scenario where a user queries a user proﬁle database, maintained by a social networking service provider, to identify users whose proﬁles match the proﬁle speciﬁed by the querying user. A typical example of this application is online dating. Most recently, an online dating website, Ashley Madison, was hacked, which resulted in a disclosure of a large number of dating user proﬁles. This data breach has urged researchers to explore practical privacy protection for user proﬁles in a social network. In this paper, we propose a privacy-preserving solution for proﬁle matching in social networks by using multiple servers. Our solution is built on homomorphic encryption and allows a user to ﬁnd out matching users with the help of multiple servers without revealing to anyone the query and the queried user proﬁles in clear. Our solution achieves user proﬁle privacy and user query privacy as long as at least one of the multiple servers is honest. Our experiments demonstrate that our solution is practical.},
	language = {en},
	number = {8},
	urldate = {2023-02-13},
	journal = {IEEE Trans. Knowl. Data Eng.},
	author = {Yi, Xun and Bertino, Elisa and Rao, Fang-Yu and Lam, Kwok-Yan and Nepal, Surya and Bouguettaya, Athman},
	month = aug,
	year = {2020},
	pages = {1572--1585},
	file = {Yi et al. - 2020 - Privacy-Preserving User Profile Matching in Social.pdf:/home/erosfabrici/Zotero/storage/V36W9FJK/Yi et al. - 2020 - Privacy-Preserving User Profile Matching in Social.pdf:application/pdf},
}

@article{vatsalan_local_2022,
	title = {Local {Differentially} {Private} {Fuzzy} {Counting} in {Stream} {Data} {Using} {Probabilistic} {Data} {Structures}},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/9855874/},
	doi = {10.1109/TKDE.2022.3198478},
	abstract = {Privacy-preserving estimation of counts of items in streaming data finds applications in several real-world scenarios including word auto-correction and traffic management applications. Recent works of RAPPOR [1] and Apple’s count-mean sketch (CMS) algorithm [2] propose privacy preserving mechanisms for count estimation in large volumes of data using probabilistic data structures like counting Bloom filter and CMS. However, these existing methods fall short in providing a sound solution for real-time streaming data applications. Since the size of the data structure in these methods is not adaptive to the volume of the streaming data, the utility (accuracy of the count estimate) can suffer over time due to increased false positive rates. Further, the lookup operation needs to be highly efficient to answer count estimate queries in real-time. More importantly, the local Differential privacy mechanisms used in these approaches to provide privacy guarantees come at a large cost to utility (impacting the accuracy of count estimation). In this work, we propose a novel (local) Differentially private mechanism that provides high utility for the streaming data count estimation problem with similar or even lower privacy budgets while providing: a) fuzzy counting to report counts of related or similar items (for instance to account for typing errors and data variations), and b) improved querying efficiency to reduce the response time for real-time querying of counts. Our algorithm uses a combination of two probabilistic data structures Cuckoo filter and Bloom filter. We provide formal proofs for privacy and utility guarantees and present extensive experimental evaluation of our algorithm using real and synthetic English words datasets for both the exact and fuzzy counting scenarios. Our privacy preserving mechanism substantially outperforms the prior work in terms of lower querying time, significantly higher utility (accuracy of count estimation) under similar or lower privacy guarantees, at the cost of communication overhead.},
	language = {en},
	urldate = {2023-02-08},
	journal = {IEEE Trans. Knowl. Data Eng.},
	author = {Vatsalan, Dinusha and Bhaskar, Raghav and Kaafar, Mohamed Ali},
	year = {2022},
	pages = {1--14},
	file = {Vatsalan et al. - 2022 - Local Differentially Private Fuzzy Counting in Str.pdf:/home/erosfabrici/Zotero/storage/6AV7KZ8B/Vatsalan et al. - 2022 - Local Differentially Private Fuzzy Counting in Str.pdf:application/pdf},
}

@inproceedings{koutras_valentine_2021,
	address = {Chania, Greece},
	title = {Valentine: {Evaluating} {Matching} {Techniques} for {Dataset} {Discovery}},
	isbn = {978-1-72819-184-3},
	shorttitle = {Valentine},
	url = {https://ieeexplore.ieee.org/document/9458921/},
	doi = {10.1109/ICDE51399.2021.00047},
	abstract = {Data scientists today search large data lakes to discover and integrate datasets. In order to bring together disparate data sources, dataset discovery methods rely on some form of schema matching: the process of establishing correspondences between datasets. Traditionally, schema matching has been used to ﬁnd matching pairs of columns between a source and a target schema. However, the use of schema matching in dataset discovery methods differs from its original use. Nowadays schema matching serves as a building block for indicating and ranking inter-dataset relationships. Surprisingly, although a discovery method’s success relies highly on the quality of the underlying matching algorithms, the latest discovery methods employ existing schema matching algorithms in an ad-hoc fashion due to the lack of openly-available datasets with ground truth, reference method implementations, and evaluation metrics.},
	language = {en},
	urldate = {2023-02-08},
	booktitle = {2021 {IEEE} 37th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Koutras, Christos and Siachamis, George and Ionescu, Andra and Psarakis, Kyriakos and Brons, Jerry and Fragkoulis, Marios and Lofi, Christoph and Bonifati, Angela and Katsifodimos, Asterios},
	month = apr,
	year = {2021},
	pages = {468--479},
	file = {Koutras et al. - 2021 - Valentine Evaluating Matching Techniques for Data.pdf:/home/erosfabrici/Zotero/storage/3F42K4XS/Koutras et al. - 2021 - Valentine Evaluating Matching Techniques for Data.pdf:application/pdf},
}

@article{whang_joint_2013,
	title = {Joint entity resolution on multiple datasets},
	volume = {22},
	issn = {1066-8888, 0949-877X},
	url = {http://link.springer.com/10.1007/s00778-013-0308-z},
	doi = {10.1007/s00778-013-0308-z},
	abstract = {Entity resolution (ER) is the problem of identifying which records in a database represent the same entity. Often, records of different types are involved (e.g., authors, publications, institutions, venues), and resolving records of one type can impact the resolution of other types of records. In this paper we propose a ﬂexible, modular resolution framework where existing ER algorithms developed for a given record type can be plugged in and used in concert with other ER algorithms. Our approach also makes it possible to run ER on subsets of similar records at a time, important when the full data are too large to resolve together. We study the scheduling and coordination of the individual ER algorithms, in order to resolve the full dataset, and show the scalability of our approach. We also introduce a “state-based” training technique where each ER algorithm is trained for the particular execution context (relative to other types of records) where it will be used.},
	language = {en},
	number = {6},
	urldate = {2023-02-08},
	journal = {The VLDB Journal},
	author = {Whang, Steven Euijong and Garcia-Molina, Hector},
	month = dec,
	year = {2013},
	pages = {773--795},
	file = {Whang and Garcia-Molina - 2013 - Joint entity resolution on multiple datasets.pdf:/home/erosfabrici/Zotero/storage/92L7CWA8/Whang and Garcia-Molina - 2013 - Joint entity resolution on multiple datasets.pdf:application/pdf},
}

@article{ouellette_ronin_2021,
	title = {{RONIN}: data lake exploration},
	volume = {14},
	issn = {2150-8097},
	shorttitle = {{RONIN}},
	url = {https://dl.acm.org/doi/10.14778/3476311.3476364},
	doi = {10.14778/3476311.3476364},
	abstract = {Dataset discovery can be performed using search (with a query or keywords) to find relevant data. However, the result of this discovery can be overwhelming to explore. Existing navigation techniques mostly focus on linkage graphs that enable navigation from one data set to another based on similarity or joinability of attributes. However, users often do not know which data set to start the navigation from. RONIN proposes an alternative way to navigate by building a hierarchical structure on a collection of data sets: the user navigates between groups of data sets in a hierarchical manner to narrow down to the data of interest. We demonstrate RONIN, a tool that enables user exploration of a data lake by seamlessly integrating the two common modalities of discovery: data set search and navigation of a hierarchical structure. In RONIN, a user can perform a keyword search or joinability search over a data lake, then, navigate the result using a hierarchical structure, called an organization, that is created on the fly. While navigating an organization, the user may switch to the search mode, and back to navigation on an organization that is updated based on search. This integration of search and navigation provides great power in allowing users to find and explore interesting data in a data lake.},
	language = {en},
	number = {12},
	urldate = {2023-02-08},
	journal = {Proc. VLDB Endow.},
	author = {Ouellette, Paul and Sciortino, Aidan and Nargesian, Fatemeh and Bashardoost, Bahar Ghadiri and Zhu, Erkang and Pu, Ken Q. and Miller, Renée J.},
	month = jul,
	year = {2021},
	pages = {2863--2866},
	file = {Ouellette et al. - 2021 - RONIN data lake exploration.pdf:/home/erosfabrici/Zotero/storage/78UFXECD/Ouellette et al. - 2021 - RONIN data lake exploration.pdf:application/pdf},
}
